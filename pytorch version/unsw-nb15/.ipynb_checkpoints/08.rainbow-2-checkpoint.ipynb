{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt install python-opengl\n",
    "    !apt install ffmpeg\n",
    "    !apt install xvfb\n",
    "    !pip install PyVirtualDisplay==3.0\n",
    "    !pip install gym==0.21.0\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    # Start virtual display\n",
    "    dis = Display(visible=0, size=(400, 400))\n",
    "    dis.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08. Rainbow\n",
    "\n",
    "[M. Hessel et al., \"Rainbow: Combining Improvements in Deep Reinforcement Learning.\" arXiv preprint arXiv:1710.02298, 2017.](https://arxiv.org/pdf/1710.02298.pdf)\n",
    "\n",
    "We will integrate all the following seven components into a single integrated agent, which is called Rainbow!\n",
    "\n",
    "1. DQN\n",
    "2. Double DQN\n",
    "3. Prioritized Experience Replay\n",
    "4. Dueling Network\n",
    "5. Noisy Network\n",
    "6. Categorical DQN\n",
    "7. N-step Learning\n",
    "\n",
    "This method shows an impressive performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. \n",
    "\n",
    "![rainbow](https://user-images.githubusercontent.com/14961526/60591412-61748100-9dd9-11e9-84fb-076c7a61fbab.png)\n",
    "\n",
    "However, the integration is not so simple because some of components are not independent each other, so we will look into a number of points that people especailly feel confused.\n",
    "\n",
    "1. Noisy Network <-> Dueling Network\n",
    "2. Dueling Network <-> Categorical DQN\n",
    "3. Categorical DQN <-> Double DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "from typing import Deque, Dict, List, Tuple\n",
    "\n",
    "import gym\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# download segment tree module\n",
    "if IN_COLAB:\n",
    "    !wget https://raw.githubusercontent.com/curt-park/rainbow-is-all-you-need/master/segment_tree.py\n",
    "\n",
    "# from segment_tree import MinSegmentTree, SumSegmentTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class SegmentTree:\n",
    "    \"\"\" Create SegmentTree.\n",
    "\n",
    "    Taken from OpenAI baselines github repository:\n",
    "    https://github.com/openai/baselines/blob/master/baselines/common/segment_tree.py\n",
    "\n",
    "    Attributes:\n",
    "        capacity (int)\n",
    "        tree (list)\n",
    "        operation (function)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, capacity: int, operation: Callable, init_value: float):\n",
    "        \"\"\"Initialization.\n",
    "\n",
    "        Args:\n",
    "            capacity (int)\n",
    "            operation (function)\n",
    "            init_value (float)\n",
    "\n",
    "        \"\"\"\n",
    "        assert (\n",
    "            capacity > 0 and capacity & (capacity - 1) == 0\n",
    "        ), \"capacity must be positive and a power of 2.\"\n",
    "        self.capacity = capacity\n",
    "        self.tree = [init_value for _ in range(2 * capacity)]\n",
    "        self.operation = operation\n",
    "\n",
    "    def _operate_helper(\n",
    "        self, start: int, end: int, node: int, node_start: int, node_end: int\n",
    "    ) -> float:\n",
    "        \"\"\"Returns result of operation in segment.\"\"\"\n",
    "        if start == node_start and end == node_end:\n",
    "            return self.tree[node]\n",
    "        mid = (node_start + node_end) // 2\n",
    "        if end <= mid:\n",
    "            return self._operate_helper(start, end, 2 * node, node_start, mid)\n",
    "        else:\n",
    "            if mid + 1 <= start:\n",
    "                return self._operate_helper(start, end, 2 * node + 1, mid + 1, node_end)\n",
    "            else:\n",
    "                return self.operation(\n",
    "                    self._operate_helper(start, mid, 2 * node, node_start, mid),\n",
    "                    self._operate_helper(mid + 1, end, 2 * node + 1, mid + 1, node_end),\n",
    "                )\n",
    "\n",
    "    def operate(self, start: int = 0, end: int = 0) -> float:\n",
    "        \"\"\"Returns result of applying `self.operation`.\"\"\"\n",
    "        if end <= 0:\n",
    "            end += self.capacity\n",
    "        end -= 1\n",
    "\n",
    "        return self._operate_helper(start, end, 1, 0, self.capacity - 1)\n",
    "\n",
    "    def __setitem__(self, idx: int, val: float):\n",
    "        \"\"\"Set value in tree.\"\"\"\n",
    "        idx += self.capacity\n",
    "        self.tree[idx] = val\n",
    "\n",
    "        idx //= 2\n",
    "        while idx >= 1:\n",
    "            self.tree[idx] = self.operation(self.tree[2 * idx], self.tree[2 * idx + 1])\n",
    "            idx //= 2\n",
    "\n",
    "    def __getitem__(self, idx: int) -> float:\n",
    "        \"\"\"Get real value in leaf node of tree.\"\"\"\n",
    "        assert 0 <= idx < self.capacity\n",
    "\n",
    "        return self.tree[self.capacity + idx]\n",
    "\n",
    "\n",
    "class SumSegmentTree(SegmentTree):\n",
    "    \"\"\" Create SumSegmentTree.\n",
    "\n",
    "    Taken from OpenAI baselines github repository:\n",
    "    https://github.com/openai/baselines/blob/master/baselines/common/segment_tree.py\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, capacity: int):\n",
    "        \"\"\"Initialization.\n",
    "\n",
    "        Args:\n",
    "            capacity (int)\n",
    "\n",
    "        \"\"\"\n",
    "        super(SumSegmentTree, self).__init__(\n",
    "            capacity=capacity, operation=operator.add, init_value=0.0\n",
    "        )\n",
    "\n",
    "    def sum(self, start: int = 0, end: int = 0) -> float:\n",
    "        \"\"\"Returns arr[start] + ... + arr[end].\"\"\"\n",
    "        return super(SumSegmentTree, self).operate(start, end)\n",
    "\n",
    "    def retrieve(self, upperbound: float) -> int:\n",
    "        \"\"\"Find the highest index `i` about upper bound in the tree\"\"\"\n",
    "        # TODO: Check assert case and fix bug\n",
    "        assert 0 <= upperbound <= self.sum() + 1e-5, \"upperbound: {}\".format(upperbound)\n",
    "\n",
    "        idx = 1\n",
    "\n",
    "        while idx < self.capacity:  # while non-leaf\n",
    "            left = 2 * idx\n",
    "            right = left + 1\n",
    "            if self.tree[left] > upperbound:\n",
    "                idx = 2 * idx\n",
    "            else:\n",
    "                upperbound -= self.tree[left]\n",
    "                idx = right\n",
    "        return idx - self.capacity\n",
    "\n",
    "\n",
    "class MinSegmentTree(SegmentTree):\n",
    "    \"\"\" Create SegmentTree.\n",
    "\n",
    "    Taken from OpenAI baselines github repository:\n",
    "    https://github.com/openai/baselines/blob/master/baselines/common/segment_tree.py\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, capacity: int):\n",
    "        \"\"\"Initialization.\n",
    "\n",
    "        Args:\n",
    "            capacity (int)\n",
    "\n",
    "        \"\"\"\n",
    "        super(MinSegmentTree, self).__init__(\n",
    "            capacity=capacity, operation=min, init_value=float(\"inf\")\n",
    "        )\n",
    "\n",
    "    def min(self, start: int = 0, end: int = 0) -> float:\n",
    "        \"\"\"Returns min(arr[start], ...,  arr[end]).\"\"\"\n",
    "        return super(MinSegmentTree, self).operate(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Same as the basic N-step buffer. \n",
    "\n",
    "(Please see *01.dqn.ipynb*, *07.n_step_learning.ipynb* for detailed description about the basic (n-step) replay buffer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99\n",
    "    ):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "        \n",
    "        # for N-step Learning\n",
    "        self.n_step_buffer = deque(maxlen=n_step)\n",
    "        self.n_step = n_step\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        transition = (obs, act, rew, next_obs, done)\n",
    "        self.n_step_buffer.append(transition)\n",
    "\n",
    "        # single step transition is not ready\n",
    "        if len(self.n_step_buffer) < self.n_step:\n",
    "            return ()\n",
    "        \n",
    "        # make a n-step transition\n",
    "        rew, next_obs, done = self._get_n_step_info(\n",
    "            self.n_step_buffer, self.gamma\n",
    "        )\n",
    "        obs, act = self.n_step_buffer[0][:2]\n",
    "        \n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "        \n",
    "        return self.n_step_buffer[0]\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "            # for N-step Learning\n",
    "            indices=idxs,\n",
    "        )\n",
    "    \n",
    "    def sample_batch_from_idxs(\n",
    "        self, idxs: np.ndarray\n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "        # for N-step Learning\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "        )\n",
    "    \n",
    "    def _get_n_step_info(\n",
    "        self, n_step_buffer: Deque, gamma: float\n",
    "    ) -> Tuple[np.int64, np.ndarray, bool]:\n",
    "        \"\"\"Return n step rew, next_obs, and done.\"\"\"\n",
    "        # info of the last transition\n",
    "        rew, next_obs, done = n_step_buffer[-1][-3:]\n",
    "\n",
    "        for transition in reversed(list(n_step_buffer)[:-1]):\n",
    "            r, n_o, d = transition[-3:]\n",
    "\n",
    "            rew = r + gamma * rew * (1 - d)\n",
    "            next_obs, done = (n_o, d) if d else (next_obs, done)\n",
    "\n",
    "        return rew, next_obs, done\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prioritized replay Buffer\n",
    "\n",
    "`store` method returns boolean in order to inform if a N-step transition has been generated.\n",
    "\n",
    "(Please see *02.per.ipynb* for detailed description about PER.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer(ReplayBuffer):\n",
    "    \"\"\"Prioritized Replay buffer.\n",
    "    \n",
    "    Attributes:\n",
    "        max_priority (float): max priority\n",
    "        tree_ptr (int): next index of tree\n",
    "        alpha (float): alpha parameter for prioritized replay buffer\n",
    "        sum_tree (SumSegmentTree): sum tree for prior\n",
    "        min_tree (MinSegmentTree): min tree for min prior to get max weight\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        alpha: float = 0.6,\n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        assert alpha >= 0\n",
    "        \n",
    "        super(PrioritizedReplayBuffer, self).__init__(\n",
    "            obs_dim, size, batch_size, n_step, gamma\n",
    "        )\n",
    "        self.max_priority, self.tree_ptr = 1.0, 0\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # capacity must be positive and a power of 2.\n",
    "        tree_capacity = 1\n",
    "        while tree_capacity < self.max_size:\n",
    "            tree_capacity *= 2\n",
    "\n",
    "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
    "        self.min_tree = MinSegmentTree(tree_capacity)\n",
    "        \n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: int, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        \"\"\"Store experience and priority.\"\"\"\n",
    "        transition = super().store(obs, act, rew, next_obs, done)\n",
    "        \n",
    "        if transition:\n",
    "            self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.tree_ptr = (self.tree_ptr + 1) % self.max_size\n",
    "        \n",
    "        return transition\n",
    "\n",
    "    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        assert len(self) >= self.batch_size\n",
    "        assert beta > 0\n",
    "        \n",
    "        indices = self._sample_proportional()\n",
    "        \n",
    "        obs = self.obs_buf[indices]\n",
    "        next_obs = self.next_obs_buf[indices]\n",
    "        acts = self.acts_buf[indices]\n",
    "        rews = self.rews_buf[indices]\n",
    "        done = self.done_buf[indices]\n",
    "        weights = np.array([self._calculate_weight(i, beta) for i in indices])\n",
    "        \n",
    "        return dict(\n",
    "            obs=obs,\n",
    "            next_obs=next_obs,\n",
    "            acts=acts,\n",
    "            rews=rews,\n",
    "            done=done,\n",
    "            weights=weights,\n",
    "            indices=indices,\n",
    "        )\n",
    "        \n",
    "    def update_priorities(self, indices: List[int], priorities: np.ndarray):\n",
    "        \"\"\"Update priorities of sampled transitions.\"\"\"\n",
    "        assert len(indices) == len(priorities)\n",
    "\n",
    "        for idx, priority in zip(indices, priorities):\n",
    "            assert priority > 0\n",
    "            assert 0 <= idx < len(self)\n",
    "\n",
    "            self.sum_tree[idx] = priority ** self.alpha\n",
    "            self.min_tree[idx] = priority ** self.alpha\n",
    "\n",
    "            self.max_priority = max(self.max_priority, priority)\n",
    "            \n",
    "    def _sample_proportional(self) -> List[int]:\n",
    "        \"\"\"Sample indices based on proportions.\"\"\"\n",
    "        indices = []\n",
    "        p_total = self.sum_tree.sum(0, len(self) - 1)\n",
    "        segment = p_total / self.batch_size\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "            upperbound = random.uniform(a, b)\n",
    "            idx = self.sum_tree.retrieve(upperbound)\n",
    "            indices.append(idx)\n",
    "            \n",
    "        return indices\n",
    "    \n",
    "    def _calculate_weight(self, idx: int, beta: float):\n",
    "        \"\"\"Calculate the weight of the experience at idx.\"\"\"\n",
    "        # get max weight\n",
    "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
    "        max_weight = (p_min * len(self)) ** (-beta)\n",
    "        \n",
    "        # calculate weights\n",
    "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
    "        weight = (p_sample * len(self)) ** (-beta)\n",
    "        weight = weight / max_weight\n",
    "        \n",
    "        return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Layer\n",
    "\n",
    "Please see *05.noisy_net.ipynb* for detailed description.\n",
    "\n",
    "**References:**\n",
    "\n",
    "- https://github.com/higgsfield/RL-Adventure/blob/master/5.noisy%20dqn.ipynb\n",
    "- https://github.com/Kaixhin/Rainbow/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    \"\"\"Noisy linear module for NoisyNet.\n",
    "    \n",
    "    \n",
    "        \n",
    "    Attributes:\n",
    "        in_features (int): input size of linear module\n",
    "        out_features (int): output size of linear module\n",
    "        std_init (float): initial std value\n",
    "        weight_mu (nn.Parameter): mean value weight parameter\n",
    "        weight_sigma (nn.Parameter): std value weight parameter\n",
    "        bias_mu (nn.Parameter): mean value bias parameter\n",
    "        bias_sigma (nn.Parameter): std value bias parameter\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int, \n",
    "        out_features: int, \n",
    "        std_init: float = 0.5,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(\n",
    "            torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"weight_epsilon\", torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.Tensor(out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reset trainable network parameters (factorized gaussian noise).\"\"\"\n",
    "        mu_range = 1 / math.sqrt(self.in_features)\n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.in_features)\n",
    "        )\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.out_features)\n",
    "        )\n",
    "\n",
    "    def reset_noise(self):\n",
    "        \"\"\"Make new noise.\"\"\"\n",
    "        epsilon_in = self.scale_noise(self.in_features)\n",
    "        epsilon_out = self.scale_noise(self.out_features)\n",
    "\n",
    "        # outer product\n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(epsilon_out)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\n",
    "        \n",
    "        We don't use separate statements on train / eval mode.\n",
    "        It doesn't show remarkable difference of performance.\n",
    "        \"\"\"\n",
    "        return F.linear(\n",
    "            x,\n",
    "            self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
    "            self.bias_mu + self.bias_sigma * self.bias_epsilon,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale_noise(size: int) -> torch.Tensor:\n",
    "        \"\"\"Set scale to make noise (factorized gaussian noise).\"\"\"\n",
    "        x = torch.randn(size)\n",
    "\n",
    "        return x.sign().mul(x.abs().sqrt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoisyNet + DuelingNet + Categorical DQN\n",
    "\n",
    "#### NoisyNet + DuelingNet\n",
    "\n",
    "NoisyLinear is employed for the last two layers of advantage and value layers. The noise should be reset at evey update step.\n",
    "\n",
    "#### DuelingNet + Categorical DQN\n",
    "\n",
    "The dueling network architecture is adapted for use with return distributions. The network has a shared representation, which is then fed into a value stream with atom_size outputs, and into an advantage stream with atom_size × out_dim outputs. For each atom, the value and advantage streams are aggregated, as in dueling DQN, and then passed through a softmax layer to obtain the normalized parametric distributions used to estimate the returns’ distributions.\n",
    "\n",
    "```\n",
    "        advantage = self.advantage_layer(adv_hid).view(-1, self.out_dim, self.atom_size)\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "```\n",
    "\n",
    "(Please see *04.dueling.ipynb*, *05.noisy_net.ipynb*, *06.categorical_dqn.ipynb* for detailed description of each component's network architecture.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_dim: int, \n",
    "        out_dim: int, \n",
    "        atom_size: int, \n",
    "        support: torch.Tensor\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.support = support\n",
    "        self.out_dim = out_dim\n",
    "        self.atom_size = atom_size\n",
    "\n",
    "        # set common feature layer\n",
    "        self.feature_layer = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # set advantage layer\n",
    "        self.advantage_hidden_layer = NoisyLinear(128, 128)\n",
    "        self.advantage_layer = NoisyLinear(128, out_dim * atom_size)\n",
    "\n",
    "        # set value layer\n",
    "        self.value_hidden_layer = NoisyLinear(128, 128)\n",
    "        self.value_layer = NoisyLinear(128, atom_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        dist = self.dist(x)\n",
    "        q = torch.sum(dist * self.support, dim=2)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def dist(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Get distribution for atoms.\"\"\"\n",
    "        feature = self.feature_layer(x)\n",
    "        adv_hid = F.relu(self.advantage_hidden_layer(feature))\n",
    "        val_hid = F.relu(self.value_hidden_layer(feature))\n",
    "        \n",
    "        advantage = self.advantage_layer(adv_hid).view(\n",
    "            -1, self.out_dim, self.atom_size\n",
    "        )\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "        dist = dist.clamp(min=1e-3)  # for avoiding nans\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        \"\"\"Reset all noisy layers.\"\"\"\n",
    "        self.advantage_hidden_layer.reset_noise()\n",
    "        self.advantage_layer.reset_noise()\n",
    "        self.value_hidden_layer.reset_noise()\n",
    "        self.value_layer.reset_noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>90909.09375</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1762</td>\n",
       "      <td>0</td>\n",
       "      <td>125000.00000</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1068</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.00000</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>166666.65625</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2126</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dur  proto  service  state  spkts  dpkts  sbytes  dbytes  \\\n",
       "0  0.000011    117        0      4      2      0     496       0   \n",
       "1  0.000008    117        0      4      2      0    1762       0   \n",
       "2  0.000005    117        0      4      2      0    1068       0   \n",
       "3  0.000006    117        0      4      2      0     900       0   \n",
       "4  0.000010    117        0      4      2      0    2126       0   \n",
       "\n",
       "           rate  sttl  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
       "0   90909.09375   254  ...                 1               2         False   \n",
       "1  125000.00000   254  ...                 1               2         False   \n",
       "2  200000.00000   254  ...                 1               3         False   \n",
       "3  166666.65625   254  ...                 1               3         False   \n",
       "4  100000.00000   254  ...                 1               3         False   \n",
       "\n",
       "   ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
       "0           0                 0           1           2            False   \n",
       "1           0                 0           1           2            False   \n",
       "2           0                 0           1           3            False   \n",
       "3           0                 0           2           3            False   \n",
       "4           0                 0           2           3            False   \n",
       "\n",
       "   attack_cat  label  \n",
       "0      normal  False  \n",
       "1      normal  False  \n",
       "2      normal  False  \n",
       "3      normal  False  \n",
       "4      normal  False  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_feather(\"../datasets/unsw-nb15/UNSW_NB15_training-set.feather\")\n",
    "df_test = pd.read_feather(\"../datasets/unsw-nb15/UNSW_NB15_testing-set.feather\")\n",
    "# data = pd.concat([nslkdd_test], ignore_index=True)\n",
    "# print(len(data.columns))\n",
    "\n",
    "df_train.proto = pd.Categorical(df_train.proto).codes\n",
    "df_train.state = pd.Categorical(df_train.state).codes\n",
    "df_train.service = pd.Categorical(df_train.service).codes\n",
    "\n",
    "\n",
    "df_test.proto = pd.Categorical(df_test.proto).codes\n",
    "df_test.service = pd.Categorical(df_test.service).codes\n",
    "df_test.state = pd.Categorical(df_test.state).codes\n",
    "\n",
    "\n",
    "# nslkdd_train = pd.get_dummies(nslkdd_train,columns=['proto' ,'service', 'state'])\n",
    "# nslkdd_test = pd.get_dummies(nslkdd_test, columns=['proto' ,'service', 'state'])\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53946 entries, 0 to 53945\n",
      "Data columns (total 44 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   dur                53946 non-null  float32 \n",
      " 1   proto              53946 non-null  int16   \n",
      " 2   service            53946 non-null  int8    \n",
      " 3   state              53946 non-null  int8    \n",
      " 4   spkts              53946 non-null  int16   \n",
      " 5   dpkts              53946 non-null  int16   \n",
      " 6   sbytes             53946 non-null  int32   \n",
      " 7   dbytes             53946 non-null  int32   \n",
      " 8   rate               53946 non-null  float32 \n",
      " 9   sttl               53946 non-null  int16   \n",
      " 10  dttl               53946 non-null  int16   \n",
      " 11  sload              53946 non-null  float32 \n",
      " 12  dload              53946 non-null  float32 \n",
      " 13  sloss              53946 non-null  int16   \n",
      " 14  dloss              53946 non-null  int16   \n",
      " 15  sinpkt             53946 non-null  float32 \n",
      " 16  dinpkt             53946 non-null  float32 \n",
      " 17  sjit               53946 non-null  float32 \n",
      " 18  djit               53946 non-null  float32 \n",
      " 19  swin               53946 non-null  int16   \n",
      " 20  stcpb              53946 non-null  int64   \n",
      " 21  dtcpb              53946 non-null  int64   \n",
      " 22  dwin               53946 non-null  int16   \n",
      " 23  tcprtt             53946 non-null  float32 \n",
      " 24  synack             53946 non-null  float32 \n",
      " 25  ackdat             53946 non-null  float32 \n",
      " 26  smean              53946 non-null  int16   \n",
      " 27  dmean              53946 non-null  int16   \n",
      " 28  trans_depth        53946 non-null  int16   \n",
      " 29  response_body_len  53946 non-null  int32   \n",
      " 30  ct_srv_src         53946 non-null  int8    \n",
      " 31  ct_state_ttl       53946 non-null  int8    \n",
      " 32  ct_dst_ltm         53946 non-null  int8    \n",
      " 33  ct_src_dport_ltm   53946 non-null  int8    \n",
      " 34  ct_dst_sport_ltm   53946 non-null  int8    \n",
      " 35  ct_dst_src_ltm     53946 non-null  int8    \n",
      " 36  is_ftp_login       53946 non-null  bool    \n",
      " 37  ct_ftp_cmd         53946 non-null  int8    \n",
      " 38  ct_flw_http_mthd   53946 non-null  int8    \n",
      " 39  ct_src_ltm         53946 non-null  int8    \n",
      " 40  ct_srv_dst         53946 non-null  int8    \n",
      " 41  is_sm_ips_ports    53946 non-null  bool    \n",
      " 42  attack_cat         53946 non-null  category\n",
      " 43  label              53946 non-null  bool    \n",
      "dtypes: bool(3), category(1), float32(11), int16(12), int32(3), int64(2), int8(12)\n",
      "memory usage: 5.8 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_state_ttl</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.00000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>5.394600e+04</td>\n",
       "      <td>5.394600e+04</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.022179</td>\n",
       "      <td>111.51001</td>\n",
       "      <td>1.514459</td>\n",
       "      <td>3.081934</td>\n",
       "      <td>25.869759</td>\n",
       "      <td>25.967060</td>\n",
       "      <td>1.131112e+04</td>\n",
       "      <td>1.985872e+04</td>\n",
       "      <td>36179.699219</td>\n",
       "      <td>150.903681</td>\n",
       "      <td>...</td>\n",
       "      <td>5.969896</td>\n",
       "      <td>1.035628</td>\n",
       "      <td>3.273533</td>\n",
       "      <td>2.190709</td>\n",
       "      <td>1.486468</td>\n",
       "      <td>3.877711</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.160346</td>\n",
       "      <td>3.807437</td>\n",
       "      <td>5.496330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.918573</td>\n",
       "      <td>9.57705</td>\n",
       "      <td>2.442089</td>\n",
       "      <td>0.607792</td>\n",
       "      <td>161.154040</td>\n",
       "      <td>141.707459</td>\n",
       "      <td>2.072230e+05</td>\n",
       "      <td>1.865964e+05</td>\n",
       "      <td>112020.734375</td>\n",
       "      <td>106.750997</td>\n",
       "      <td>...</td>\n",
       "      <td>7.114324</td>\n",
       "      <td>1.084044</td>\n",
       "      <td>4.594301</td>\n",
       "      <td>3.990693</td>\n",
       "      <td>2.516725</td>\n",
       "      <td>6.775809</td>\n",
       "      <td>0.099564</td>\n",
       "      <td>0.561155</td>\n",
       "      <td>4.909204</td>\n",
       "      <td>7.011688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.004238</td>\n",
       "      <td>111.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.320000e+02</td>\n",
       "      <td>1.780000e+02</td>\n",
       "      <td>24.097402</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.388905</td>\n",
       "      <td>111.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>3.540000e+02</td>\n",
       "      <td>65.447559</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.937146</td>\n",
       "      <td>111.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.158000e+03</td>\n",
       "      <td>1.824000e+03</td>\n",
       "      <td>3289.241089</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.999989</td>\n",
       "      <td>130.00000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10646.000000</td>\n",
       "      <td>11018.000000</td>\n",
       "      <td>1.435577e+07</td>\n",
       "      <td>1.465753e+07</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                dur        proto       service         state         spkts  \\\n",
       "count  53946.000000  53946.00000  53946.000000  53946.000000  53946.000000   \n",
       "mean       1.022179    111.51001      1.514459      3.081934     25.869759   \n",
       "std        3.918573      9.57705      2.442089      0.607792    161.154040   \n",
       "min        0.000000      0.00000      0.000000      0.000000      1.000000   \n",
       "25%        0.004238    111.00000      0.000000      3.000000      4.000000   \n",
       "50%        0.388905    111.00000      0.000000      3.000000     10.000000   \n",
       "75%        0.937146    111.00000      2.000000      3.000000     16.000000   \n",
       "max       59.999989    130.00000     12.000000      6.000000  10646.000000   \n",
       "\n",
       "              dpkts        sbytes        dbytes            rate          sttl  \\\n",
       "count  53946.000000  5.394600e+04  5.394600e+04    53946.000000  53946.000000   \n",
       "mean      25.967060  1.131112e+04  1.985872e+04    36179.699219    150.903681   \n",
       "std      141.707459  2.072230e+05  1.865964e+05   112020.734375    106.750997   \n",
       "min        0.000000  2.400000e+01  0.000000e+00        0.000000      0.000000   \n",
       "25%        2.000000  5.320000e+02  1.780000e+02       24.097402     31.000000   \n",
       "50%        8.000000  9.000000e+02  3.540000e+02       65.447559    254.000000   \n",
       "75%       18.000000  2.158000e+03  1.824000e+03     3289.241089    254.000000   \n",
       "max    11018.000000  1.435577e+07  1.465753e+07  1000000.000000    255.000000   \n",
       "\n",
       "       ...    ct_srv_src  ct_state_ttl    ct_dst_ltm  ct_src_dport_ltm  \\\n",
       "count  ...  53946.000000  53946.000000  53946.000000      53946.000000   \n",
       "mean   ...      5.969896      1.035628      3.273533          2.190709   \n",
       "std    ...      7.114324      1.084044      4.594301          3.990693   \n",
       "min    ...      1.000000      0.000000      1.000000          1.000000   \n",
       "25%    ...      2.000000      0.000000      1.000000          1.000000   \n",
       "50%    ...      4.000000      1.000000      2.000000          1.000000   \n",
       "75%    ...      7.000000      1.000000      3.000000          2.000000   \n",
       "max    ...     63.000000      6.000000     59.000000         59.000000   \n",
       "\n",
       "       ct_dst_sport_ltm  ct_dst_src_ltm    ct_ftp_cmd  ct_flw_http_mthd  \\\n",
       "count      53946.000000    53946.000000  53946.000000      53946.000000   \n",
       "mean           1.486468        3.877711      0.009862          0.160346   \n",
       "std            2.516725        6.775809      0.099564          0.561155   \n",
       "min            1.000000        1.000000      0.000000          0.000000   \n",
       "25%            1.000000        1.000000      0.000000          0.000000   \n",
       "50%            1.000000        2.000000      0.000000          0.000000   \n",
       "75%            1.000000        4.000000      0.000000          0.000000   \n",
       "max           38.000000       63.000000      2.000000         16.000000   \n",
       "\n",
       "         ct_src_ltm    ct_srv_dst  \n",
       "count  53946.000000  53946.000000  \n",
       "mean       3.807437      5.496330  \n",
       "std        4.909204      7.011688  \n",
       "min        1.000000      1.000000  \n",
       "25%        1.000000      1.000000  \n",
       "50%        2.000000      3.000000  \n",
       "75%        4.000000      6.000000  \n",
       "max       60.000000     62.000000  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.info()\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "cicdos2017_features = [\"Init Bwd Win Bytes\",  \"Idle Min\", \"ACK Flag Count\", \"Fwd Packet Length Min\", \"Fwd PSH Flags\"]\n",
    "cicids2017_features = [\"Protocol\", \"Avg Bwd Segment Size\", \"Packet Length Max\", \"Bwd Packet Length Min\", \"Fwd IAT Mean\"]\n",
    "cicddos2019_features = [\"URG Flag Count\", \"Down/Up Ratio\", \"Bwd Packet Length Min\", \"ACK Flag Count\", \"Fwd Packets Length Total\"]\n",
    "nslkdd_features = [\"dst_host_serror_rate\", \"service_private\", \"count\",\"dst_host_count\", \"service_domain_u\", \"flag_REJ\", \"dst_host_diff_srv_rate\"]\n",
    "unsw_features = [\"sttl\", \"ct_state_ttl\", \"service\", \"dload\", \"rate\", \"dmean\", \"dbytes\", \"dur\", \"is_sm_ips_ports\", \"dloss\"]\n",
    "\n",
    "important_features = unsw_features + [\"attack_cat\"] # Adding class for custom environment logic\n",
    "important_features = list(set(important_features))\n",
    "print(len(important_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\AppData\\Local\\Temp\\ipykernel_3848\\2619472776.py:1: FutureWarning: Index.__xor__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__xor__.  Use index.symmetric_difference(other) instead.\n",
      "  removable_features = df_train.columns ^ important_features\n"
     ]
    }
   ],
   "source": [
    "removable_features = df_train.columns ^ important_features\n",
    "print(removable_features.shape)\n",
    "skinny_df_train = df_train.drop(labels=removable_features, axis='columns')\n",
    "skinny_df_test = df_train.drop(labels=removable_features, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53946 entries, 0 to 53945\n",
      "Data columns (total 24 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   proto              53946 non-null  int16   \n",
      " 1   service            53946 non-null  int8    \n",
      " 2   state              53946 non-null  int8    \n",
      " 3   sbytes             53946 non-null  int32   \n",
      " 4   dbytes             53946 non-null  int32   \n",
      " 5   rate               53946 non-null  float32 \n",
      " 6   sttl               53946 non-null  int16   \n",
      " 7   dttl               53946 non-null  int16   \n",
      " 8   sload              53946 non-null  float32 \n",
      " 9   dload              53946 non-null  float32 \n",
      " 10  swin               53946 non-null  int16   \n",
      " 11  synack             53946 non-null  float32 \n",
      " 12  ackdat             53946 non-null  float32 \n",
      " 13  smean              53946 non-null  int16   \n",
      " 14  dmean              53946 non-null  int16   \n",
      " 15  trans_depth        53946 non-null  int16   \n",
      " 16  response_body_len  53946 non-null  int32   \n",
      " 17  ct_srv_src         53946 non-null  int8    \n",
      " 18  ct_state_ttl       53946 non-null  int8    \n",
      " 19  ct_dst_ltm         53946 non-null  int8    \n",
      " 20  ct_dst_sport_ltm   53946 non-null  int8    \n",
      " 21  ct_flw_http_mthd   53946 non-null  int8    \n",
      " 22  ct_src_ltm         53946 non-null  int8    \n",
      " 23  attack_cat         53946 non-null  category\n",
      "dtypes: category(1), float32(5), int16(7), int32(3), int8(8)\n",
      "memory usage: 2.8 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>dload</th>\n",
       "      <th>...</th>\n",
       "      <th>smean</th>\n",
       "      <th>dmean</th>\n",
       "      <th>trans_depth</th>\n",
       "      <th>response_body_len</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_state_ttl</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53946.00000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>5.394600e+04</td>\n",
       "      <td>5.394600e+04</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>5.394600e+04</td>\n",
       "      <td>5.394600e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>5.394600e+04</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "      <td>53946.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>111.51001</td>\n",
       "      <td>1.514459</td>\n",
       "      <td>3.081934</td>\n",
       "      <td>1.131112e+04</td>\n",
       "      <td>1.985872e+04</td>\n",
       "      <td>36179.699219</td>\n",
       "      <td>150.903681</td>\n",
       "      <td>136.375728</td>\n",
       "      <td>4.417520e+07</td>\n",
       "      <td>9.582204e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>168.603752</td>\n",
       "      <td>170.481815</td>\n",
       "      <td>0.137174</td>\n",
       "      <td>2.417378e+03</td>\n",
       "      <td>5.969896</td>\n",
       "      <td>1.035628</td>\n",
       "      <td>3.273533</td>\n",
       "      <td>1.486468</td>\n",
       "      <td>0.160346</td>\n",
       "      <td>3.807437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.57705</td>\n",
       "      <td>2.442089</td>\n",
       "      <td>0.607792</td>\n",
       "      <td>2.072230e+05</td>\n",
       "      <td>1.865964e+05</td>\n",
       "      <td>112020.734375</td>\n",
       "      <td>106.750997</td>\n",
       "      <td>117.269586</td>\n",
       "      <td>1.947021e+08</td>\n",
       "      <td>2.900338e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>242.784273</td>\n",
       "      <td>281.487907</td>\n",
       "      <td>0.661746</td>\n",
       "      <td>4.699383e+04</td>\n",
       "      <td>7.114324</td>\n",
       "      <td>1.084044</td>\n",
       "      <td>4.594301</td>\n",
       "      <td>2.516725</td>\n",
       "      <td>0.561155</td>\n",
       "      <td>4.909204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>111.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.320000e+02</td>\n",
       "      <td>1.780000e+02</td>\n",
       "      <td>24.097402</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>8.323655e+03</td>\n",
       "      <td>1.787040e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>111.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>3.540000e+02</td>\n",
       "      <td>65.447559</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>4.005692e+04</td>\n",
       "      <td>5.700335e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>111.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.158000e+03</td>\n",
       "      <td>1.824000e+03</td>\n",
       "      <td>3289.241089</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>9.414949e+05</td>\n",
       "      <td>2.485340e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>130.00000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.435577e+07</td>\n",
       "      <td>1.465753e+07</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>5.268000e+09</td>\n",
       "      <td>2.082111e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1504.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>5.242880e+06</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             proto       service         state        sbytes        dbytes  \\\n",
       "count  53946.00000  53946.000000  53946.000000  5.394600e+04  5.394600e+04   \n",
       "mean     111.51001      1.514459      3.081934  1.131112e+04  1.985872e+04   \n",
       "std        9.57705      2.442089      0.607792  2.072230e+05  1.865964e+05   \n",
       "min        0.00000      0.000000      0.000000  2.400000e+01  0.000000e+00   \n",
       "25%      111.00000      0.000000      3.000000  5.320000e+02  1.780000e+02   \n",
       "50%      111.00000      0.000000      3.000000  9.000000e+02  3.540000e+02   \n",
       "75%      111.00000      2.000000      3.000000  2.158000e+03  1.824000e+03   \n",
       "max      130.00000     12.000000      6.000000  1.435577e+07  1.465753e+07   \n",
       "\n",
       "                 rate          sttl          dttl         sload         dload  \\\n",
       "count    53946.000000  53946.000000  53946.000000  5.394600e+04  5.394600e+04   \n",
       "mean     36179.699219    150.903681    136.375728  4.417520e+07  9.582204e+05   \n",
       "std     112020.734375    106.750997    117.269586  1.947021e+08  2.900338e+06   \n",
       "min          0.000000      0.000000      0.000000  0.000000e+00  0.000000e+00   \n",
       "25%         24.097402     31.000000     29.000000  8.323655e+03  1.787040e+03   \n",
       "50%         65.447559    254.000000    252.000000  4.005692e+04  5.700335e+03   \n",
       "75%       3289.241089    254.000000    252.000000  9.414949e+05  2.485340e+05   \n",
       "max    1000000.000000    255.000000    253.000000  5.268000e+09  2.082111e+07   \n",
       "\n",
       "       ...         smean         dmean   trans_depth  response_body_len  \\\n",
       "count  ...  53946.000000  53946.000000  53946.000000       5.394600e+04   \n",
       "mean   ...    168.603752    170.481815      0.137174       2.417378e+03   \n",
       "std    ...    242.784273    281.487907      0.661746       4.699383e+04   \n",
       "min    ...     24.000000      0.000000      0.000000       0.000000e+00   \n",
       "25%    ...     57.000000     44.000000      0.000000       0.000000e+00   \n",
       "50%    ...     76.000000     56.000000      0.000000       0.000000e+00   \n",
       "75%    ...    132.000000    121.000000      0.000000       0.000000e+00   \n",
       "max    ...   1504.000000   1500.000000    131.000000       5.242880e+06   \n",
       "\n",
       "         ct_srv_src  ct_state_ttl    ct_dst_ltm  ct_dst_sport_ltm  \\\n",
       "count  53946.000000  53946.000000  53946.000000      53946.000000   \n",
       "mean       5.969896      1.035628      3.273533          1.486468   \n",
       "std        7.114324      1.084044      4.594301          2.516725   \n",
       "min        1.000000      0.000000      1.000000          1.000000   \n",
       "25%        2.000000      0.000000      1.000000          1.000000   \n",
       "50%        4.000000      1.000000      2.000000          1.000000   \n",
       "75%        7.000000      1.000000      3.000000          1.000000   \n",
       "max       63.000000      6.000000     59.000000         38.000000   \n",
       "\n",
       "       ct_flw_http_mthd    ct_src_ltm  \n",
       "count      53946.000000  53946.000000  \n",
       "mean           0.160346      3.807437  \n",
       "std            0.561155      4.909204  \n",
       "min            0.000000      1.000000  \n",
       "25%            0.000000      1.000000  \n",
       "50%            0.000000      2.000000  \n",
       "75%            0.000000      4.000000  \n",
       "max           16.000000     60.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skinny_df_train.info()\n",
    "skinny_df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_dataset_sampler_df(df, train_frac=0.2, val_frac=0.1, test_frac=0.7):\n",
    "    col = df.columns[-1]\n",
    "    print(col)\n",
    "    cols = df.columns[:-1]\n",
    "    print(cols)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    n = vc.iloc[-1]\n",
    "    print(n)\n",
    "    m = vc.iloc[0]\n",
    "    print(m)\n",
    "    print(int(m-n))\n",
    "    initial_cut = df.loc[df[col] == vc.index[0]].sample(n=int(m-n), replace=False)\n",
    "    print(initial_cut.index)\n",
    "    df = df.drop(index=initial_cut.index)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    print(int(n*train_frac))\n",
    "    train_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*train_frac), replace=False))\n",
    "    train_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=train_df.index)\n",
    "\n",
    "    validation_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*val_frac), replace=False))\n",
    "    validation_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=validation_df.index)\n",
    "\n",
    "    test_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*test_frac), replace=False))\n",
    "    test_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=test_df.index)\n",
    "\n",
    "    return train_df[cols], train_df[col], validation_df[cols], validation_df[col], test_df[cols], test_df[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nslkdd_split_df(train_df, test_df):\n",
    "    train_col = train_df.columns[-1]\n",
    "    print(train_col)\n",
    "    train_cols = train_df.columns[:-1]\n",
    "    print(train_cols)\n",
    "    test_col = test_df.columns[-1]\n",
    "    print(test_col)\n",
    "    test_cols = test_df.columns[:-1]\n",
    "    print(test_cols)\n",
    "\n",
    "    return train_df[train_cols], train_df[train_col], test_df[test_cols], test_df[test_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def malicious_benign(df):\n",
    "    print(df['attack_cat'].value_counts())\n",
    "    df['attack_cat'] = df['attack_cat'].astype('object')\n",
    "    atk_idx = df.loc[df['attack_cat'] != \"normal\"].index\n",
    "    df.loc[atk_idx, 'attack_cat'] = 1.0\n",
    "    df.loc[df.index.difference(atk_idx), 'attack_cat'] = 0.0\n",
    "    df['attack_cat'] = df['attack_cat'].astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal            34200\n",
      "exploits           7126\n",
      "fuzzers            4394\n",
      "generic            3640\n",
      "reconnaissance     2469\n",
      "dos                1315\n",
      "shellcode           377\n",
      "analysis            312\n",
      "backdoor             70\n",
      "worms                43\n",
      "Name: attack_cat, dtype: int64\n",
      "\n",
      "normal            34200\n",
      "exploits           7126\n",
      "fuzzers            4394\n",
      "generic            3640\n",
      "reconnaissance     2469\n",
      "dos                1315\n",
      "shellcode           377\n",
      "analysis            312\n",
      "backdoor             70\n",
      "worms                43\n",
      "Name: attack_cat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "malicious_benign(skinny_df_train)\n",
    "print()\n",
    "malicious_benign(skinny_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53946 entries, 0 to 53945\n",
      "Data columns (total 24 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   proto              53946 non-null  int16  \n",
      " 1   service            53946 non-null  int8   \n",
      " 2   state              53946 non-null  int8   \n",
      " 3   sbytes             53946 non-null  int32  \n",
      " 4   dbytes             53946 non-null  int32  \n",
      " 5   rate               53946 non-null  float32\n",
      " 6   sttl               53946 non-null  int16  \n",
      " 7   dttl               53946 non-null  int16  \n",
      " 8   sload              53946 non-null  float32\n",
      " 9   dload              53946 non-null  float32\n",
      " 10  swin               53946 non-null  int16  \n",
      " 11  synack             53946 non-null  float32\n",
      " 12  ackdat             53946 non-null  float32\n",
      " 13  smean              53946 non-null  int16  \n",
      " 14  dmean              53946 non-null  int16  \n",
      " 15  trans_depth        53946 non-null  int16  \n",
      " 16  response_body_len  53946 non-null  int32  \n",
      " 17  ct_srv_src         53946 non-null  int8   \n",
      " 18  ct_state_ttl       53946 non-null  int8   \n",
      " 19  ct_dst_ltm         53946 non-null  int8   \n",
      " 20  ct_dst_sport_ltm   53946 non-null  int8   \n",
      " 21  ct_flw_http_mthd   53946 non-null  int8   \n",
      " 22  ct_src_ltm         53946 non-null  int8   \n",
      " 23  attack_cat         53946 non-null  float32\n",
      "dtypes: float32(6), int16(7), int32(3), int8(8)\n",
      "memory usage: 3.0 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\AppData\\Local\\Temp\\ipykernel_3848\\1986725243.py:1: FutureWarning: Index.__xor__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__xor__.  Use index.symmetric_difference(other) instead.\n",
      "  extra_removables = skinny_df_test.columns ^ skinny_df_train.columns\n"
     ]
    }
   ],
   "source": [
    "extra_removables = skinny_df_test.columns ^ skinny_df_train.columns\n",
    "print(extra_removables)\n",
    "try:\n",
    "    skinny_df_train = skinny_df_train.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    skinny_df_test.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "skinny_df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack_cat\n",
      "Index(['proto', 'service', 'state', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl',\n",
      "       'sload', 'dload', 'swin', 'synack', 'ackdat', 'smean', 'dmean',\n",
      "       'trans_depth', 'response_body_len', 'ct_srv_src', 'ct_state_ttl',\n",
      "       'ct_dst_ltm', 'ct_dst_sport_ltm', 'ct_flw_http_mthd', 'ct_src_ltm'],\n",
      "      dtype='object')\n",
      "attack_cat\n",
      "Index(['proto', 'service', 'state', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl',\n",
      "       'sload', 'dload', 'swin', 'synack', 'ackdat', 'smean', 'dmean',\n",
      "       'trans_depth', 'response_body_len', 'ct_srv_src', 'ct_state_ttl',\n",
      "       'ct_dst_ltm', 'ct_dst_sport_ltm', 'ct_flw_http_mthd', 'ct_src_ltm'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test  = nslkdd_split_df(skinny_df_train, skinny_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()\n",
    "\n",
    "# custom keys -> replace by index\n",
    "\n",
    "x_train = x_train.set_index([pd.Index(range (0, len(x_train)))])\n",
    "y_train = y_train.set_index([pd.Index(range (0, len(y_train)))])\n",
    "x_test = x_test.set_index([pd.Index(range (0, len(x_test)))])\n",
    "y_test = y_test.set_index([pd.Index(range (0, len(y_test)))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rainbow Agent\n",
    "\n",
    "Here is a summary of DQNAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "| ---              | ---                                                  |\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|compute_dqn_loss  | return dqn loss.                                     |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|target_hard_update| hard update from the local model to the target model.|\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|plot              | plot the training progresses.                        |\n",
    "\n",
    "#### Categorical DQN + Double DQN\n",
    "\n",
    "The idea of Double Q-learning is to reduce overestimations by decomposing the max operation in the target into action selection and action evaluation. Here, we use `self.dqn` instead of `self.dqn_target` to obtain the target actions.\n",
    "\n",
    "```\n",
    "        # Categorical DQN + Double DQN\n",
    "        # target_dqn is used when we don't employ double DQN\n",
    "        next_action = self.dqn(next_state).argmax(1)\n",
    "        next_dist = self.dqn_target.dist(next_state)\n",
    "        next_dist = next_dist[range(self.batch_size), next_action]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (PrioritizedReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including \n",
    "                           state, action, reward, next_state, done\n",
    "        v_min (float): min value of support\n",
    "        v_max (float): max value of support\n",
    "        atom_size (int): the unit number of support\n",
    "        support (torch.Tensor): support for categorical dqn\n",
    "        use_n_step (bool): whether to use n_step memory\n",
    "        n_step (int): step number to calculate n-step td error\n",
    "        memory_n (ReplayBuffer): n-step replay buffer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        gamma: float = 0.99,\n",
    "        # PER parameters\n",
    "        alpha: float = 0.2,\n",
    "        beta: float = 0.6,\n",
    "        prior_eps: float = 1e-6,\n",
    "        # Categorical DQN parameters\n",
    "        v_min: float = 0.0,\n",
    "        v_max: float = 200.0,\n",
    "        atom_size: int = 51,\n",
    "        # N-step Learning\n",
    "        n_step: int = 3,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            lr (float): learning rate\n",
    "            gamma (float): discount factor\n",
    "            alpha (float): determines how much prioritization is used\n",
    "            beta (float): determines how much importance sampling is used\n",
    "            prior_eps (float): guarantees every transition can be sampled\n",
    "            v_min (float): min value of support\n",
    "            v_max (float): max value of support\n",
    "            atom_size (int): the unit number of support\n",
    "            n_step (int): step number to calculate n-step td error\n",
    "        \"\"\"\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.n\n",
    "        \n",
    "        self.env = env\n",
    "        self.batch_size = batch_size\n",
    "        self.target_update = target_update\n",
    "        self.gamma = gamma\n",
    "        # NoisyNet: All attributes related to epsilon are removed\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "        \n",
    "        # PER\n",
    "        # memory for 1-step Learning\n",
    "        self.beta = beta\n",
    "        self.prior_eps = prior_eps\n",
    "        self.memory = PrioritizedReplayBuffer(\n",
    "            obs_dim, memory_size, batch_size, alpha=alpha\n",
    "        )\n",
    "        \n",
    "        # memory for N-step Learning\n",
    "        self.use_n_step = True if n_step > 1 else False\n",
    "        if self.use_n_step:\n",
    "            self.n_step = n_step\n",
    "            self.memory_n = ReplayBuffer(\n",
    "                obs_dim, memory_size, batch_size, n_step=n_step, gamma=gamma\n",
    "            )\n",
    "            \n",
    "        # Categorical DQN parameters\n",
    "        self.v_min = v_min\n",
    "        self.v_max = v_max\n",
    "        self.atom_size = atom_size\n",
    "        self.support = torch.linspace(\n",
    "            self.v_min, self.v_max, self.atom_size\n",
    "        ).to(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target = Network(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # NoisyNet: no epsilon greedy action selection\n",
    "        selected_action = self.dqn(\n",
    "            torch.FloatTensor(state).to(self.device)\n",
    "        ).argmax()\n",
    "        selected_action = selected_action.detach().cpu().numpy()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        \n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, done, _ = self.env.step(action)\n",
    "\n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            \n",
    "            # N-step transition\n",
    "            if self.use_n_step:\n",
    "                one_step_transition = self.memory_n.store(*self.transition)\n",
    "            # 1-step transition\n",
    "            else:\n",
    "                one_step_transition = self.transition\n",
    "\n",
    "            # add a single step transition\n",
    "            if one_step_transition:\n",
    "                self.memory.store(*one_step_transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        # PER needs beta to calculate weights\n",
    "        samples = self.memory.sample_batch(self.beta)\n",
    "        weights = torch.FloatTensor(\n",
    "            samples[\"weights\"].reshape(-1, 1)\n",
    "        ).to(self.device)\n",
    "        indices = samples[\"indices\"]\n",
    "        \n",
    "        # 1-step Learning loss\n",
    "        elementwise_loss = self._compute_dqn_loss(samples, self.gamma)\n",
    "        \n",
    "        # PER: importance sampling before average\n",
    "        loss = torch.mean(elementwise_loss * weights)\n",
    "        \n",
    "        # N-step Learning loss\n",
    "        # we are gonna combine 1-step loss and n-step loss so as to\n",
    "        # prevent high-variance. The original rainbow employs n-step loss only.\n",
    "        if self.use_n_step:\n",
    "            gamma = self.gamma ** self.n_step\n",
    "            samples = self.memory_n.sample_batch_from_idxs(indices)\n",
    "            elementwise_loss_n_loss = self._compute_dqn_loss(samples, gamma)\n",
    "            elementwise_loss += elementwise_loss_n_loss\n",
    "            \n",
    "            # PER: importance sampling before average\n",
    "            loss = torch.mean(elementwise_loss * weights)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(self.dqn.parameters(), 10.0)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # PER: update priorities\n",
    "        loss_for_prior = elementwise_loss.detach().cpu().numpy()\n",
    "        new_priorities = loss_for_prior + self.prior_eps\n",
    "        self.memory.update_priorities(indices, new_priorities)\n",
    "        \n",
    "        # NoisyNet: reset noise\n",
    "        self.dqn.reset_noise()\n",
    "        self.dqn_target.reset_noise()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        update_cnt = 0\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "            # NoisyNet: removed decrease of epsilon\n",
    "            \n",
    "            # PER: increase beta\n",
    "            fraction = min(frame_idx / num_frames, 1.0)\n",
    "            self.beta = self.beta + fraction * (1.0 - self.beta)\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state = self.env.reset()\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses)\n",
    "                \n",
    "        self.env.close()\n",
    "                \n",
    "    def test(self) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        TP, FP, TN, FN = 0,0,0,0\n",
    "        # for recording a video\n",
    "        naive_env = self.env\n",
    "        self.env = IdsEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)\n",
    "\n",
    "        action = self.env.reset()\n",
    "        done = False\n",
    "        count = 0\n",
    "        try:\n",
    "            while True:\n",
    "                     \n",
    "                done = False\n",
    "                while not done:\n",
    "                    count += 1\n",
    "                    action = self.select_action(action)\n",
    "                    next_action, rew, done, info = self.env.step(action)\n",
    "                    action = next_action\n",
    "                    label = info['label']\n",
    "                    if label == 0 and rew > 0:\n",
    "                        TP += 1\n",
    "                    if label == 0 and rew == 0:\n",
    "                        FP += 1\n",
    "                    if label == 1 and rew > 0:\n",
    "                        TN += 1\n",
    "                    if label == 1 and rew == 0:\n",
    "                        FN += 1\n",
    "        except StopIteration:\n",
    "            accuracy = (float(TP + TN) / (TP + FP + FN + TN)) \n",
    "            precision = (float(TP) / (TP + FP))\n",
    "            try:\n",
    "                recall = (float(TP) / (TP + FN)) # = TPR = Sensitivity\n",
    "            except:\n",
    "                recall = 0\n",
    "            try:\n",
    "                FPR = (float(FP) / (TN + FP)) # 1 - specificity\n",
    "            except:\n",
    "                FPR = 0\n",
    "            try:\n",
    "                f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "            except:\n",
    "                f1_score = 0\n",
    "            print()\n",
    "            print('validation done...')\n",
    "            print('Accuracy: {0}%'.format(accuracy * 100))\n",
    "            print('Precision: {0}%'.format(precision * 100))\n",
    "            print('Recall/TPR/Sensitivity: {0}%'.format(recall * 100))\n",
    "            print('FPR: {0}%'.format(FPR * 100))\n",
    "            print('F1 score: {0}'.format(f1_score))\n",
    "            print('count: {0}'.format(count))\n",
    "        self.env.close()\n",
    "        \n",
    "        # reset\n",
    "        self.env = naive_env\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray], gamma: float) -> torch.Tensor:\n",
    "        \"\"\"Return categorical dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"]).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "        \n",
    "        # Categorical DQN algorithm\n",
    "        delta_z = float(self.v_max - self.v_min) / (self.atom_size - 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Double DQN\n",
    "            next_action = self.dqn(next_state).argmax(1)\n",
    "            next_dist = self.dqn_target.dist(next_state)\n",
    "            next_dist = next_dist[range(self.batch_size), next_action]\n",
    "\n",
    "            t_z = reward + (1 - done) * gamma * self.support\n",
    "            t_z = t_z.clamp(min=self.v_min, max=self.v_max)\n",
    "            b = (t_z - self.v_min) / delta_z\n",
    "            l = b.floor().long()\n",
    "            u = b.ceil().long()\n",
    "\n",
    "            offset = (\n",
    "                torch.linspace(\n",
    "                    0, (self.batch_size - 1) * self.atom_size, self.batch_size\n",
    "                ).long()\n",
    "                .unsqueeze(1)\n",
    "                .expand(self.batch_size, self.atom_size)\n",
    "                .to(self.device)\n",
    "            )\n",
    "\n",
    "            proj_dist = torch.zeros(next_dist.size(), device=self.device)\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (l + offset).view(-1), (next_dist * (u.float() - b)).view(-1)\n",
    "            )\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (u + offset).view(-1), (next_dist * (b - l.float())).view(-1)\n",
    "            )\n",
    "\n",
    "        dist = self.dqn.dist(state)\n",
    "        log_p = torch.log(dist[range(self.batch_size), action])\n",
    "        elementwise_loss = -(proj_dist * log_p).sum(1)\n",
    "\n",
    "        return elementwise_loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores: List[float], \n",
    "        losses: List[float],\n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
    "        plt.plot(scores)\n",
    "        plt.subplot(132)\n",
    "        plt.title('loss')\n",
    "        plt.plot(losses)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "You can see the [code](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py) and [configurations](https://github.com/openai/gym/blob/master/gym/envs/__init__.py#L53) of CartPole-v0 from OpenAI's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdsEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "        # Actions we can take, classify as malicious or non-malicious (later also the correct attack)\n",
    "        # change to 19 if detectiong all different attacks\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "         # All the features we have, len(important_features) - 1 features and 1 label. Label should not be included\n",
    "        self.observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(len(skinny_df_train.columns) - 1,))\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "    \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "        current_label = self.expected_action\n",
    "        obs = self._next_obs()\n",
    "        \n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {'label': current_label}\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y.iloc[next_obs_idx,:])\n",
    "            obs = self.x.iloc[next_obs_idx,:]\n",
    "\n",
    "        else:\n",
    "            obs = self.x.iloc[self.dataset_idx]\n",
    "            self.expected_action = int(self.y.iloc[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "        return obs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "env = IdsEnv(images_per_episode=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\anaconda3\\envs\\MP\\lib\\site-packages\\gym\\core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[777]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 777\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "seed_torch(seed)\n",
    "env.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames = int(1.0e5)\n",
    "memory_size = 100000\n",
    "batch_size = 128\n",
    "target_update = 10000\n",
    "\n",
    "# train\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.train(num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Run the trained agent (1 episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation done...\n",
      "Accuracy: 63.39537297938603%\n",
      "Precision: 100.0%\n",
      "Recall/TPR/Sensitivity: 63.39537297938603%\n",
      "FPR: 0%\n",
      "F1 score: 0.7759751310385514\n",
      "count: 53945\n"
     ]
    }
   ],
   "source": [
    "agent.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
