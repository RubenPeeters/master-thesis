{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt install python-opengl\n",
    "    !apt install ffmpeg\n",
    "    !apt install xvfb\n",
    "    !pip install PyVirtualDisplay==3.0\n",
    "    !pip install gym==0.21.0\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    # Start virtual display\n",
    "    dis = Display(visible=0, size=(400, 400))\n",
    "    dis.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Noisy Networks for Exploration\n",
    "\n",
    "[M. Fortunato et al., \"Noisy Networks for Exploration.\" arXiv preprint arXiv:1706.10295, 2017.](https://arxiv.org/pdf/1706.10295.pdf)\n",
    "\n",
    "\n",
    "NoisyNet is an exploration method that learns perturbations of the network weights to drive exploration. The key insight is that a single change to the weight vector can induce a consistent, and potentially very complex, state-dependent change in policy over multiple time steps.\n",
    "\n",
    "Firstly, let's take a look into a linear layer of a neural network with $p$ inputs and $q$ outputs, represented by\n",
    "\n",
    "$$\n",
    "y = wx + b,\n",
    "$$\n",
    "\n",
    "where $x \\in \\mathbb{R}^p$ is the layer input, $w \\in \\mathbb{R}^{q \\times p}$, and $b \\in \\mathbb{R}$ the bias.\n",
    "\n",
    "The corresponding noisy linear layer is defined as:\n",
    "\n",
    "$$\n",
    "y = (\\mu^w + \\sigma^w \\odot \\epsilon^w) x + \\mu^b + \\sigma^b \\odot \\epsilon^b,\n",
    "$$\n",
    "\n",
    "where $\\mu^w + \\sigma^w \\odot \\epsilon^w$ and $\\mu^b + \\sigma^b \\odot \\epsilon^b$ replace $w$ and $b$ in the first linear layer equation. The parameters $\\mu^w \\in \\mathbb{R}^{q \\times p}, \\mu^b \\in \\mathbb{R}^q, \\sigma^w \\in \\mathbb{R}^{q \\times p}$ and $\\sigma^b \\in \\mathbb{R}^q$ are learnable, whereas $\\epsilon^w \\in \\mathbb{R}^{q \\times p}$ and $\\epsilon^b \\in \\mathbb{R}^q$ are noise random variables which can be generated by one of the following two ways:\n",
    "\n",
    "1. **Independent Gaussian noise**: the noise applied to each weight and bias is independent, where each random noise entry is drawn from a unit Gaussian distribution. This means that for each noisy linear layer, there are $pq + q$ noise variables (for $p$ inputs to the layer and $q$ outputs).\n",
    "2. **Factorised Gaussian noise:** This is a more computationally efficient way. It produces 2 random Gaussian noise vectors ($p, q$) and makes $pq + q$ noise entries by outer product as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\epsilon_{i,j}^w &= f(\\epsilon_i) f(\\epsilon_j),\\\\\n",
    "\\epsilon_{j}^b &= f(\\epsilon_i),\\\\\n",
    "\\text{where } f(x) &= sgn(x) \\sqrt{|x|}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In all experiements of the paper, the authors used Factorised Gaussian noise, so we will go for it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Please see *01.dqn.ipynb* for detailed description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "\n",
    "    def store(\n",
    "        self,\n",
    "        obs: np.ndarray,\n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ):\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "        return dict(obs=self.obs_buf[idxs],\n",
    "                    next_obs=self.next_obs_buf[idxs],\n",
    "                    acts=self.acts_buf[idxs],\n",
    "                    rews=self.rews_buf[idxs],\n",
    "                    done=self.done_buf[idxs])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Layer\n",
    "\n",
    "**References:**\n",
    "- https://github.com/higgsfield/RL-Adventure/blob/master/5.noisy%20dqn.ipynb\n",
    "- https://github.com/Kaixhin/Rainbow/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    \"\"\"Noisy linear module for NoisyNet.\n",
    "    \n",
    "    Attributes:\n",
    "        in_features (int): input size of linear module\n",
    "        out_features (int): output size of linear module\n",
    "        std_init (float): initial std value\n",
    "        weight_mu (nn.Parameter): mean value weight parameter\n",
    "        weight_sigma (nn.Parameter): std value weight parameter\n",
    "        bias_mu (nn.Parameter): mean value bias parameter\n",
    "        bias_sigma (nn.Parameter): std value bias parameter\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, std_init: float = 0.5):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(\n",
    "            torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"weight_epsilon\", torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.Tensor(out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reset trainable network parameters (factorized gaussian noise).\"\"\"\n",
    "        mu_range = 1 / math.sqrt(self.in_features)\n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.in_features)\n",
    "        )\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.out_features)\n",
    "        )\n",
    "\n",
    "    def reset_noise(self):\n",
    "        \"\"\"Make new noise.\"\"\"\n",
    "        epsilon_in = self.scale_noise(self.in_features)\n",
    "        epsilon_out = self.scale_noise(self.out_features)\n",
    "\n",
    "        # outer product\n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(epsilon_out)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\n",
    "        \n",
    "        We don't use separate statements on train / eval mode.\n",
    "        It doesn't show remarkable difference of performance.\n",
    "        \"\"\"\n",
    "        return F.linear(\n",
    "            x,\n",
    "            self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
    "            self.bias_mu + self.bias_sigma * self.bias_epsilon,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale_noise(size: int) -> torch.Tensor:\n",
    "        \"\"\"Set scale to make noise (factorized gaussian noise).\"\"\"\n",
    "        x = torch.randn(size)\n",
    "\n",
    "        return x.sign().mul(x.abs().sqrt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Network\n",
    "\n",
    "We use NoisyLinear for the last two FC layers, and there is a method to reset noise at every step.\n",
    "These are the only differences from the example of *01.dqn.ipynb*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.feature = nn.Linear(in_dim, 128)\n",
    "        self.noisy_layer1 = NoisyLinear(128, 128)\n",
    "        self.noisy_layer2 = NoisyLinear(128, out_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        feature = F.relu(self.feature(x))\n",
    "        hidden = F.relu(self.noisy_layer1(feature))\n",
    "        out = self.noisy_layer2(hidden)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        \"\"\"Reset all noisy layers.\"\"\"\n",
    "        self.noisy_layer1.reset_noise()\n",
    "        self.noisy_layer2.reset_noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0         0        491          0     0               0       0    0   \n",
       "1         0        146          0     0               0       0    0   \n",
       "2         0          0          0     0               0       0    0   \n",
       "3         0        232       8153     0               0       0    0   \n",
       "4         0        199        420     0               0       0    0   \n",
       "\n",
       "   num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_RSTO  \\\n",
       "0                  0          0                0  ...         0          0   \n",
       "1                  0          0                0  ...         0          0   \n",
       "2                  0          0                0  ...         0          0   \n",
       "3                  0          1                0  ...         0          0   \n",
       "4                  0          1                0  ...         0          0   \n",
       "\n",
       "   flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
       "0            0          0        0        0        0        0        1   \n",
       "1            0          0        0        0        0        0        1   \n",
       "2            0          0        1        0        0        0        0   \n",
       "3            0          0        0        0        0        0        1   \n",
       "4            0          0        0        0        0        0        1   \n",
       "\n",
       "   flag_SH  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train = pd.read_feather(\"./datasets/nsl-kdd/KDDTrain.feather\")\n",
    "nslkdd_test = pd.read_feather(\"./datasets/nsl-kdd/KDDTest.feather\")\n",
    "# data = pd.concat([nslkdd_test], ignore_index=True)\n",
    "# print(len(data.columns))\n",
    "\n",
    "# nslkdd_train.protocol_type = pd.Categorical(nslkdd_train.protocol_type).codes\n",
    "# nslkdd_train.service = pd.Categorical(nslkdd_train.service).codes\n",
    "# nslkdd_train.flag = pd.Categorical(nslkdd_train.flag).codes\n",
    "\n",
    "\n",
    "# nslkdd_test.protocol_type = pd.Categorical(nslkdd_test.protocol_type).codes\n",
    "# nslkdd_test.service = pd.Categorical(nslkdd_test.service).codes\n",
    "# nslkdd_test.flag = pd.Categorical(nslkdd_test.flag).codes\n",
    "\n",
    "\n",
    "nslkdd_train = pd.get_dummies(nslkdd_train,columns=['protocol_type' ,'service', 'flag'])\n",
    "nslkdd_test = pd.get_dummies(nslkdd_test, columns=['protocol_type' ,'service', 'flag'])\n",
    "nslkdd_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Columns: 123 entries, duration to flag_SH\n",
      "dtypes: float64(15), int64(23), object(1), uint8(84)\n",
      "memory usage: 47.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125973.00000</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>125973.00000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>287.14465</td>\n",
       "      <td>4.556674e+04</td>\n",
       "      <td>1.977911e+04</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.204409</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.395736</td>\n",
       "      <td>0.279250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08917</td>\n",
       "      <td>0.012399</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.019218</td>\n",
       "      <td>0.276655</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.594929</td>\n",
       "      <td>0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2604.51531</td>\n",
       "      <td>5.870331e+06</td>\n",
       "      <td>4.021269e+06</td>\n",
       "      <td>0.014086</td>\n",
       "      <td>0.253530</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>2.149968</td>\n",
       "      <td>0.045239</td>\n",
       "      <td>0.489010</td>\n",
       "      <td>23.942042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28499</td>\n",
       "      <td>0.110661</td>\n",
       "      <td>0.028583</td>\n",
       "      <td>0.137292</td>\n",
       "      <td>0.447346</td>\n",
       "      <td>0.053750</td>\n",
       "      <td>0.031736</td>\n",
       "      <td>0.019719</td>\n",
       "      <td>0.490908</td>\n",
       "      <td>0.046332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.760000e+02</td>\n",
       "      <td>5.160000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42908.00000</td>\n",
       "      <td>1.379964e+09</td>\n",
       "      <td>1.309937e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes           land  \\\n",
       "count  125973.00000  1.259730e+05  1.259730e+05  125973.000000   \n",
       "mean      287.14465  4.556674e+04  1.977911e+04       0.000198   \n",
       "std      2604.51531  5.870331e+06  4.021269e+06       0.014086   \n",
       "min         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "25%         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "50%         0.00000  4.400000e+01  0.000000e+00       0.000000   \n",
       "75%         0.00000  2.760000e+02  5.160000e+02       0.000000   \n",
       "max     42908.00000  1.379964e+09  1.309937e+09       1.000000   \n",
       "\n",
       "       wrong_fragment         urgent            hot  num_failed_logins  \\\n",
       "count   125973.000000  125973.000000  125973.000000      125973.000000   \n",
       "mean         0.022687       0.000111       0.204409           0.001222   \n",
       "std          0.253530       0.014366       2.149968           0.045239   \n",
       "min          0.000000       0.000000       0.000000           0.000000   \n",
       "25%          0.000000       0.000000       0.000000           0.000000   \n",
       "50%          0.000000       0.000000       0.000000           0.000000   \n",
       "75%          0.000000       0.000000       0.000000           0.000000   \n",
       "max          3.000000       3.000000      77.000000           5.000000   \n",
       "\n",
       "           logged_in  num_compromised  ...      flag_REJ      flag_RSTO  \\\n",
       "count  125973.000000    125973.000000  ...  125973.00000  125973.000000   \n",
       "mean        0.395736         0.279250  ...       0.08917       0.012399   \n",
       "std         0.489010        23.942042  ...       0.28499       0.110661   \n",
       "min         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "25%         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "50%         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "75%         1.000000         0.000000  ...       0.00000       0.000000   \n",
       "max         1.000000      7479.000000  ...       1.00000       1.000000   \n",
       "\n",
       "         flag_RSTOS0      flag_RSTR        flag_S0        flag_S1  \\\n",
       "count  125973.000000  125973.000000  125973.000000  125973.000000   \n",
       "mean        0.000818       0.019218       0.276655       0.002897   \n",
       "std         0.028583       0.137292       0.447346       0.053750   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       1.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             flag_S2        flag_S3        flag_SF        flag_SH  \n",
       "count  125973.000000  125973.000000  125973.000000  125973.000000  \n",
       "mean        0.001008       0.000389       0.594929       0.002151  \n",
       "std         0.031736       0.019719       0.490908       0.046332  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       1.000000       0.000000  \n",
       "75%         0.000000       0.000000       1.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 122 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train.info()\n",
    "nslkdd_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_dataset_sampler_df(df, train_frac=0.2, val_frac=0.1, test_frac=0.7):\n",
    "    col = df.columns[-1]\n",
    "    print(col)\n",
    "    cols = df.columns[:-1]\n",
    "    print(cols)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    n = vc.iloc[-1]\n",
    "    print(n)\n",
    "    m = vc.iloc[0]\n",
    "    print(m)\n",
    "    print(int(m-n))\n",
    "    initial_cut = df.loc[df[col] == vc.index[0]].sample(n=int(m-n), replace=False)\n",
    "    print(initial_cut.index)\n",
    "    df = df.drop(index=initial_cut.index)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    print(int(n*train_frac))\n",
    "    train_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*train_frac), replace=False))\n",
    "    train_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=train_df.index)\n",
    "\n",
    "    validation_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*val_frac), replace=False))\n",
    "    validation_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=validation_df.index)\n",
    "\n",
    "    test_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*test_frac), replace=False))\n",
    "    test_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=test_df.index)\n",
    "\n",
    "    return train_df[cols], train_df[col], validation_df[cols], validation_df[col], test_df[cols], test_df[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nslkdd_split_df(train_df, test_df):\n",
    "    train_col = train_df.columns[-1]\n",
    "    print(train_col)\n",
    "    train_cols = train_df.columns[:-1]\n",
    "    print(train_cols)\n",
    "    test_col = test_df.columns[-1]\n",
    "    print(test_col)\n",
    "    test_cols = test_df.columns[:-1]\n",
    "    print(test_cols)\n",
    "\n",
    "    return train_df[train_cols], train_df[train_col], test_df[test_cols], test_df[test_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def malicious_benign(df):\n",
    "    print(df['class'].value_counts())\n",
    "    df['class'] = df['class'].astype('object')\n",
    "    atk_idx = df.loc[df['class'] != \"normal\"].index\n",
    "    df.loc[atk_idx, 'class'] = 1.0\n",
    "    df.loc[df.index.difference(atk_idx), 'class'] = 0.0\n",
    "    df['class'] = df['class'].astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: class, dtype: int64\n",
      "\n",
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "rootkit              13\n",
      "xterm                13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "worm                  2\n",
      "loadmodule            2\n",
      "perl                  2\n",
      "sqlattack             2\n",
      "udpstorm              2\n",
      "phf                   2\n",
      "imap                  1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "malicious_benign(nslkdd_train)\n",
    "print()\n",
    "malicious_benign(nslkdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['service_aol', 'service_harvest', 'service_http_2784',\n",
      "       'service_http_8001', 'service_red_i', 'service_urh_i'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Columns: 117 entries, duration to flag_SH\n",
      "dtypes: float32(1), float64(15), int64(23), uint8(78)\n",
      "memory usage: 46.4 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\AppData\\Local\\Temp\\ipykernel_14244\\366472954.py:1: FutureWarning: Index.__xor__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__xor__.  Use index.symmetric_difference(other) instead.\n",
      "  extra_removables = nslkdd_test.columns ^ nslkdd_train.columns\n"
     ]
    }
   ],
   "source": [
    "extra_removables = nslkdd_test.columns ^ nslkdd_train.columns\n",
    "print(extra_removables)\n",
    "try:\n",
    "    nslkdd_train = nslkdd_train.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    nslkdd_test.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "nslkdd_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag_SH\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR',\n",
      "       'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF'],\n",
      "      dtype='object', length=116)\n",
      "flag_SH\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR',\n",
      "       'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF'],\n",
      "      dtype='object', length=116)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test  = nslkdd_split_df(nslkdd_train, nslkdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()\n",
    "\n",
    "# custom keys -> replace by index\n",
    "\n",
    "x_train = x_train.set_index([pd.Index(range (0, len(x_train)))])\n",
    "y_train = y_train.set_index([pd.Index(range (0, len(y_train)))])\n",
    "x_test = x_test.set_index([pd.Index(range (0, len(x_test)))])\n",
    "y_test = y_test.set_index([pd.Index(range (0, len(y_test)))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN + NoisyNet Agent (w/o DuelingNet)\n",
    "\n",
    "Here is a summary of DQNAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "| ---              | ---                                                  |\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|compute_dqn_loss  | return dqn loss.                                     |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|target_hard_update| hard update from the local model to the target model.|\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|plot              | plot the training progresses.                        |\n",
    "\n",
    "In the paper, NoisyNet is used as a component of the Dueling Network Architecture, which includes Double-DQN and Prioritized Experience Replay. However, we don't implement them to simplify the tutorial. One thing to note is that NoisyNet is an alternertive to $\\epsilon$-greedy method, so all $\\epsilon$ related lines are removed. Please check all comments with *NoisyNet*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (ReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including\n",
    "                           state, action, reward, next_state, done\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        # NoisyNet: All attributes related to epsilon are removed\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.n\n",
    "        \n",
    "        self.env = env\n",
    "        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.target_update = target_update\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # NoisyNet: no epsilon greedy action selection\n",
    "        selected_action = self.dqn(\n",
    "            torch.FloatTensor(state).to(self.device)\n",
    "        ).argmax()\n",
    "        selected_action = selected_action.detach().cpu().numpy()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        \n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, done, _ = self.env.step(action)\n",
    "\n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            self.memory.store(*self.transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        samples = self.memory.sample_batch()\n",
    "\n",
    "        loss = self._compute_dqn_loss(samples)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # NoisyNet: reset noise\n",
    "        self.dqn.reset_noise()\n",
    "        self.dqn_target.reset_noise()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        update_cnt = 0\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "            # NoisyNet: removed decrease of epsilon\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state = self.env.reset()\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses)\n",
    "                \n",
    "        self.env.close()\n",
    "                \n",
    "    def test(self) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        TP, FP, TN, FN = 0,0,0,0\n",
    "        # for recording a video\n",
    "        naive_env = self.env\n",
    "        self.env = IdsEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)\n",
    "\n",
    "        action = self.env.reset()\n",
    "        done = False\n",
    "        count = 0\n",
    "        try:\n",
    "            while True:\n",
    "                     \n",
    "                done = False\n",
    "                while not done:\n",
    "                    count += 1\n",
    "                    action = self.select_action(action)\n",
    "                    next_action, rew, done, info = self.env.step(action)\n",
    "                    action = next_action\n",
    "                    label = info['label']\n",
    "                    if label == 0 and rew > 0:\n",
    "                        TP += 1\n",
    "                    if label == 0 and rew == 0:\n",
    "                        FP += 1\n",
    "                    if label == 1 and rew > 0:\n",
    "                        TN += 1\n",
    "                    if label == 1 and rew == 0:\n",
    "                        FN += 1\n",
    "        except StopIteration:\n",
    "            accuracy = (float(TP + TN) / (TP + FP + FN + TN)) \n",
    "            precision = (float(TP) / (TP + FP))\n",
    "            try:\n",
    "                recall = (float(TP) / (TP + FN)) # = TPR = Sensitivity\n",
    "            except:\n",
    "                recall = 0\n",
    "            try:\n",
    "                FPR = (float(FP) / (TN + FP)) # 1 - specificity\n",
    "            except:\n",
    "                FPR = 0\n",
    "            try:\n",
    "                f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "            except:\n",
    "                f1_score = 0\n",
    "            print()\n",
    "            print('validation done...')\n",
    "            print('Accuracy: {0}%'.format(accuracy * 100))\n",
    "            print('Precision: {0}%'.format(precision * 100))\n",
    "            print('Recall/TPR/Sensitivity: {0}%'.format(recall * 100))\n",
    "            print('FPR: {0}%'.format(FPR * 100))\n",
    "            print('F1 score: {0}'.format(f1_score))\n",
    "            print('count: {0}'.format(count))\n",
    "        self.env.close()\n",
    "        \n",
    "        # reset\n",
    "        self.env = naive_env\n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:\n",
    "        \"\"\"Return dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"].reshape(-1, 1)).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "        \n",
    "        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal\n",
    "        #       = r                       otherwise\n",
    "        curr_q_value = self.dqn(state).gather(1, action)\n",
    "        next_q_value = self.dqn_target(next_state).max(\n",
    "            dim=1, keepdim=True\n",
    "        )[0].detach()\n",
    "        mask = 1 - done\n",
    "        target = (reward + self.gamma * next_q_value * mask).to(self.device)\n",
    "\n",
    "        # calculate dqn loss\n",
    "        loss = F.smooth_l1_loss(curr_q_value, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores: List[float], \n",
    "        losses: List[float], \n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
    "        plt.plot(scores)\n",
    "        plt.subplot(132)\n",
    "        plt.title('loss')\n",
    "        plt.plot(losses)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "You can see the [code](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py) and [configurations](https://github.com/openai/gym/blob/master/gym/envs/__init__.py#L53) of CartPole-v0 from OpenAI's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdsEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "        # Actions we can take, classify as malicious or non-malicious (later also the correct attack)\n",
    "        # change to 19 if detectiong all different attacks\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "         # All the features we have, len(important_features) - 1 features and 1 label. Label should not be included\n",
    "        self.observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(len(nslkdd_train.columns) - 1,))\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "    \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "        current_label = self.expected_action\n",
    "        obs = self._next_obs()\n",
    "        \n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {'label': current_label}\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y.iloc[next_obs_idx,:])\n",
    "            obs = self.x.iloc[next_obs_idx,:]\n",
    "\n",
    "        else:\n",
    "            obs = self.x.iloc[self.dataset_idx]\n",
    "            self.expected_action = int(self.y.iloc[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "        return obs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "env = IdsEnv(images_per_episode=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\anaconda3\\envs\\MP\\lib\\site-packages\\gym\\core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[777]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 777\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "seed_torch(seed)\n",
    "env.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames = int(1.0e5)\n",
    "memory_size = 100000\n",
    "batch_size = 128\n",
    "target_update = 10000\n",
    "\n",
    "# train\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.train(num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Run the trained agent (1 episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation done...\n",
      "Accuracy: 100.0%\n",
      "Precision: 100.0%\n",
      "Recall/TPR/Sensitivity: 100.0%\n",
      "FPR: 0.0%\n",
      "F1 score: 1.0\n",
      "count: 22543\n"
     ]
    }
   ],
   "source": [
    "agent.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22544 entries, 0 to 22543\n",
      "Columns: 116 entries, duration to flag_SF\n",
      "dtypes: float32(1), float64(15), int64(23), uint8(77)\n",
      "memory usage: 8.3 MB\n"
     ]
    }
   ],
   "source": [
    "x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
