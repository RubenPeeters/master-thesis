{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt install python-opengl\n",
    "    !apt install ffmpeg\n",
    "    !apt install xvfb\n",
    "    !pip install PyVirtualDisplay==3.0\n",
    "    !pip install gym==0.21.0\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    # Start virtual display\n",
    "    dis = Display(visible=0, size=(400, 400))\n",
    "    dis.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07. N-Step Learning\n",
    "\n",
    "[R. S. Sutton, \"Learning to predict by the methods of temporal differences.\" Machine learning, 3(1):9–44, 1988.](http://incompleteideas.net/papers/sutton-88-with-erratum.pdf)\n",
    "\n",
    "Q-learning accumulates a single reward and then uses the greedy action at the next step to bootstrap. Alternatively, forward-view multi-step targets can be used (Sutton 1988). We call it Truncated N-Step Return\n",
    "from a given state $S_t$. It is defined as,\n",
    "\n",
    "$$\n",
    "R^{(n)}_t = \\sum_{k=0}^{n-1} \\gamma_t^{(k)} R_{t+k+1}.\n",
    "$$\n",
    "\n",
    "A multi-step variant of DQN is then defined by minimizing the alternative loss,\n",
    "\n",
    "$$\n",
    "(R^{(n)}_t + \\gamma^{(n)}_t \\max_{a'} q_{\\theta}^{-}\n",
    "(S_{t+n}, a')\n",
    "- q_{\\theta}(S_t, A_t))^2.\n",
    "$$\n",
    "\n",
    "Multi-step targets with suitably tuned $n$ often lead to faster learning (Sutton and Barto 1998)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import deque\n",
    "from typing import Deque, Dict, List, Tuple\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer for N-step learning\n",
    "\n",
    "There are a little bit changes in Replay buffer for N-step learning. First, we use `deque` to store the most recent n-step transitions.\n",
    "\n",
    "```python\n",
    "    self.n_step_buffer = deque(maxlen=n_step)\n",
    "```\n",
    "\n",
    "You can see it doesn't actually store a transition in the buffer, unless `n_step_buffer` is full.\n",
    "\n",
    "```\n",
    "    # in store method\n",
    "    if len(self.n_step_buffer) < self.n_step:\n",
    "        return ()\n",
    "```\n",
    "\n",
    "When the length of `n_step_buffer` becomes equal to N, it eventually stores the N-step transition, which is calculated by `_get_n_step_info` method.\n",
    "\n",
    "(Please see *01.dqn.ipynb* for detailed description of the basic replay buffer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        n_step: int = 3, \n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "        \n",
    "        # for N-step Learning\n",
    "        self.n_step_buffer = deque(maxlen=n_step)\n",
    "        self.n_step = n_step\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        transition = (obs, act, rew, next_obs, done)\n",
    "        self.n_step_buffer.append(transition)\n",
    "\n",
    "        # single step transition is not ready\n",
    "        if len(self.n_step_buffer) < self.n_step:\n",
    "            return ()\n",
    "        \n",
    "        # make a n-step transition\n",
    "        rew, next_obs, done = self._get_n_step_info(\n",
    "            self.n_step_buffer, self.gamma\n",
    "        )\n",
    "        obs, act = self.n_step_buffer[0][:2]\n",
    "        \n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "        \n",
    "        return self.n_step_buffer[0]\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        indices = np.random.choice(\n",
    "            self.size, size=self.batch_size, replace=False\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "            obs=self.obs_buf[indices],\n",
    "            next_obs=self.next_obs_buf[indices],\n",
    "            acts=self.acts_buf[indices],\n",
    "            rews=self.rews_buf[indices],\n",
    "            done=self.done_buf[indices],\n",
    "            # for N-step Learning\n",
    "            indices=indices,\n",
    "        )\n",
    "    \n",
    "    def sample_batch_from_idxs(\n",
    "        self, indices: np.ndarray\n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "        # for N-step Learning\n",
    "        return dict(\n",
    "            obs=self.obs_buf[indices],\n",
    "            next_obs=self.next_obs_buf[indices],\n",
    "            acts=self.acts_buf[indices],\n",
    "            rews=self.rews_buf[indices],\n",
    "            done=self.done_buf[indices],\n",
    "        )\n",
    "    \n",
    "    def _get_n_step_info(\n",
    "        self, n_step_buffer: Deque, gamma: float\n",
    "    ) -> Tuple[np.int64, np.ndarray, bool]:\n",
    "        \"\"\"Return n step rew, next_obs, and done.\"\"\"\n",
    "        # info of the last transition\n",
    "        rew, next_obs, done = n_step_buffer[-1][-3:]\n",
    "\n",
    "        for transition in reversed(list(n_step_buffer)[:-1]):\n",
    "            r, n_o, d = transition[-3:]\n",
    "\n",
    "            rew = r + gamma * rew * (1 - d)\n",
    "            next_obs, done = (n_o, d) if d else (next_obs, done)\n",
    "\n",
    "        return rew, next_obs, done\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network\n",
    "\n",
    "We are going to use a simple network architecture with three fully connected layers and two non-linearity functions (ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0         0        491          0     0               0       0    0   \n",
       "1         0        146          0     0               0       0    0   \n",
       "2         0          0          0     0               0       0    0   \n",
       "3         0        232       8153     0               0       0    0   \n",
       "4         0        199        420     0               0       0    0   \n",
       "\n",
       "   num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_RSTO  \\\n",
       "0                  0          0                0  ...         0          0   \n",
       "1                  0          0                0  ...         0          0   \n",
       "2                  0          0                0  ...         0          0   \n",
       "3                  0          1                0  ...         0          0   \n",
       "4                  0          1                0  ...         0          0   \n",
       "\n",
       "   flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
       "0            0          0        0        0        0        0        1   \n",
       "1            0          0        0        0        0        0        1   \n",
       "2            0          0        1        0        0        0        0   \n",
       "3            0          0        0        0        0        0        1   \n",
       "4            0          0        0        0        0        0        1   \n",
       "\n",
       "   flag_SH  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train = pd.read_feather(\"./datasets/nsl-kdd/KDDTrain.feather\")\n",
    "nslkdd_test = pd.read_feather(\"./datasets/nsl-kdd/KDDTest.feather\")\n",
    "# data = pd.concat([nslkdd_test], ignore_index=True)\n",
    "# print(len(data.columns))\n",
    "\n",
    "# nslkdd_train.protocol_type = pd.Categorical(nslkdd_train.protocol_type).codes\n",
    "# nslkdd_train.service = pd.Categorical(nslkdd_train.service).codes\n",
    "# nslkdd_train.flag = pd.Categorical(nslkdd_train.flag).codes\n",
    "\n",
    "\n",
    "# nslkdd_test.protocol_type = pd.Categorical(nslkdd_test.protocol_type).codes\n",
    "# nslkdd_test.service = pd.Categorical(nslkdd_test.service).codes\n",
    "# nslkdd_test.flag = pd.Categorical(nslkdd_test.flag).codes\n",
    "\n",
    "\n",
    "nslkdd_train = pd.get_dummies(nslkdd_train,columns=['protocol_type' ,'service', 'flag'])\n",
    "nslkdd_test = pd.get_dummies(nslkdd_test, columns=['protocol_type' ,'service', 'flag'])\n",
    "nslkdd_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Columns: 123 entries, duration to flag_SH\n",
      "dtypes: float64(15), int64(23), object(1), uint8(84)\n",
      "memory usage: 47.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125973.00000</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>125973.00000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>287.14465</td>\n",
       "      <td>4.556674e+04</td>\n",
       "      <td>1.977911e+04</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.204409</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.395736</td>\n",
       "      <td>0.279250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08917</td>\n",
       "      <td>0.012399</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.019218</td>\n",
       "      <td>0.276655</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.594929</td>\n",
       "      <td>0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2604.51531</td>\n",
       "      <td>5.870331e+06</td>\n",
       "      <td>4.021269e+06</td>\n",
       "      <td>0.014086</td>\n",
       "      <td>0.253530</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>2.149968</td>\n",
       "      <td>0.045239</td>\n",
       "      <td>0.489010</td>\n",
       "      <td>23.942042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28499</td>\n",
       "      <td>0.110661</td>\n",
       "      <td>0.028583</td>\n",
       "      <td>0.137292</td>\n",
       "      <td>0.447346</td>\n",
       "      <td>0.053750</td>\n",
       "      <td>0.031736</td>\n",
       "      <td>0.019719</td>\n",
       "      <td>0.490908</td>\n",
       "      <td>0.046332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.760000e+02</td>\n",
       "      <td>5.160000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42908.00000</td>\n",
       "      <td>1.379964e+09</td>\n",
       "      <td>1.309937e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes           land  \\\n",
       "count  125973.00000  1.259730e+05  1.259730e+05  125973.000000   \n",
       "mean      287.14465  4.556674e+04  1.977911e+04       0.000198   \n",
       "std      2604.51531  5.870331e+06  4.021269e+06       0.014086   \n",
       "min         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "25%         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "50%         0.00000  4.400000e+01  0.000000e+00       0.000000   \n",
       "75%         0.00000  2.760000e+02  5.160000e+02       0.000000   \n",
       "max     42908.00000  1.379964e+09  1.309937e+09       1.000000   \n",
       "\n",
       "       wrong_fragment         urgent            hot  num_failed_logins  \\\n",
       "count   125973.000000  125973.000000  125973.000000      125973.000000   \n",
       "mean         0.022687       0.000111       0.204409           0.001222   \n",
       "std          0.253530       0.014366       2.149968           0.045239   \n",
       "min          0.000000       0.000000       0.000000           0.000000   \n",
       "25%          0.000000       0.000000       0.000000           0.000000   \n",
       "50%          0.000000       0.000000       0.000000           0.000000   \n",
       "75%          0.000000       0.000000       0.000000           0.000000   \n",
       "max          3.000000       3.000000      77.000000           5.000000   \n",
       "\n",
       "           logged_in  num_compromised  ...      flag_REJ      flag_RSTO  \\\n",
       "count  125973.000000    125973.000000  ...  125973.00000  125973.000000   \n",
       "mean        0.395736         0.279250  ...       0.08917       0.012399   \n",
       "std         0.489010        23.942042  ...       0.28499       0.110661   \n",
       "min         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "25%         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "50%         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "75%         1.000000         0.000000  ...       0.00000       0.000000   \n",
       "max         1.000000      7479.000000  ...       1.00000       1.000000   \n",
       "\n",
       "         flag_RSTOS0      flag_RSTR        flag_S0        flag_S1  \\\n",
       "count  125973.000000  125973.000000  125973.000000  125973.000000   \n",
       "mean        0.000818       0.019218       0.276655       0.002897   \n",
       "std         0.028583       0.137292       0.447346       0.053750   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       1.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             flag_S2        flag_S3        flag_SF        flag_SH  \n",
       "count  125973.000000  125973.000000  125973.000000  125973.000000  \n",
       "mean        0.001008       0.000389       0.594929       0.002151  \n",
       "std         0.031736       0.019719       0.490908       0.046332  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       1.000000       0.000000  \n",
       "75%         0.000000       0.000000       1.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 122 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train.info()\n",
    "nslkdd_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_dataset_sampler_df(df, train_frac=0.2, val_frac=0.1, test_frac=0.7):\n",
    "    col = df.columns[-1]\n",
    "    print(col)\n",
    "    cols = df.columns[:-1]\n",
    "    print(cols)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    n = vc.iloc[-1]\n",
    "    print(n)\n",
    "    m = vc.iloc[0]\n",
    "    print(m)\n",
    "    print(int(m-n))\n",
    "    initial_cut = df.loc[df[col] == vc.index[0]].sample(n=int(m-n), replace=False)\n",
    "    print(initial_cut.index)\n",
    "    df = df.drop(index=initial_cut.index)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    print(int(n*train_frac))\n",
    "    train_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*train_frac), replace=False))\n",
    "    train_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=train_df.index)\n",
    "\n",
    "    validation_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*val_frac), replace=False))\n",
    "    validation_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=validation_df.index)\n",
    "\n",
    "    test_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*test_frac), replace=False))\n",
    "    test_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=test_df.index)\n",
    "\n",
    "    return train_df[cols], train_df[col], validation_df[cols], validation_df[col], test_df[cols], test_df[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nslkdd_split_df(train_df, test_df):\n",
    "    train_col = train_df.columns[-1]\n",
    "    print(train_col)\n",
    "    train_cols = train_df.columns[:-1]\n",
    "    print(train_cols)\n",
    "    test_col = test_df.columns[-1]\n",
    "    print(test_col)\n",
    "    test_cols = test_df.columns[:-1]\n",
    "    print(test_cols)\n",
    "\n",
    "    return train_df[train_cols], train_df[train_col], test_df[test_cols], test_df[test_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def malicious_benign(df):\n",
    "    print(df['class'].value_counts())\n",
    "    df['class'] = df['class'].astype('object')\n",
    "    atk_idx = df.loc[df['class'] != \"normal\"].index\n",
    "    df.loc[atk_idx, 'class'] = 1.0\n",
    "    df.loc[df.index.difference(atk_idx), 'class'] = 0.0\n",
    "    df['class'] = df['class'].astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: class, dtype: int64\n",
      "\n",
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "rootkit              13\n",
      "xterm                13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "worm                  2\n",
      "loadmodule            2\n",
      "perl                  2\n",
      "sqlattack             2\n",
      "udpstorm              2\n",
      "phf                   2\n",
      "imap                  1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "malicious_benign(nslkdd_train)\n",
    "print()\n",
    "malicious_benign(nslkdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['service_aol', 'service_harvest', 'service_http_2784',\n",
      "       'service_http_8001', 'service_red_i', 'service_urh_i'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Columns: 117 entries, duration to flag_SH\n",
      "dtypes: float32(1), float64(15), int64(23), uint8(78)\n",
      "memory usage: 46.4 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\AppData\\Local\\Temp\\ipykernel_4068\\366472954.py:1: FutureWarning: Index.__xor__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__xor__.  Use index.symmetric_difference(other) instead.\n",
      "  extra_removables = nslkdd_test.columns ^ nslkdd_train.columns\n"
     ]
    }
   ],
   "source": [
    "extra_removables = nslkdd_test.columns ^ nslkdd_train.columns\n",
    "print(extra_removables)\n",
    "try:\n",
    "    nslkdd_train = nslkdd_train.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    nslkdd_test.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "nslkdd_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag_SH\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR',\n",
      "       'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF'],\n",
      "      dtype='object', length=116)\n",
      "flag_SH\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR',\n",
      "       'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF'],\n",
      "      dtype='object', length=116)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test  = nslkdd_split_df(nslkdd_train, nslkdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()\n",
    "\n",
    "# custom keys -> replace by index\n",
    "\n",
    "x_train = x_train.set_index([pd.Index(range (0, len(x_train)))])\n",
    "y_train = y_train.set_index([pd.Index(range (0, len(y_train)))])\n",
    "x_test = x_test.set_index([pd.Index(range (0, len(x_test)))])\n",
    "y_test = y_test.set_index([pd.Index(range (0, len(y_test)))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Agent + N-step learning Agent\n",
    "\n",
    "Here is a summary of DQNAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "| ---              | ---                                                  |\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|compute_dqn_loss  | return dqn loss.                                     |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|target_hard_update| hard update from the local model to the target model.|\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|plot              | plot the training progresses.                        |\n",
    "\n",
    "We use two buffers: `memory` and `memory_n` for 1-step transitions and n-step transitions respectively. It guarantees that any paired 1-step and n-step transitions have the same indices (See `step` method for more details). Due to the reason, we can sample pairs of transitions from the two buffers once we have indices for samples.\n",
    "\n",
    "```python\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        ...\n",
    "        samples = self.memory.sample_batch()\n",
    "        indices = samples[\"indices\"]\n",
    "        ...\n",
    "        \n",
    "        # N-step Learning loss\n",
    "        if self.use_n_step:\n",
    "            samples = self.memory_n.sample_batch_from_idxs(indices)\n",
    "            ...\n",
    "```\n",
    "\n",
    "One thing to note that  we are gonna combine 1-step loss and n-step loss so as to control high-variance / high-bias trade-off.\n",
    "\n",
    "(Search the comments with *N-step Leaning* to see any difference from DQN.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (ReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        epsilon (float): parameter for epsilon greedy policy\n",
    "        epsilon_decay (float): step size to decrease epsilon\n",
    "        max_epsilon (float): max value of epsilon\n",
    "        min_epsilon (float): min value of epsilon\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including \n",
    "                           state, action, reward, next_state, done\n",
    "        use_n_step (bool): whether to use n_step memory\n",
    "        n_step (int): step number to calculate n-step td error\n",
    "        memory_n (ReplayBuffer): n-step replay buffer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        epsilon_decay: float,\n",
    "        max_epsilon: float = 1.0,\n",
    "        min_epsilon: float = 0.1,\n",
    "        gamma: float = 0.99,\n",
    "        # N-step Learning\n",
    "        n_step: int = 3,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            epsilon_decay (float): step size to decrease epsilon\n",
    "            lr (float): learning rate\n",
    "            max_epsilon (float): max value of epsilon\n",
    "            min_epsilon (float): min value of epsilon\n",
    "            gamma (float): discount factor\n",
    "            n_step (int): step number to calculate n-step td error\n",
    "        \"\"\"\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.n\n",
    "        \n",
    "        self.env = env\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon = max_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.max_epsilon = max_epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.target_update = target_update\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # memory for 1-step Learning\n",
    "        self.memory = ReplayBuffer(\n",
    "            obs_dim, memory_size, batch_size, n_step=1\n",
    "        )\n",
    "        \n",
    "        # memory for N-step Learning\n",
    "        self.use_n_step = True if n_step > 1 else False\n",
    "        if self.use_n_step:\n",
    "            self.n_step = n_step\n",
    "            self.memory_n = ReplayBuffer(\n",
    "                obs_dim, memory_size, batch_size, n_step=n_step, gamma=gamma\n",
    "            )\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # epsilon greedy policy\n",
    "        if self.epsilon > np.random.random():\n",
    "            selected_action = self.env.action_space.sample()\n",
    "        else:\n",
    "            selected_action = self.dqn(\n",
    "                torch.FloatTensor(state).to(self.device)\n",
    "            ).argmax()\n",
    "            selected_action = selected_action.detach().cpu().numpy()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        \n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, done, _ = self.env.step(action)\n",
    "\n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            \n",
    "            # N-step transition\n",
    "            if self.use_n_step:\n",
    "                one_step_transition = self.memory_n.store(*self.transition)\n",
    "            # 1-step transition\n",
    "            else:\n",
    "                one_step_transition = self.transition\n",
    "\n",
    "            # add a single step transition\n",
    "            if one_step_transition:\n",
    "                self.memory.store(*one_step_transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        samples = self.memory.sample_batch()\n",
    "        indices = samples[\"indices\"]\n",
    "        loss = self._compute_dqn_loss(samples, self.gamma)\n",
    "        \n",
    "        # N-step Learning loss\n",
    "        # we are gonna combine 1-step loss and n-step loss so as to\n",
    "        # prevent high-variance.\n",
    "        if self.use_n_step:\n",
    "            samples = self.memory_n.sample_batch_from_idxs(indices)\n",
    "            gamma = self.gamma ** self.n_step\n",
    "            n_loss = self._compute_dqn_loss(samples, gamma)\n",
    "            loss += n_loss\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        update_cnt = 0\n",
    "        epsilons = []\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state = self.env.reset()\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # linearly decrease epsilon\n",
    "                self.epsilon = max(\n",
    "                    self.min_epsilon, self.epsilon - (\n",
    "                        self.max_epsilon - self.min_epsilon\n",
    "                    ) * self.epsilon_decay\n",
    "                )\n",
    "                epsilons.append(self.epsilon)\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses, epsilons)\n",
    "                \n",
    "        self.env.close()\n",
    "\n",
    "    def test(self) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        TP, FP, TN, FN = 0,0,0,0\n",
    "        # for recording a video\n",
    "        naive_env = self.env\n",
    "        self.env = IdsEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)\n",
    "\n",
    "        action = self.env.reset()\n",
    "        done = False\n",
    "        count = 0\n",
    "        try:\n",
    "            while True:\n",
    "\n",
    "                done = False\n",
    "                while not done:\n",
    "                    count += 1\n",
    "                    action = self.select_action(action)\n",
    "                    next_action, rew, done, info = self.env.step(action)\n",
    "                    action = next_action\n",
    "                    label = info['label']\n",
    "                    if label == 0 and rew > 0:\n",
    "                        TP += 1\n",
    "                    if label == 0 and rew == 0:\n",
    "                        FP += 1\n",
    "                    if label == 1 and rew > 0:\n",
    "                        TN += 1\n",
    "                    if label == 1 and rew == 0:\n",
    "                        FN += 1\n",
    "        except StopIteration:\n",
    "            accuracy = (float(TP + TN) / (TP + FP + FN + TN)) \n",
    "            precision = (float(TP) / (TP + FP))\n",
    "            try:\n",
    "                recall = (float(TP) / (TP + FN)) # = TPR = Sensitivity\n",
    "            except:\n",
    "                recall = 0\n",
    "            try:\n",
    "                FPR = (float(FP) / (TN + FP)) # 1 - specificity\n",
    "            except:\n",
    "                FPR = 0\n",
    "            try:\n",
    "                f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "            except:\n",
    "                f1_score = 0\n",
    "            print()\n",
    "            print('validation done...')\n",
    "            print('Accuracy: {0}%'.format(accuracy * 100))\n",
    "            print('Precision: {0}%'.format(precision * 100))\n",
    "            print('Recall/TPR/Sensitivity: {0}%'.format(recall * 100))\n",
    "            print('FPR: {0}%'.format(FPR * 100))\n",
    "            print('F1 score: {0}'.format(f1_score))\n",
    "            print('count: {0}'.format(count))\n",
    "        self.env.close()\n",
    "\n",
    "        # reset\n",
    "        self.env = naive_env\n",
    "        \n",
    "    def _compute_dqn_loss(\n",
    "        self, \n",
    "        samples: Dict[str, np.ndarray], \n",
    "        gamma: float\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Return dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"].reshape(-1, 1)).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "\n",
    "        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal\n",
    "        #       = r                       otherwise\n",
    "        curr_q_value = self.dqn(state).gather(1, action)\n",
    "        next_q_value = self.dqn_target(next_state).max(\n",
    "            dim=1, keepdim=True\n",
    "        )[0].detach()\n",
    "        mask = 1 - done\n",
    "        target = (reward + gamma * next_q_value * mask).to(self.device)\n",
    "\n",
    "        # calculate dqn loss\n",
    "        loss = F.smooth_l1_loss(curr_q_value, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores: List[float], \n",
    "        losses: List[float], \n",
    "        epsilons: List[float],\n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
    "        plt.plot(scores)\n",
    "        plt.subplot(132)\n",
    "        plt.title('loss')\n",
    "        plt.plot(losses)\n",
    "        plt.subplot(133)\n",
    "        plt.title('epsilons')\n",
    "        plt.plot(epsilons)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "You can see the [code](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py) and [configurations](https://github.com/openai/gym/blob/master/gym/envs/__init__.py#L53) of CartPole-v0 from OpenAI's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdsEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "        # Actions we can take, classify as malicious or non-malicious (later also the correct attack)\n",
    "        # change to 19 if detectiong all different attacks\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "         # All the features we have, len(important_features) - 1 features and 1 label. Label should not be included\n",
    "        self.observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(len(nslkdd_train.columns) - 1,))\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "    \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "        current_label = self.expected_action\n",
    "        obs = self._next_obs()\n",
    "        \n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {'label': current_label}\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y.iloc[next_obs_idx,:])\n",
    "            obs = self.x.iloc[next_obs_idx,:]\n",
    "\n",
    "        else:\n",
    "            obs = self.x.iloc[self.dataset_idx]\n",
    "            self.expected_action = int(self.y.iloc[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "        return obs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "env = IdsEnv(images_per_episode=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\anaconda3\\envs\\MP\\lib\\site-packages\\gym\\core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[777]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 777\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "seed_torch(seed)\n",
    "env.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames = int(1.0e5)\n",
    "memory_size = 100000\n",
    "batch_size = 128\n",
    "target_update = 10000\n",
    "epsilon_decay = 1 / 10000\n",
    "\n",
    "# train\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update, epsilon_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.train(num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Run the trained agent (1 episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation done...\n",
      "Accuracy: 95.15127317895484%\n",
      "Precision: 95.15332235524501%\n",
      "Recall/TPR/Sensitivity: 99.98129442573887%\n",
      "FPR: 94.04145077720207%\n",
      "F1 score: 0.9750758214945386\n",
      "count: 22543\n"
     ]
    }
   ],
   "source": [
    "agent.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
