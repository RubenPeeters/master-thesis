{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'baselines' already exists and is not an empty directory.\n",
      "/project/baselines\n",
      "Obtaining file:///project/baselines\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: gym<0.16.0,>=0.15.4 in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (0.15.7)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (1.4.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (4.46.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (0.15.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (1.2.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (7.1.2)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (4.5.5.64)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /opt/conda/lib/python3.7/site-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.18.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.15.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym<0.16.0,>=0.15.4->baselines==0.1.6) (0.18.2)\n",
      "Installing collected packages: baselines\n",
      "  Attempting uninstall: baselines\n",
      "    Found existing installation: baselines 0.1.6\n",
      "    Uninstalling baselines-0.1.6:\n",
      "      Successfully uninstalled baselines-0.1.6\n",
      "  Running setup.py develop for baselines\n",
      "Successfully installed baselines-0.1.6\n",
      "Requirement already satisfied: stable-baselines[mpi] in /opt/conda/lib/python3.7/site-packages (2.10.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from stable-baselines[mpi]) (3.2.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from stable-baselines[mpi]) (0.15.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from stable-baselines[mpi]) (1.4.1)\n",
      "Requirement already satisfied: cloudpickle>=0.5.5 in /opt/conda/lib/python3.7/site-packages (from stable-baselines[mpi]) (1.2.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from stable-baselines[mpi]) (1.18.5)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from stable-baselines[mpi]) (4.5.5.64)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from stable-baselines[mpi]) (1.0.4)\n",
      "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /opt/conda/lib/python3.7/site-packages (from stable-baselines[mpi]) (0.15.7)\n",
      "Collecting mpi4py\n",
      "  Using cached mpi4py-3.1.3.tar.gz (2.5 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (1.5.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (1.15.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (7.1.2)\n",
      "Requirement already satisfied: atari-py~=0.2.0 in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (0.2.9)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines[mpi]) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines[mpi]) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines[mpi]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines[mpi]) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->stable-baselines[mpi]) (2020.1)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (0.18.2)\n",
      "Building wheels for collected packages: mpi4py\n",
      "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for mpi4py \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[148 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_src\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.7\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.7/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/__main__.py -> build/lib.linux-x86_64-3.7/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/run.py -> build/lib.linux-x86_64-3.7/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/__init__.py -> build/lib.linux-x86_64-3.7/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/bench.py -> build/lib.linux-x86_64-3.7/mpi4py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.7/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/__main__.py -> build/lib.linux-x86_64-3.7/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/_lib.py -> build/lib.linux-x86_64-3.7/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/pool.py -> build/lib.linux-x86_64-3.7/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/_core.py -> build/lib.linux-x86_64-3.7/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/__init__.py -> build/lib.linux-x86_64-3.7/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/server.py -> build/lib.linux-x86_64-3.7/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/_base.py -> build/lib.linux-x86_64-3.7/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/aplus.py -> build/lib.linux-x86_64-3.7/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.7/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/dtlib.py -> build/lib.linux-x86_64-3.7/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/__init__.py -> build/lib.linux-x86_64-3.7/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/pkl5.py -> build/lib.linux-x86_64-3.7/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/py.typed -> build/lib.linux-x86_64-3.7/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/__init__.pyi -> build/lib.linux-x86_64-3.7/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/run.pyi -> build/lib.linux-x86_64-3.7/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/bench.pyi -> build/lib.linux-x86_64-3.7/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/__main__.pyi -> build/lib.linux-x86_64-3.7/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/MPI.pyi -> build/lib.linux-x86_64-3.7/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/dl.pyi -> build/lib.linux-x86_64-3.7/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/MPI.pxd -> build/lib.linux-x86_64-3.7/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/libmpi.pxd -> build/lib.linux-x86_64-3.7/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/__init__.pxd -> build/lib.linux-x86_64-3.7/mpi4py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.7/mpi4py/include\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.7/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/include/mpi4py/mpi4py.h -> build/lib.linux-x86_64-3.7/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/include/mpi4py/mpi4py.MPI.h -> build/lib.linux-x86_64-3.7/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/include/mpi4py/mpi4py.MPI_api.h -> build/lib.linux-x86_64-3.7/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/include/mpi4py/mpi4py.i -> build/lib.linux-x86_64-3.7/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/include/mpi4py/mpi.pxi -> build/lib.linux-x86_64-3.7/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/__init__.pyi -> build/lib.linux-x86_64-3.7/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/server.pyi -> build/lib.linux-x86_64-3.7/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/pool.pyi -> build/lib.linux-x86_64-3.7/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/_core.pyi -> build/lib.linux-x86_64-3.7/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/_lib.pyi -> build/lib.linux-x86_64-3.7/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/__main__.pyi -> build/lib.linux-x86_64-3.7/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/aplus.pyi -> build/lib.linux-x86_64-3.7/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/__init__.pyi -> build/lib.linux-x86_64-3.7/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/pkl5.pyi -> build/lib.linux-x86_64-3.7/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/dtlib.pyi -> build/lib.linux-x86_64-3.7/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m running build_clib\n",
      "  \u001b[31m   \u001b[0m MPI configuration: [mpi] from 'mpi.cfg'\n",
      "  \u001b[31m   \u001b[0m checking for library 'lmpe' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ _configtest.o -llmpe -o _configtest\n",
      "  \u001b[31m   \u001b[0m /usr/bin/ld: cannot find -llmpe\n",
      "  \u001b[31m   \u001b[0m collect2: error: ld returned 1 exit status\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m building 'mpe' dylib library\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.7\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.7/src\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.7/src/lib-pmpi\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -c src/lib-pmpi/mpe.c -o build/temp.linux-x86_64-3.7/src/lib-pmpi/mpe.o\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.7/mpi4py/lib-pmpi\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ -Wl,--no-as-needed build/temp.linux-x86_64-3.7/src/lib-pmpi/mpe.o -o build/lib.linux-x86_64-3.7/mpi4py/lib-pmpi/libmpe.so\n",
      "  \u001b[31m   \u001b[0m checking for library 'vt-mpi' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ _configtest.o -lvt-mpi -o _configtest\n",
      "  \u001b[31m   \u001b[0m /usr/bin/ld: cannot find -lvt-mpi\n",
      "  \u001b[31m   \u001b[0m collect2: error: ld returned 1 exit status\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m checking for library 'vt.mpi' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ _configtest.o -lvt.mpi -o _configtest\n",
      "  \u001b[31m   \u001b[0m /usr/bin/ld: cannot find -lvt.mpi\n",
      "  \u001b[31m   \u001b[0m collect2: error: ld returned 1 exit status\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m building 'vt' dylib library\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -c src/lib-pmpi/vt.c -o build/temp.linux-x86_64-3.7/src/lib-pmpi/vt.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ -Wl,--no-as-needed build/temp.linux-x86_64-3.7/src/lib-pmpi/vt.o -o build/lib.linux-x86_64-3.7/mpi4py/lib-pmpi/libvt.so\n",
      "  \u001b[31m   \u001b[0m checking for library 'vt-mpi' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ _configtest.o -lvt-mpi -o _configtest\n",
      "  \u001b[31m   \u001b[0m /usr/bin/ld: cannot find -lvt-mpi\n",
      "  \u001b[31m   \u001b[0m collect2: error: ld returned 1 exit status\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m checking for library 'vt.mpi' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ _configtest.o -lvt.mpi -o _configtest\n",
      "  \u001b[31m   \u001b[0m /usr/bin/ld: cannot find -lvt.mpi\n",
      "  \u001b[31m   \u001b[0m collect2: error: ld returned 1 exit status\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m building 'vt-mpi' dylib library\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -c src/lib-pmpi/vt-mpi.c -o build/temp.linux-x86_64-3.7/src/lib-pmpi/vt-mpi.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ -Wl,--no-as-needed build/temp.linux-x86_64-3.7/src/lib-pmpi/vt-mpi.o -o build/lib.linux-x86_64-3.7/mpi4py/lib-pmpi/libvt-mpi.so\n",
      "  \u001b[31m   \u001b[0m checking for library 'vt-hyb' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ _configtest.o -lvt-hyb -o _configtest\n",
      "  \u001b[31m   \u001b[0m /usr/bin/ld: cannot find -lvt-hyb\n",
      "  \u001b[31m   \u001b[0m collect2: error: ld returned 1 exit status\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m checking for library 'vt.ompi' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ _configtest.o -lvt.ompi -o _configtest\n",
      "  \u001b[31m   \u001b[0m /usr/bin/ld: cannot find -lvt.ompi\n",
      "  \u001b[31m   \u001b[0m collect2: error: ld returned 1 exit status\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m building 'vt-hyb' dylib library\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -c src/lib-pmpi/vt-hyb.c -o build/temp.linux-x86_64-3.7/src/lib-pmpi/vt-hyb.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ -Wl,--no-as-needed build/temp.linux-x86_64-3.7/src/lib-pmpi/vt-hyb.o -o build/lib.linux-x86_64-3.7/mpi4py/lib-pmpi/libvt-hyb.so\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m MPI configuration: [mpi] from 'mpi.cfg'\n",
      "  \u001b[31m   \u001b[0m checking for dlopen() availability ...\n",
      "  \u001b[31m   \u001b[0m checking for header 'dlfcn.h' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/include/python3.7m -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m success!\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m success!\n",
      "  \u001b[31m   \u001b[0m checking for library 'dl' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/include/python3.7m -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ _configtest.o -Lbuild/temp.linux-x86_64-3.7 -ldl -o _configtest\n",
      "  \u001b[31m   \u001b[0m success!\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o _configtest\n",
      "  \u001b[31m   \u001b[0m checking for function 'dlopen' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/include/python3.7m -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ _configtest.o -Lbuild/temp.linux-x86_64-3.7 -ldl -o _configtest\n",
      "  \u001b[31m   \u001b[0m success!\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o _configtest\n",
      "  \u001b[31m   \u001b[0m building 'mpi4py.dl' extension\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DHAVE_DLFCN_H=1 -DHAVE_DLOPEN=1 -I/opt/conda/include/python3.7m -c src/dynload.c -o build/temp.linux-x86_64-3.7/src/dynload.o\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/src/dynload.o -Lbuild/temp.linux-x86_64-3.7 -ldl -o build/lib.linux-x86_64-3.7/mpi4py/dl.cpython-37m-x86_64-linux-gnu.so\n",
      "  \u001b[31m   \u001b[0m checking for MPI compile and link ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/include/python3.7m -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m _configtest.c:2:10: fatal error: mpi.h: No such file or directory\n",
      "  \u001b[31m   \u001b[0m  #include <mpi.h>\n",
      "  \u001b[31m   \u001b[0m           ^~~~~~~\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m error: Cannot compile MPI programs. Check your configuration!!!\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for mpi4py\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25hFailed to build mpi4py\n",
      "\u001b[31mERROR: Could not build wheels for mpi4py, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: tensorflow==1.14.0 in /opt/conda/lib/python3.7/site-packages (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (3.11.4)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.3.3)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.29.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.18.5)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.15.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (62.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.0)\n",
      "Requirement already satisfied: tensorflow-gpu==1.14.0 in /opt/conda/lib/python3.7/site-packages (1.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.18.5)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.29.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.9.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.37.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (3.11.4)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14.0) (62.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.1.0)\n",
      "Requirement already satisfied: gym in /opt/conda/lib/python3.7/site-packages (0.15.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gym) (1.15.0)\n",
      "Requirement already satisfied: cloudpickle~=1.2.0 in /opt/conda/lib/python3.7/site-packages (from gym) (1.2.2)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /opt/conda/lib/python3.7/site-packages (from gym) (1.18.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from gym) (1.4.1)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.18.2)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.7/site-packages (7.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from pyarrow) (1.18.5)\n",
      "\u001b[33mWARNING: Skipping tensorboard-plugin-wit as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/openai/baselines.git\n",
    "%cd baselines\n",
    "!pip install -e .\n",
    "!pip install stable-baselines\n",
    "!pip install mpi4py\n",
    "!pip install --upgrade tensorflow==1.14.0\n",
    "!pip install --upgrade tensorflow-gpu==1.14.0\n",
    "!pip install gym\n",
    "!pip install pyarrow\n",
    "!pip uninstall --yes tensorboard-plugin-wit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DDPG' from 'stable_baselines' (/opt/conda/lib/python3.7/site-packages/stable_baselines/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-889b58ab6b93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdummy_vec_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDummyVecEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDDPG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbench\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DDPG' from 'stable_baselines' (/opt/conda/lib/python3.7/site-packages/stable_baselines/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gym\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "\n",
    "from stable_baselines import DDPG\n",
    "from stable_baselines import bench\n",
    "from stable_baselines import logger\n",
    "import tensorflow as tf\n",
    "\n",
    "from baselines.common.tf_util import make_session\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "logdir = \"Training/Logs/DDPG/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cicddos2019 = pd.read_feather(\"/project/datasets/clean-ids-collection/cic-ddos2019/clean/cicddos2019.feather\")\n",
    "cicdos2017 = pd.read_feather(\"/project/datasets/clean-ids-collection/cic-dos2017/clean/cicdos2017.feather\")\n",
    "cicids2017 = pd.read_feather(\"/project/datasets/clean-ids-collection/cic-ids2017/clean/cicids2017.feather\")\n",
    "data = pd.concat([cicddos2019], ignore_index=True)\n",
    "print(len(data.columns))\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cicdos2017_features = [\"Init Bwd Win Bytes\",  \"Idle Min\", \"ACK Flag Count\", \"Fwd Packet Length Min\", \"Fwd PSH Flags\"]\n",
    "cicids2017_features = [\"Protocol\", \"Avg Bwd Segment Size\", \"Packet Length Max\", \"Bwd Packet Length Min\", \"Fwd IAT Mean\"]\n",
    "cicddos2019_features = [\"URG Flag Count\", \"Down/Up Ratio\", \"Bwd Packet Length Min\", \"ACK Flag Count\", \"Fwd Packets Length Total\"]\n",
    "important_features = cicddos2019_features + [\"Label\", \"Timestamp\"] # Adding Timestamp for custom environment logic\n",
    "important_features = list(set(important_features))\n",
    "print(len(important_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removable_features = data.columns ^ important_features\n",
    "print(removable_features.shape)\n",
    "skinny_data = data.drop(labels=removable_features, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing done by Laurens D'Hooge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n",
    "- Build an agent to classify network flow automatically\n",
    "- Feed a packet that gets classified\n",
    "- Want the classification to be equal to the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_dataset_sampler_df(df, train_frac=0.2, val_frac=0.1, test_frac=0.7):\n",
    "    col = df.columns[-1]\n",
    "    print(col)\n",
    "    cols = df.columns[:-1]\n",
    "    print(cols)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    n = vc.iloc[-1]\n",
    "    print(n)\n",
    "    m = vc.iloc[0]\n",
    "    print(m)\n",
    "    print(int(m-n))\n",
    "    initial_cut = df.loc[df[col] == vc.index[0]].sample(n=int(m-n), replace=False)\n",
    "    print(initial_cut.index)\n",
    "    df = df.drop(index=initial_cut.index)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    print(int(n*train_frac))\n",
    "    train_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*train_frac), replace=False))\n",
    "    train_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=train_df.index)\n",
    "\n",
    "    validation_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*val_frac), replace=False))\n",
    "    validation_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=validation_df.index)\n",
    "\n",
    "    test_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*test_frac), replace=False))\n",
    "    test_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=test_df.index)\n",
    "\n",
    "    return train_df[cols], train_df[col], validation_df[cols], validation_df[col], test_df[cols], test_df[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Timestamp', inplace=True, axis=1)\n",
    "print(data['Label'].value_counts())\n",
    "data['Label'] = data['Label'].astype('object')\n",
    "atk_idx = data.loc[data['Label'] != \"Benign\"].index\n",
    "data.loc[atk_idx, 'Label'] = 1.0\n",
    "data.loc[skinny_data.index.difference(atk_idx), 'Label'] = 0.0\n",
    "data['Label'] = data['Label'].astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test  = balancing_dataset_sampler_df(data, train_frac=0.9, val_frac=0.0, test_frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"Validation\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(\"Testing\")\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.index)\n",
    "print(y_train.index)\n",
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom keys -> replace by index\n",
    "\n",
    "x_train = x_train.set_index([pd.Index(range (0, len(x_train)))])\n",
    "y_train = y_train.set_index([pd.Index(range (0, len(y_train)))])\n",
    "x_test = x_test.set_index([pd.Index(range (0, len(x_test)))])\n",
    "y_test = y_test.set_index([pd.Index(range (0, len(y_test)))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.index)\n",
    "print(y_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.iloc[17162,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.index)\n",
    "print(x_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdsEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "        # Actions we can take, classify as malicious or non-malicious (later also the correct attack)\n",
    "        # change to 19 if detectiong all different attacks\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "        # All the features we have, len(important_features) - 1 features and 1 label. Label should not be included\n",
    "        self.observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(67,))\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "    \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "\n",
    "        obs = self._next_obs()\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y.iloc[next_obs_idx,:])\n",
    "            obs = self.x.iloc[next_obs_idx,:]\n",
    "\n",
    "        else:\n",
    "            obs = self.x.iloc[self.dataset_idx]\n",
    "            self.expected_action = int(self.y.iloc[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "\n",
    "        return obs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train classifier using dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_dqn():\n",
    "#     logger.configure(dir=os.path.join(os.getcwd(),'Training/Logs/ids_dqn'), format_strs=['stdout', 'tensorboard'])\n",
    "    env = IdsEnv(images_per_episode=4096)\n",
    "#     env = bench.Monitor(env, logger.get_dir())\n",
    "\n",
    "    model = DDPG(\n",
    "        MlpPolicy, \n",
    "        env, \n",
    "        verbose=1,\n",
    "        tensorboard_log=logdir,\n",
    "        full_tensorboard_log=True,\n",
    "    ).learn(\n",
    "        total_timesteps=int(1.0e4),\n",
    "        log_interval=1000,\n",
    "    )\n",
    "\n",
    "    model.save('ddpg_stableb2_ids.pkl')\n",
    "    env.close()\n",
    "    \n",
    "    return model\n",
    "\n",
    "start_time = time.time()\n",
    "dqn_model = ids_dqn()\n",
    "print(\"DQN Training Time:\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_dqn_eval(dqn_model):\n",
    "    attempts, correct = 0,0\n",
    "\n",
    "    env = IdsEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            obs, done = env.reset(), False\n",
    "            while not done:\n",
    "                obs, rew, done, _ = env.step(dqn_model.predict(obs)[0])\n",
    "\n",
    "                attempts += 1\n",
    "                if rew > 0:\n",
    "                    correct += 1\n",
    "\n",
    "    except StopIteration:\n",
    "        print()\n",
    "        print('validation done...')\n",
    "        print('Accuracy: {0}%'.format((float(correct) / attempts) * 100))\n",
    "\n",
    "ids_dqn_eval(dqn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir {logdir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
