{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'baselines' already exists and is not an empty directory.\n",
      "/project/baselines\n",
      "Obtaining file:///project/baselines\n",
      "Requirement already satisfied: gym<0.16.0,>=0.15.4 in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (0.15.7)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (1.4.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (4.46.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (0.15.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (1.2.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (7.1.2)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /opt/conda/lib/python3.7/site-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.18.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.15.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.5.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym<0.16.0,>=0.15.4->baselines==0.1.6) (0.18.2)\n",
      "Installing collected packages: baselines\n",
      "  Attempting uninstall: baselines\n",
      "    Found existing installation: baselines 0.1.6\n",
      "    Uninstalling baselines-0.1.6:\n",
      "      Successfully uninstalled baselines-0.1.6\n",
      "  Running setup.py develop for baselines\n",
      "Successfully installed baselines\n",
      "Requirement already satisfied: stable-baselines in /opt/conda/lib/python3.7/site-packages (2.10.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (0.15.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (3.2.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (1.0.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (1.4.1)\n",
      "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (0.15.7)\n",
      "Requirement already satisfied: cloudpickle>=0.5.5 in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (1.2.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (1.18.5)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (4.5.5.64)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->stable-baselines) (2020.1)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines) (1.5.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines) (1.15.0)\n",
      "Requirement already satisfied: Pillow; extra == \"atari\" in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines) (7.1.2)\n",
      "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines) (0.2.9)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines) (0.18.2)\n",
      "Requirement already up-to-date: tensorflow==1.14.0 in /opt/conda/lib/python3.7/site-packages (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<1.15.0,>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.29.0)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (3.11.4)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (47.1.1.post20200529)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.6.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.0)\n",
      "Requirement already satisfied: gym in /opt/conda/lib/python3.7/site-packages (0.15.7)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from gym) (1.4.1)\n",
      "Requirement already satisfied: cloudpickle~=1.2.0 in /opt/conda/lib/python3.7/site-packages (from gym) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /opt/conda/lib/python3.7/site-packages (from gym) (1.18.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gym) (1.15.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.18.2)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.7/site-packages (7.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from pyarrow) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/openai/baselines.git\n",
    "%cd baselines\n",
    "!pip install -e .\n",
    "!pip install stable-baselines\n",
    "!pip install --upgrade tensorflow==1.14.0\n",
    "!pip install gym\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gym\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "\n",
    "from stable_baselines import A2C\n",
    "from stable_baselines import bench\n",
    "from stable_baselines import logger\n",
    "import tensorflow as tf\n",
    "\n",
    "from baselines.common.tf_util import make_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Fwd Packets Length Total</th>\n",
       "      <th>Bwd Packets Length Total</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-03 09:18:16.964447</td>\n",
       "      <td>114456999</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8185.583496</td>\n",
       "      <td>28337.111328</td>\n",
       "      <td>98168.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9529897.0</td>\n",
       "      <td>351582.62500</td>\n",
       "      <td>10001143.0</td>\n",
       "      <td>9048097.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-03 09:18:18.506537</td>\n",
       "      <td>114347504</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35028.417969</td>\n",
       "      <td>121314.914062</td>\n",
       "      <td>420255.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9493930.0</td>\n",
       "      <td>351541.09375</td>\n",
       "      <td>9978130.0</td>\n",
       "      <td>8820294.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-11-03 09:18:18.610576</td>\n",
       "      <td>36435473</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>116.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.333334</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>62416.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62416.0</td>\n",
       "      <td>62416.0</td>\n",
       "      <td>36373056.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>36373056.0</td>\n",
       "      <td>36373056.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-11-03 09:18:18.610579</td>\n",
       "      <td>36434705</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>116.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.333334</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>62413.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62413.0</td>\n",
       "      <td>62413.0</td>\n",
       "      <td>36372292.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>36372292.0</td>\n",
       "      <td>36372292.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-11-03 09:18:18.610581</td>\n",
       "      <td>36434626</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>116.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.333334</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>62409.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62409.0</td>\n",
       "      <td>62409.0</td>\n",
       "      <td>36372216.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>36372216.0</td>\n",
       "      <td>36372216.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Protocol                  Timestamp  Flow Duration  Total Fwd Packets  \\\n",
       "0         0 2018-11-03 09:18:16.964447      114456999                 45   \n",
       "1         0 2018-11-03 09:18:18.506537      114347504                 56   \n",
       "2         6 2018-11-03 09:18:18.610576       36435473                  6   \n",
       "3         6 2018-11-03 09:18:18.610579       36434705                  6   \n",
       "4         6 2018-11-03 09:18:18.610581       36434626                  6   \n",
       "\n",
       "   Total Backward Packets  Fwd Packets Length Total  Bwd Packets Length Total  \\\n",
       "0                       0                       0.0                       0.0   \n",
       "1                       0                       0.0                       0.0   \n",
       "2                       2                     116.0                      92.0   \n",
       "3                       2                     116.0                      92.0   \n",
       "4                       2                     116.0                      92.0   \n",
       "\n",
       "   Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  ...  \\\n",
       "0                    0.0                    0.0                0.000000  ...   \n",
       "1                    0.0                    0.0                0.000000  ...   \n",
       "2                   46.0                    6.0               19.333334  ...   \n",
       "3                   46.0                    6.0               19.333334  ...   \n",
       "4                   46.0                    6.0               19.333334  ...   \n",
       "\n",
       "   Fwd Seg Size Min   Active Mean     Active Std  Active Max  Active Min  \\\n",
       "0                 0   8185.583496   28337.111328     98168.0         3.0   \n",
       "1                 0  35028.417969  121314.914062    420255.0         4.0   \n",
       "2                20  62416.000000       0.000000     62416.0     62416.0   \n",
       "3                20  62413.000000       0.000000     62413.0     62413.0   \n",
       "4                20  62409.000000       0.000000     62409.0     62409.0   \n",
       "\n",
       "    Idle Mean      Idle Std    Idle Max    Idle Min   Label  \n",
       "0   9529897.0  351582.62500  10001143.0   9048097.0  Benign  \n",
       "1   9493930.0  351541.09375   9978130.0   8820294.0  Benign  \n",
       "2  36373056.0       0.00000  36373056.0  36373056.0  Benign  \n",
       "3  36372292.0       0.00000  36372292.0  36372292.0  Benign  \n",
       "4  36372216.0       0.00000  36372216.0  36372216.0  Benign  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cicddos2019 = pd.read_feather(\"/project/datasets/clean-ids-collection/cic-ddos2019/clean/cicddos2019.feather\")\n",
    "cicdos2017 = pd.read_feather(\"/project/datasets/clean-ids-collection/cic-dos2017/clean/cicdos2017.feather\")\n",
    "cicids2017 = pd.read_feather(\"/project/datasets/clean-ids-collection/cic-ids2017/clean/cicids2017.feather\")\n",
    "data = pd.concat([cicddos2019], ignore_index=True)\n",
    "print(len(data.columns))\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "cicdos2017_features = [\"Init Bwd Win Bytes\",  \"Idle Min\", \"ACK Flag Count\", \"Fwd Packet Length Min\", \"Fwd PSH Flags\"]\n",
    "cicids2017_features = [\"Protocol\", \"Avg Bwd Segment Size\", \"Packet Length Max\", \"Bwd Packet Length Min\", \"Fwd IAT Mean\"]\n",
    "cicddos2019_features = [\"URG Flag Count\", \"Down/Up Ratio\", \"Bwd Packet Length Min\", \"ACK Flag Count\", \"Fwd Packets Length Total\"]\n",
    "important_features = cicddos2019_features + [\"Label\", \"Timestamp\"] # Adding Timestamp for custom environment logic\n",
    "important_features = list(set(important_features))\n",
    "print(len(important_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62,)\n"
     ]
    }
   ],
   "source": [
    "removable_features = data.columns ^ important_features\n",
    "print(removable_features.shape)\n",
    "skinny_data = data.drop(labels=removable_features, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 138007 entries, 0 to 138006\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count   Dtype         \n",
      "---  ------                    --------------   -----         \n",
      " 0   Timestamp                 138007 non-null  datetime64[ns]\n",
      " 1   Fwd Packets Length Total  138007 non-null  float32       \n",
      " 2   Bwd Packet Length Min     138007 non-null  float32       \n",
      " 3   ACK Flag Count            138007 non-null  int8          \n",
      " 4   URG Flag Count            138007 non-null  int8          \n",
      " 5   Down/Up Ratio             138007 non-null  float32       \n",
      " 6   Label                     138007 non-null  category      \n",
      "dtypes: category(1), datetime64[ns](1), float32(3), int8(2)\n",
      "memory usage: 3.0 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fwd Packets Length Total</th>\n",
       "      <th>Bwd Packet Length Min</th>\n",
       "      <th>ACK Flag Count</th>\n",
       "      <th>URG Flag Count</th>\n",
       "      <th>Down/Up Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>138007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.018388e+03</td>\n",
       "      <td>25.685892</td>\n",
       "      <td>0.198584</td>\n",
       "      <td>0.275283</td>\n",
       "      <td>0.702986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.148026e+04</td>\n",
       "      <td>52.287216</td>\n",
       "      <td>0.398936</td>\n",
       "      <td>0.446658</td>\n",
       "      <td>0.937449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.600000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.064000e+03</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.526642e+07</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Fwd Packets Length Total  Bwd Packet Length Min  ACK Flag Count  \\\n",
       "count              1.380070e+05          138007.000000   138007.000000   \n",
       "mean               4.018388e+03              25.685892        0.198584   \n",
       "std                5.148026e+04              52.287216        0.398936   \n",
       "min                0.000000e+00               0.000000        0.000000   \n",
       "25%                1.800000e+01               0.000000        0.000000   \n",
       "50%                8.600000e+01               0.000000        0.000000   \n",
       "75%                2.064000e+03              46.000000        0.000000   \n",
       "max                1.526642e+07            1460.000000        1.000000   \n",
       "\n",
       "       URG Flag Count  Down/Up Ratio  \n",
       "count   138007.000000  138007.000000  \n",
       "mean         0.275283       0.702986  \n",
       "std          0.446658       0.937449  \n",
       "min          0.000000       0.000000  \n",
       "25%          0.000000       0.000000  \n",
       "50%          0.000000       1.000000  \n",
       "75%          1.000000       1.000000  \n",
       "max          1.000000      23.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skinny_data.info()\n",
    "skinny_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing done by Laurens D'Hooge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n",
    "- Build an agent to classify network flow automatically\n",
    "- Feed a packet that gets classified\n",
    "- Want the classification to be equal to the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_dataset_sampler_df(df, train_frac=0.2, val_frac=0.1, test_frac=0.7):\n",
    "    col = df.columns[-1]\n",
    "    print(col)\n",
    "    cols = df.columns[:-1]\n",
    "    print(cols)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    n = vc.iloc[-1]\n",
    "    print(n)\n",
    "    m = vc.iloc[0]\n",
    "    print(m)\n",
    "    print(int(m-n))\n",
    "    initial_cut = df.loc[df[col] == vc.index[0]].sample(n=int(m-n), replace=False)\n",
    "    print(initial_cut.index)\n",
    "    df = df.drop(index=initial_cut.index)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    print(int(n*train_frac))\n",
    "    train_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*train_frac), replace=False))\n",
    "    train_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=train_df.index)\n",
    "\n",
    "    validation_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*val_frac), replace=False))\n",
    "    validation_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=validation_df.index)\n",
    "\n",
    "    test_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*test_frac), replace=False))\n",
    "    test_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=test_df.index)\n",
    "\n",
    "    return train_df[cols], train_df[col], validation_df[cols], validation_df[col], test_df[cols], test_df[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign           95095\n",
      "DrDoS_NTP        13687\n",
      "TFTP             13027\n",
      "Syn               6713\n",
      "UDP               2158\n",
      "MSSQL             1763\n",
      "DrDoS_UDP         1174\n",
      "UDP-lag           1097\n",
      "DrDoS_MSSQL        927\n",
      "DrDoS_DNS          552\n",
      "LDAP               484\n",
      "DrDoS_SSDP         413\n",
      "DrDoS_SNMP         392\n",
      "Portmap            215\n",
      "DrDoS_LDAP         174\n",
      "NetBIOS             73\n",
      "DrDoS_NetBIOS       51\n",
      "UDPLag              10\n",
      "WebDDoS              2\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "skinny_data.drop('Timestamp', inplace=True, axis=1)\n",
    "print(skinny_data['Label'].value_counts())\n",
    "skinny_data['Label'] = skinny_data['Label'].astype('object')\n",
    "atk_idx = skinny_data.loc[skinny_data['Label'] != \"Benign\"].index\n",
    "skinny_data.loc[atk_idx, 'Label'] = 1.0\n",
    "skinny_data.loc[skinny_data.index.difference(atk_idx), 'Label'] = 0.0\n",
    "skinny_data['Label'] = skinny_data['Label'].astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "Index(['Fwd Packets Length Total', 'Bwd Packet Length Min', 'ACK Flag Count',\n",
      "       'URG Flag Count', 'Down/Up Ratio'],\n",
      "      dtype='object')\n",
      "0.0    95095\n",
      "1.0    42912\n",
      "Name: Label, dtype: int64\n",
      "42912\n",
      "95095\n",
      "52183\n",
      "Int64Index([ 89061,  21137,  10993,  91205,  11189, 101130,  48981,   9273,\n",
      "             54832,  92666,\n",
      "            ...\n",
      "            126386, 110379, 118497,  67701,     67,    501,  93758,  61800,\n",
      "             50613,  82668],\n",
      "           dtype='int64', length=52183)\n",
      "1.0    42912\n",
      "0.0    42912\n",
      "Name: Label, dtype: int64\n",
      "38620\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test  = balancing_dataset_sampler_df(skinny_data, train_frac=0.9, val_frac=0.0, test_frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "(77240, 5)\n",
      "(77240,)\n",
      "Validation\n",
      "(0, 5)\n",
      "(0,)\n",
      "Testing\n",
      "(8582, 5)\n",
      "(8582,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"Validation\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(\"Testing\")\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77240, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 61660, 135773, 130676,  90397,   2907,  39353,  34643,   7216,\n",
      "             34403,  98025,\n",
      "            ...\n",
      "             29952,  71354,  13224,  18278, 119352, 105251,  11950,  10772,\n",
      "             71707, 112551],\n",
      "           dtype='int64', length=77240)\n",
      "Int64Index([ 61660, 135773, 130676,  90397,   2907,  39353,  34643,   7216,\n",
      "             34403,  98025,\n",
      "            ...\n",
      "             29952,  71354,  13224,  18278, 119352, 105251,  11950,  10772,\n",
      "             71707, 112551],\n",
      "           dtype='int64', length=77240)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.index)\n",
    "print(y_train.index)\n",
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom keys -> replace by index\n",
    "\n",
    "x_train = x_train.set_index([pd.Index(range (0, len(x_train)))])\n",
    "y_train = y_train.set_index([pd.Index(range (0, len(y_train)))])\n",
    "x_test = x_test.set_index([pd.Index(range (0, len(x_test)))])\n",
    "y_test = y_test.set_index([pd.Index(range (0, len(y_test)))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=77240, step=1)\n",
      "RangeIndex(start=0, stop=77240, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.index)\n",
    "print(y_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Label\n",
      "0        0.0\n",
      "1        0.0\n",
      "2        0.0\n",
      "3        0.0\n",
      "4        0.0\n",
      "...      ...\n",
      "77235    1.0\n",
      "77236    1.0\n",
      "77237    1.0\n",
      "77238    1.0\n",
      "77239    1.0\n",
      "\n",
      "[77240 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label    0.0\n",
      "Name: 17162, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "print(y_train.iloc[17162,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=77240, step=1)\n",
      "RangeIndex(start=0, stop=77240, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.index)\n",
    "print(x_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdsEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "        # Actions we can take, classify as malicious or non-malicious (later also the correct attack)\n",
    "        # change to 19 if detectiong all different attacks\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "        # All the features we have, len(important_features) - 1 features and 1 label. Label should not be included\n",
    "        self.observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(len(important_features) - 2,))\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "    \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "\n",
    "        obs = self._next_obs()\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y.iloc[next_obs_idx,:])\n",
    "            obs = self.x.iloc[next_obs_idx,:]\n",
    "\n",
    "        else:\n",
    "            obs = self.x.iloc[self.dataset_idx]\n",
    "            self.expected_action = int(self.y.iloc[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "\n",
    "        return obs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train classifier using dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2118af99d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2118af99d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2118af99d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2118af99d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2118a9dbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2118a9dbd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2118a9dbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2118a9dbd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:160: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:184: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:196: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "---------------------------------\n",
      "| explained_variance | -0.277   |\n",
      "| fps                | 8        |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 4.46     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 2.2e+03  |\n",
      "| explained_variance | 0.472    |\n",
      "| fps                | 263      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 0.422    |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 7.94     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 2.51e+03 |\n",
      "| explained_variance | -0.0301  |\n",
      "| fps                | 270      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 0.0395   |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 2.34     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 2.78e+03 |\n",
      "| explained_variance | -0.0109  |\n",
      "| fps                | 273      |\n",
      "| nupdates           | 3000     |\n",
      "| policy_entropy     | 0.0276   |\n",
      "| total_timesteps    | 15000    |\n",
      "| value_loss         | 0.158    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 2.92e+03 |\n",
      "| explained_variance | 0.00239  |\n",
      "| fps                | 276      |\n",
      "| nupdates           | 4000     |\n",
      "| policy_entropy     | 0.0119   |\n",
      "| total_timesteps    | 20000    |\n",
      "| value_loss         | 0.183    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.08e+03 |\n",
      "| explained_variance | -0.00457 |\n",
      "| fps                | 276      |\n",
      "| nupdates           | 5000     |\n",
      "| policy_entropy     | 0.0117   |\n",
      "| total_timesteps    | 25000    |\n",
      "| value_loss         | 0.178    |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 4.1e+03   |\n",
      "| ep_reward_mean     | 3.12e+03  |\n",
      "| explained_variance | -0.000707 |\n",
      "| fps                | 277       |\n",
      "| nupdates           | 6000      |\n",
      "| policy_entropy     | 0.0139    |\n",
      "| total_timesteps    | 30000     |\n",
      "| value_loss         | 0.164     |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.15e+03 |\n",
      "| explained_variance | 0.00017  |\n",
      "| fps                | 278      |\n",
      "| nupdates           | 7000     |\n",
      "| policy_entropy     | 0.0153   |\n",
      "| total_timesteps    | 35000    |\n",
      "| value_loss         | 0.568    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.18e+03 |\n",
      "| explained_variance | 0.000889 |\n",
      "| fps                | 279      |\n",
      "| nupdates           | 8000     |\n",
      "| policy_entropy     | 0.00347  |\n",
      "| total_timesteps    | 40000    |\n",
      "| value_loss         | 0.415    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.2e+03  |\n",
      "| explained_variance | 0.00705  |\n",
      "| fps                | 280      |\n",
      "| nupdates           | 9000     |\n",
      "| policy_entropy     | 0.00187  |\n",
      "| total_timesteps    | 45000    |\n",
      "| value_loss         | 0.129    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.23e+03 |\n",
      "| explained_variance | -0.0694  |\n",
      "| fps                | 281      |\n",
      "| nupdates           | 10000    |\n",
      "| policy_entropy     | 0.0192   |\n",
      "| total_timesteps    | 50000    |\n",
      "| value_loss         | 0.149    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.25e+03 |\n",
      "| explained_variance | 0.0197   |\n",
      "| fps                | 281      |\n",
      "| nupdates           | 11000    |\n",
      "| policy_entropy     | 0.0606   |\n",
      "| total_timesteps    | 55000    |\n",
      "| value_loss         | 1.05     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.26e+03 |\n",
      "| explained_variance | 0.00357  |\n",
      "| fps                | 281      |\n",
      "| nupdates           | 12000    |\n",
      "| policy_entropy     | 0.103    |\n",
      "| total_timesteps    | 60000    |\n",
      "| value_loss         | 0.117    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.26e+03 |\n",
      "| explained_variance | -0.691   |\n",
      "| fps                | 282      |\n",
      "| nupdates           | 13000    |\n",
      "| policy_entropy     | 0.0133   |\n",
      "| total_timesteps    | 65000    |\n",
      "| value_loss         | 0.184    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.27e+03 |\n",
      "| explained_variance | 0.00282  |\n",
      "| fps                | 282      |\n",
      "| nupdates           | 14000    |\n",
      "| policy_entropy     | 0.0216   |\n",
      "| total_timesteps    | 70000    |\n",
      "| value_loss         | 1.14     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.28e+03 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 283      |\n",
      "| nupdates           | 15000    |\n",
      "| policy_entropy     | 0.011    |\n",
      "| total_timesteps    | 75000    |\n",
      "| value_loss         | 0.325    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.29e+03 |\n",
      "| explained_variance | 0.00315  |\n",
      "| fps                | 283      |\n",
      "| nupdates           | 16000    |\n",
      "| policy_entropy     | 0.0119   |\n",
      "| total_timesteps    | 80000    |\n",
      "| value_loss         | 0.13     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.29e+03 |\n",
      "| explained_variance | 0.0184   |\n",
      "| fps                | 283      |\n",
      "| nupdates           | 17000    |\n",
      "| policy_entropy     | 0.0209   |\n",
      "| total_timesteps    | 85000    |\n",
      "| value_loss         | 0.293    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.3e+03  |\n",
      "| explained_variance | 5.36e-07 |\n",
      "| fps                | 282      |\n",
      "| nupdates           | 18000    |\n",
      "| policy_entropy     | 0.176    |\n",
      "| total_timesteps    | 90000    |\n",
      "| value_loss         | 4.78     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.28e+03 |\n",
      "| explained_variance | -0.631   |\n",
      "| fps                | 282      |\n",
      "| nupdates           | 19000    |\n",
      "| policy_entropy     | 0.0217   |\n",
      "| total_timesteps    | 95000    |\n",
      "| value_loss         | 0.248    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.29e+03 |\n",
      "| explained_variance | -0.071   |\n",
      "| fps                | 281      |\n",
      "| nupdates           | 20000    |\n",
      "| policy_entropy     | 0.0988   |\n",
      "| total_timesteps    | 100000   |\n",
      "| value_loss         | 0.118    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.29e+03 |\n",
      "| explained_variance | 0.0626   |\n",
      "| fps                | 281      |\n",
      "| nupdates           | 21000    |\n",
      "| policy_entropy     | 0.0694   |\n",
      "| total_timesteps    | 105000   |\n",
      "| value_loss         | 0.817    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.3e+03  |\n",
      "| explained_variance | -0.138   |\n",
      "| fps                | 281      |\n",
      "| nupdates           | 22000    |\n",
      "| policy_entropy     | 0.453    |\n",
      "| total_timesteps    | 110000   |\n",
      "| value_loss         | 6.39     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.29e+03 |\n",
      "| explained_variance | 0.242    |\n",
      "| fps                | 281      |\n",
      "| nupdates           | 23000    |\n",
      "| policy_entropy     | 0.0788   |\n",
      "| total_timesteps    | 115000   |\n",
      "| value_loss         | 0.13     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.3e+03  |\n",
      "| explained_variance | -0.0117  |\n",
      "| fps                | 281      |\n",
      "| nupdates           | 24000    |\n",
      "| policy_entropy     | 0.00525  |\n",
      "| total_timesteps    | 120000   |\n",
      "| value_loss         | 0.181    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.3e+03  |\n",
      "| explained_variance | -0.0371  |\n",
      "| fps                | 281      |\n",
      "| nupdates           | 25000    |\n",
      "| policy_entropy     | 0.0719   |\n",
      "| total_timesteps    | 125000   |\n",
      "| value_loss         | 2.36     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -0.0191  |\n",
      "| fps                | 281      |\n",
      "| nupdates           | 26000    |\n",
      "| policy_entropy     | 0.0134   |\n",
      "| total_timesteps    | 130000   |\n",
      "| value_loss         | 3.86     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.00257  |\n",
      "| fps                | 280      |\n",
      "| nupdates           | 27000    |\n",
      "| policy_entropy     | 0.219    |\n",
      "| total_timesteps    | 135000   |\n",
      "| value_loss         | 0.157    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.3e+03  |\n",
      "| explained_variance | 0.286    |\n",
      "| fps                | 281      |\n",
      "| nupdates           | 28000    |\n",
      "| policy_entropy     | 0.056    |\n",
      "| total_timesteps    | 140000   |\n",
      "| value_loss         | 0.641    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.0554   |\n",
      "| fps                | 281      |\n",
      "| nupdates           | 29000    |\n",
      "| policy_entropy     | 0.142    |\n",
      "| total_timesteps    | 145000   |\n",
      "| value_loss         | 1.24     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.115    |\n",
      "| fps                | 280      |\n",
      "| nupdates           | 30000    |\n",
      "| policy_entropy     | 0.0171   |\n",
      "| total_timesteps    | 150000   |\n",
      "| value_loss         | 1.18     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.188    |\n",
      "| fps                | 281      |\n",
      "| nupdates           | 31000    |\n",
      "| policy_entropy     | 0.0214   |\n",
      "| total_timesteps    | 155000   |\n",
      "| value_loss         | 0.167    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -0.802   |\n",
      "| fps                | 280      |\n",
      "| nupdates           | 32000    |\n",
      "| policy_entropy     | 0.0575   |\n",
      "| total_timesteps    | 160000   |\n",
      "| value_loss         | 0.137    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.32e+03 |\n",
      "| explained_variance | 0.112    |\n",
      "| fps                | 280      |\n",
      "| nupdates           | 33000    |\n",
      "| policy_entropy     | 0.148    |\n",
      "| total_timesteps    | 165000   |\n",
      "| value_loss         | 0.365    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.32e+03 |\n",
      "| explained_variance | -0.141   |\n",
      "| fps                | 280      |\n",
      "| nupdates           | 34000    |\n",
      "| policy_entropy     | 0.00932  |\n",
      "| total_timesteps    | 170000   |\n",
      "| value_loss         | 1.44     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.59     |\n",
      "| fps                | 280      |\n",
      "| nupdates           | 35000    |\n",
      "| policy_entropy     | 0.0804   |\n",
      "| total_timesteps    | 175000   |\n",
      "| value_loss         | 0.223    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.273    |\n",
      "| fps                | 280      |\n",
      "| nupdates           | 36000    |\n",
      "| policy_entropy     | 0.359    |\n",
      "| total_timesteps    | 180000   |\n",
      "| value_loss         | 0.474    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.0805   |\n",
      "| fps                | 280      |\n",
      "| nupdates           | 37000    |\n",
      "| policy_entropy     | 0.198    |\n",
      "| total_timesteps    | 185000   |\n",
      "| value_loss         | 0.469    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -0.884   |\n",
      "| fps                | 280      |\n",
      "| nupdates           | 38000    |\n",
      "| policy_entropy     | 0.152    |\n",
      "| total_timesteps    | 190000   |\n",
      "| value_loss         | 0.0323   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -1.85    |\n",
      "| fps                | 280      |\n",
      "| nupdates           | 39000    |\n",
      "| policy_entropy     | 0.0323   |\n",
      "| total_timesteps    | 195000   |\n",
      "| value_loss         | 0.76     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.3e+03  |\n",
      "| explained_variance | 0.114    |\n",
      "| fps                | 280      |\n",
      "| nupdates           | 40000    |\n",
      "| policy_entropy     | 0.0563   |\n",
      "| total_timesteps    | 200000   |\n",
      "| value_loss         | 0.443    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.0605   |\n",
      "| fps                | 279      |\n",
      "| nupdates           | 41000    |\n",
      "| policy_entropy     | 0.0153   |\n",
      "| total_timesteps    | 205000   |\n",
      "| value_loss         | 0.0301   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -0.0246  |\n",
      "| fps                | 279      |\n",
      "| nupdates           | 42000    |\n",
      "| policy_entropy     | 0.188    |\n",
      "| total_timesteps    | 210000   |\n",
      "| value_loss         | 0.566    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.0149   |\n",
      "| fps                | 278      |\n",
      "| nupdates           | 43000    |\n",
      "| policy_entropy     | 0.115    |\n",
      "| total_timesteps    | 215000   |\n",
      "| value_loss         | 4.25     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.03     |\n",
      "| fps                | 278      |\n",
      "| nupdates           | 44000    |\n",
      "| policy_entropy     | 0.151    |\n",
      "| total_timesteps    | 220000   |\n",
      "| value_loss         | 2.63     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.0329   |\n",
      "| fps                | 278      |\n",
      "| nupdates           | 45000    |\n",
      "| policy_entropy     | 0.0118   |\n",
      "| total_timesteps    | 225000   |\n",
      "| value_loss         | 2.23     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.003    |\n",
      "| fps                | 278      |\n",
      "| nupdates           | 46000    |\n",
      "| policy_entropy     | 0.19     |\n",
      "| total_timesteps    | 230000   |\n",
      "| value_loss         | 1.65     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.184    |\n",
      "| fps                | 278      |\n",
      "| nupdates           | 47000    |\n",
      "| policy_entropy     | 0.00723  |\n",
      "| total_timesteps    | 235000   |\n",
      "| value_loss         | 0.0274   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -0.095   |\n",
      "| fps                | 278      |\n",
      "| nupdates           | 48000    |\n",
      "| policy_entropy     | 0.0342   |\n",
      "| total_timesteps    | 240000   |\n",
      "| value_loss         | 0.138    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -0.108   |\n",
      "| fps                | 278      |\n",
      "| nupdates           | 49000    |\n",
      "| policy_entropy     | 0.0604   |\n",
      "| total_timesteps    | 245000   |\n",
      "| value_loss         | 0.127    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.108    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 50000    |\n",
      "| policy_entropy     | 0.146    |\n",
      "| total_timesteps    | 250000   |\n",
      "| value_loss         | 0.465    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.0368   |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 51000    |\n",
      "| policy_entropy     | 0.175    |\n",
      "| total_timesteps    | 255000   |\n",
      "| value_loss         | 1.23     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -1.2     |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 52000    |\n",
      "| policy_entropy     | 0.167    |\n",
      "| total_timesteps    | 260000   |\n",
      "| value_loss         | 4.02     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -0.0118  |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 53000    |\n",
      "| policy_entropy     | 0.0315   |\n",
      "| total_timesteps    | 265000   |\n",
      "| value_loss         | 0.395    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -0.0111  |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 54000    |\n",
      "| policy_entropy     | 0.0651   |\n",
      "| total_timesteps    | 270000   |\n",
      "| value_loss         | 0.574    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -0.166   |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 55000    |\n",
      "| policy_entropy     | 0.0304   |\n",
      "| total_timesteps    | 275000   |\n",
      "| value_loss         | 1.54     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.192    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 56000    |\n",
      "| policy_entropy     | 0.00278  |\n",
      "| total_timesteps    | 280000   |\n",
      "| value_loss         | 0.0889   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.0943   |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 57000    |\n",
      "| policy_entropy     | 0.337    |\n",
      "| total_timesteps    | 285000   |\n",
      "| value_loss         | 0.626    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.298    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 58000    |\n",
      "| policy_entropy     | 0.0819   |\n",
      "| total_timesteps    | 290000   |\n",
      "| value_loss         | 0.0822   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.3e+03  |\n",
      "| explained_variance | -1.34    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 59000    |\n",
      "| policy_entropy     | 0.14     |\n",
      "| total_timesteps    | 295000   |\n",
      "| value_loss         | 0.429    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.3e+03  |\n",
      "| explained_variance | -3.38    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 60000    |\n",
      "| policy_entropy     | 0.0244   |\n",
      "| total_timesteps    | 300000   |\n",
      "| value_loss         | 0.178    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.3e+03  |\n",
      "| explained_variance | -0.0407  |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 61000    |\n",
      "| policy_entropy     | 0.0237   |\n",
      "| total_timesteps    | 305000   |\n",
      "| value_loss         | 0.00859  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.3e+03  |\n",
      "| explained_variance | 0.519    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 62000    |\n",
      "| policy_entropy     | 0.0109   |\n",
      "| total_timesteps    | 310000   |\n",
      "| value_loss         | 0.00999  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.3e+03  |\n",
      "| explained_variance | 0.477    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 63000    |\n",
      "| policy_entropy     | 0.0418   |\n",
      "| total_timesteps    | 315000   |\n",
      "| value_loss         | 0.777    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -0.025   |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 64000    |\n",
      "| policy_entropy     | 0.0406   |\n",
      "| total_timesteps    | 320000   |\n",
      "| value_loss         | 0.582    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -0.508   |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 65000    |\n",
      "| policy_entropy     | 0.0181   |\n",
      "| total_timesteps    | 325000   |\n",
      "| value_loss         | 0.0129   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.14     |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 66000    |\n",
      "| policy_entropy     | 0.00115  |\n",
      "| total_timesteps    | 330000   |\n",
      "| value_loss         | 1.06     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.32e+03 |\n",
      "| explained_variance | 0.0618   |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 67000    |\n",
      "| policy_entropy     | 0.0731   |\n",
      "| total_timesteps    | 335000   |\n",
      "| value_loss         | 0.0963   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 0.156    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 68000    |\n",
      "| policy_entropy     | 0.00386  |\n",
      "| total_timesteps    | 340000   |\n",
      "| value_loss         | 0.249    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -2.79    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 69000    |\n",
      "| policy_entropy     | 0.0598   |\n",
      "| total_timesteps    | 345000   |\n",
      "| value_loss         | 0.423    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -0.127   |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 70000    |\n",
      "| policy_entropy     | 0.00604  |\n",
      "| total_timesteps    | 350000   |\n",
      "| value_loss         | 0.778    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.32e+03 |\n",
      "| explained_variance | -0.128   |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 71000    |\n",
      "| policy_entropy     | 0.00296  |\n",
      "| total_timesteps    | 355000   |\n",
      "| value_loss         | 0.00352  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.32e+03 |\n",
      "| explained_variance | -1.12    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 72000    |\n",
      "| policy_entropy     | 0.000518 |\n",
      "| total_timesteps    | 360000   |\n",
      "| value_loss         | 0.223    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.32e+03 |\n",
      "| explained_variance | -0.41    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 73000    |\n",
      "| policy_entropy     | 0.0135   |\n",
      "| total_timesteps    | 365000   |\n",
      "| value_loss         | 0.105    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.32e+03 |\n",
      "| explained_variance | 0.091    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 74000    |\n",
      "| policy_entropy     | 0.0136   |\n",
      "| total_timesteps    | 370000   |\n",
      "| value_loss         | 0.443    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -1.97    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 75000    |\n",
      "| policy_entropy     | 0.00918  |\n",
      "| total_timesteps    | 375000   |\n",
      "| value_loss         | 0.997    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -0.166   |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 76000    |\n",
      "| policy_entropy     | 0.00561  |\n",
      "| total_timesteps    | 380000   |\n",
      "| value_loss         | 0.796    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -0.0537  |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 77000    |\n",
      "| policy_entropy     | 0.00727  |\n",
      "| total_timesteps    | 385000   |\n",
      "| value_loss         | 0.458    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | 1.53e-05 |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 78000    |\n",
      "| policy_entropy     | 0.00835  |\n",
      "| total_timesteps    | 390000   |\n",
      "| value_loss         | 0.318    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.31e+03 |\n",
      "| explained_variance | -8.22    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 79000    |\n",
      "| policy_entropy     | 0.00971  |\n",
      "| total_timesteps    | 395000   |\n",
      "| value_loss         | 3.22     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.3e+03  |\n",
      "| explained_variance | -0.627   |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 80000    |\n",
      "| policy_entropy     | 0.0123   |\n",
      "| total_timesteps    | 400000   |\n",
      "| value_loss         | 0.134    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.3e+03  |\n",
      "| explained_variance | 0.098    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 81000    |\n",
      "| policy_entropy     | 0.00227  |\n",
      "| total_timesteps    | 405000   |\n",
      "| value_loss         | 0.0141   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.29e+03 |\n",
      "| explained_variance | 0.429    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 82000    |\n",
      "| policy_entropy     | 0.0102   |\n",
      "| total_timesteps    | 410000   |\n",
      "| value_loss         | 0.13     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.3e+03  |\n",
      "| explained_variance | -0.00494 |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 83000    |\n",
      "| policy_entropy     | 0.00447  |\n",
      "| total_timesteps    | 415000   |\n",
      "| value_loss         | 0.372    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.3e+03  |\n",
      "| explained_variance | -0.142   |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 84000    |\n",
      "| policy_entropy     | 0.000931 |\n",
      "| total_timesteps    | 420000   |\n",
      "| value_loss         | 1.28     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.29e+03 |\n",
      "| explained_variance | 0.319    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 85000    |\n",
      "| policy_entropy     | 0.00899  |\n",
      "| total_timesteps    | 425000   |\n",
      "| value_loss         | 0.051    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.28e+03 |\n",
      "| explained_variance | 1.19e-07 |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 86000    |\n",
      "| policy_entropy     | 0.00817  |\n",
      "| total_timesteps    | 430000   |\n",
      "| value_loss         | 0.112    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.28e+03 |\n",
      "| explained_variance | -0.93    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 87000    |\n",
      "| policy_entropy     | 0.00521  |\n",
      "| total_timesteps    | 435000   |\n",
      "| value_loss         | 0.265    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.28e+03 |\n",
      "| explained_variance | -0.566   |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 88000    |\n",
      "| policy_entropy     | 0.00298  |\n",
      "| total_timesteps    | 440000   |\n",
      "| value_loss         | 0.023    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.28e+03 |\n",
      "| explained_variance | 0.024    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 89000    |\n",
      "| policy_entropy     | 0.0562   |\n",
      "| total_timesteps    | 445000   |\n",
      "| value_loss         | 0.571    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.28e+03 |\n",
      "| explained_variance | -0.996   |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 90000    |\n",
      "| policy_entropy     | 0.0952   |\n",
      "| total_timesteps    | 450000   |\n",
      "| value_loss         | 0.00485  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.28e+03 |\n",
      "| explained_variance | -0.421   |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 91000    |\n",
      "| policy_entropy     | 0.000135 |\n",
      "| total_timesteps    | 455000   |\n",
      "| value_loss         | 1.02     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.28e+03 |\n",
      "| explained_variance | -0.0137  |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 92000    |\n",
      "| policy_entropy     | 0.139    |\n",
      "| total_timesteps    | 460000   |\n",
      "| value_loss         | 2.41     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.28e+03 |\n",
      "| explained_variance | -0.0703  |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 93000    |\n",
      "| policy_entropy     | 0.0751   |\n",
      "| total_timesteps    | 465000   |\n",
      "| value_loss         | 0.198    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.27e+03 |\n",
      "| explained_variance | 0        |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 94000    |\n",
      "| policy_entropy     | 0.205    |\n",
      "| total_timesteps    | 470000   |\n",
      "| value_loss         | 0.182    |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| ep_len_mean        | 4.1e+03   |\n",
      "| ep_reward_mean     | 3.27e+03  |\n",
      "| explained_variance | -0.000975 |\n",
      "| fps                | 277       |\n",
      "| nupdates           | 95000     |\n",
      "| policy_entropy     | 0.0622    |\n",
      "| total_timesteps    | 475000    |\n",
      "| value_loss         | 0.0587    |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.27e+03 |\n",
      "| explained_variance | -0.157   |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 96000    |\n",
      "| policy_entropy     | 0.00702  |\n",
      "| total_timesteps    | 480000   |\n",
      "| value_loss         | 0.833    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.27e+03 |\n",
      "| explained_variance | -0.417   |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 97000    |\n",
      "| policy_entropy     | 0.00927  |\n",
      "| total_timesteps    | 485000   |\n",
      "| value_loss         | 0.544    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.27e+03 |\n",
      "| explained_variance | -1.58    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 98000    |\n",
      "| policy_entropy     | 0.068    |\n",
      "| total_timesteps    | 490000   |\n",
      "| value_loss         | 0.721    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.27e+03 |\n",
      "| explained_variance | -2.29    |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 99000    |\n",
      "| policy_entropy     | 0.0125   |\n",
      "| total_timesteps    | 495000   |\n",
      "| value_loss         | 1.36     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 4.1e+03  |\n",
      "| ep_reward_mean     | 3.27e+03 |\n",
      "| explained_variance | 0.13     |\n",
      "| fps                | 277      |\n",
      "| nupdates           | 100000   |\n",
      "| policy_entropy     | 0.000937 |\n",
      "| total_timesteps    | 500000   |\n",
      "| value_loss         | 0.304    |\n",
      "---------------------------------\n",
      "DQN Training Time: 1801.4347758293152\n"
     ]
    }
   ],
   "source": [
    "def ids_dqn():\n",
    "#     logger.configure(dir=os.path.join(os.getcwd(),'Training/Logs/ids_dqn'), format_strs=['stdout', 'tensorboard'])\n",
    "    env = IdsEnv(images_per_episode=4096)\n",
    "    env = bench.Monitor(env, logger.get_dir())\n",
    "\n",
    "    model = A2C(\n",
    "        MlpPolicy, \n",
    "        env, \n",
    "        verbose=1, \n",
    "    ).learn(\n",
    "        total_timesteps=int(5.0e5),\n",
    "        log_interval=1000\n",
    "    )\n",
    "\n",
    "    model.save('ddqn_stableb2_ids.pkl')\n",
    "    env.close()\n",
    "    \n",
    "    return model\n",
    "\n",
    "start_time = time.time()\n",
    "dqn_model = ids_dqn()\n",
    "print(\"DQN Training Time:\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation done...\n",
      "Accuracy: 57.15617715617716%\n"
     ]
    }
   ],
   "source": [
    "def ids_dqn_eval(dqn_model):\n",
    "    attempts, correct = 0,0\n",
    "\n",
    "    env = IdsEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            obs, done = env.reset(), False\n",
    "            while not done:\n",
    "                obs, rew, done, _ = env.step(dqn_model.predict(obs)[0])\n",
    "\n",
    "                attempts += 1\n",
    "                if rew > 0:\n",
    "                    correct += 1\n",
    "\n",
    "    except StopIteration:\n",
    "        print()\n",
    "        print('validation done...')\n",
    "        print('Accuracy: {0}%'.format((float(correct) / attempts) * 100))\n",
    "\n",
    "ids_dqn_eval(dqn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
