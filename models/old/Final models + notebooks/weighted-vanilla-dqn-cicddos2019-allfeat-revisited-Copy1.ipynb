{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'baselines' already exists and is not an empty directory.\n",
      "/project/finals/baselines\n",
      "Obtaining file:///project/finals/baselines\n",
      "Requirement already satisfied: gym<0.16.0,>=0.15.4 in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (0.15.7)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (1.4.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (4.46.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (0.15.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (1.2.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (7.1.2)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /opt/conda/lib/python3.7/site-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.18.5)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.5.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.15.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym<0.16.0,>=0.15.4->baselines==0.1.6) (0.18.2)\n",
      "Installing collected packages: baselines\n",
      "  Attempting uninstall: baselines\n",
      "    Found existing installation: baselines 0.1.6\n",
      "    Uninstalling baselines-0.1.6:\n",
      "      Successfully uninstalled baselines-0.1.6\n",
      "  Running setup.py develop for baselines\n",
      "Successfully installed baselines\n",
      "Requirement already satisfied: stable-baselines in /opt/conda/lib/python3.7/site-packages (2.10.2)\n",
      "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (0.15.7)\n",
      "Requirement already satisfied: cloudpickle>=0.5.5 in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (1.2.2)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (4.5.5.64)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (3.2.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (0.15.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (1.0.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (1.18.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (1.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines) (1.15.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines) (1.5.0)\n",
      "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines) (0.2.9)\n",
      "Requirement already satisfied: Pillow; extra == \"atari\" in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines) (7.1.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->stable-baselines) (2020.1)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines) (0.18.2)\n",
      "Requirement already up-to-date: tensorflow==1.14.0 in /opt/conda/lib/python3.7/site-packages (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<1.15.0,>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (3.11.4)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.29.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (47.1.1.post20200529)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.6.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.0)\n",
      "Requirement already up-to-date: tensorflow-gpu==1.14.0 in /opt/conda/lib/python3.7/site-packages (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.29.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<1.15.0,>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (3.11.4)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (47.1.1.post20200529)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.6.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.1.0)\n",
      "Requirement already satisfied: gym in /opt/conda/lib/python3.7/site-packages (0.15.7)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /opt/conda/lib/python3.7/site-packages (from gym) (1.18.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from gym) (1.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gym) (1.15.0)\n",
      "Requirement already satisfied: cloudpickle~=1.2.0 in /opt/conda/lib/python3.7/site-packages (from gym) (1.2.2)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.18.2)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.7/site-packages (7.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from pyarrow) (1.18.5)\n",
      "\u001b[33mWARNING: Skipping tensorboard-plugin-wit as it is not installed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/openai/baselines.git\n",
    "%cd baselines\n",
    "!pip install -e .\n",
    "!pip install stable-baselines\n",
    "!pip install --upgrade tensorflow==1.14.0\n",
    "!pip install --upgrade tensorflow-gpu==1.14.0\n",
    "!pip install gym\n",
    "!pip install pyarrow\n",
    "!pip uninstall --yes tensorboard-plugin-wit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 12807137755298128129,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 2699991184967703285\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 14819685690018880732\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gym\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from datetime import datetime\n",
    "\n",
    "from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "\n",
    "from stable_baselines import deepq\n",
    "from stable_baselines import bench\n",
    "from stable_baselines import logger\n",
    "import tensorflow as tf\n",
    "\n",
    "from baselines.common.tf_util import make_session\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/finals\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "logdir = \"Training/Logs/DQN/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Fwd Packets Length Total</th>\n",
       "      <th>Bwd Packets Length Total</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2944.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DrDoS_DNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2896.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1448.0</td>\n",
       "      <td>1448.0</td>\n",
       "      <td>1448.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DrDoS_DNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2526.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DrDoS_DNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2944.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DrDoS_DNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2944.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DrDoS_DNS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "0              1                  2                       0   \n",
       "1              1                  2                       0   \n",
       "2              1                  2                       0   \n",
       "3              1                  2                       0   \n",
       "4              1                  2                       0   \n",
       "\n",
       "   Fwd Packets Length Total  Bwd Packets Length Total  Fwd Packet Length Max  \\\n",
       "0                    2944.0                       0.0                 1472.0   \n",
       "1                    2896.0                       0.0                 1448.0   \n",
       "2                    2526.0                       0.0                 1263.0   \n",
       "3                    2944.0                       0.0                 1472.0   \n",
       "4                    2944.0                       0.0                 1472.0   \n",
       "\n",
       "   Fwd Packet Length Min  Fwd Packet Length Mean  Fwd Packet Length Std  \\\n",
       "0                 1472.0                  1472.0                    0.0   \n",
       "1                 1448.0                  1448.0                    0.0   \n",
       "2                 1263.0                  1263.0                    0.0   \n",
       "3                 1472.0                  1472.0                    0.0   \n",
       "4                 1472.0                  1472.0                    0.0   \n",
       "\n",
       "   Bwd Packet Length Max  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
       "0                    0.0  ...              1472          0.0         0.0   \n",
       "1                    0.0  ...              1480          0.0         0.0   \n",
       "2                    0.0  ...                 0          0.0         0.0   \n",
       "3                    0.0  ...                20          0.0         0.0   \n",
       "4                    0.0  ...                -1          0.0         0.0   \n",
       "\n",
       "   Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min      Label  \n",
       "0         0.0         0.0        0.0       0.0       0.0       0.0  DrDoS_DNS  \n",
       "1         0.0         0.0        0.0       0.0       0.0       0.0  DrDoS_DNS  \n",
       "2         0.0         0.0        0.0       0.0       0.0       0.0  DrDoS_DNS  \n",
       "3         0.0         0.0        0.0       0.0       0.0       0.0  DrDoS_DNS  \n",
       "4         0.0         0.0        0.0       0.0       0.0       0.0  DrDoS_DNS  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cicddos2019 = pd.read_feather(\"/project/datasets/clean-ids-collection/cic-ddos2019/clean/cicddos2019.feather\")\n",
    "# cicdos2017 = pd.read_feather(\"/project/datasets/clean-ids-collection/cic-dos2017/clean/cicdos2017.feather\")\n",
    "# cicids2017 = pd.read_feather(\"/project/datasets/clean-ids-collection/cic-ids2017/clean/cicids2017.feather\")\n",
    "data = pd.concat([cicddos2019], ignore_index=True)\n",
    "print(len(data.columns))\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "cicdos2017_features = [\"Init Bwd Win Bytes\",  \"Idle Min\", \"ACK Flag Count\", \"Fwd Packet Length Min\", \"Fwd PSH Flags\"]\n",
    "cicids2017_features = [\"Protocol\", \"Avg Bwd Segment Size\", \"Packet Length Max\", \"Bwd Packet Length Min\", \"Fwd IAT Mean\"]\n",
    "cicddos2019_features = [\"URG Flag Count\", \"Down/Up Ratio\", \"Bwd Packet Length Min\", \"ACK Flag Count\", \"Fwd Packets Length Total\"]\n",
    "important_features = cicddos2019_features + [\"Label\", \"Timestamp\"] # Adding Timestamp for custom environment logic\n",
    "important_features = list(set(important_features))\n",
    "print(len(important_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removable_features = data.columns ^ important_features\n",
    "# print(removable_features.shape)\n",
    "# skinny_data = data.drop(labels=removable_features, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 138007 entries, 0 to 138006\n",
      "Data columns (total 67 columns):\n",
      " #   Column                    Non-Null Count   Dtype   \n",
      "---  ------                    --------------   -----   \n",
      " 0   Flow Duration             138007 non-null  int32   \n",
      " 1   Total Fwd Packets         138007 non-null  int16   \n",
      " 2   Total Backward Packets    138007 non-null  int16   \n",
      " 3   Fwd Packets Length Total  138007 non-null  float32 \n",
      " 4   Bwd Packets Length Total  138007 non-null  float32 \n",
      " 5   Fwd Packet Length Max     138007 non-null  float32 \n",
      " 6   Fwd Packet Length Min     138007 non-null  float32 \n",
      " 7   Fwd Packet Length Mean    138007 non-null  float32 \n",
      " 8   Fwd Packet Length Std     138007 non-null  float32 \n",
      " 9   Bwd Packet Length Max     138007 non-null  float32 \n",
      " 10  Bwd Packet Length Min     138007 non-null  float32 \n",
      " 11  Bwd Packet Length Mean    138007 non-null  float32 \n",
      " 12  Bwd Packet Length Std     138007 non-null  float32 \n",
      " 13  Flow Bytes/s              138007 non-null  float32 \n",
      " 14  Flow Packets/s            138007 non-null  float32 \n",
      " 15  Flow IAT Mean             138007 non-null  float32 \n",
      " 16  Flow IAT Std              138007 non-null  float32 \n",
      " 17  Flow IAT Max              138007 non-null  float32 \n",
      " 18  Flow IAT Min              138007 non-null  float32 \n",
      " 19  Fwd IAT Total             138007 non-null  float32 \n",
      " 20  Fwd IAT Mean              138007 non-null  float32 \n",
      " 21  Fwd IAT Std               138007 non-null  float32 \n",
      " 22  Fwd IAT Max               138007 non-null  float32 \n",
      " 23  Fwd IAT Min               138007 non-null  float32 \n",
      " 24  Bwd IAT Total             138007 non-null  float32 \n",
      " 25  Bwd IAT Mean              138007 non-null  float32 \n",
      " 26  Bwd IAT Std               138007 non-null  float32 \n",
      " 27  Bwd IAT Max               138007 non-null  float32 \n",
      " 28  Bwd IAT Min               138007 non-null  float32 \n",
      " 29  Fwd PSH Flags             138007 non-null  int8    \n",
      " 30  Fwd Header Length         138007 non-null  int64   \n",
      " 31  Bwd Header Length         138007 non-null  int64   \n",
      " 32  Fwd Packets/s             138007 non-null  float32 \n",
      " 33  Bwd Packets/s             138007 non-null  float32 \n",
      " 34  Packet Length Min         138007 non-null  float32 \n",
      " 35  Packet Length Max         138007 non-null  float32 \n",
      " 36  Packet Length Mean        138007 non-null  float32 \n",
      " 37  Packet Length Std         138007 non-null  float32 \n",
      " 38  Packet Length Variance    138007 non-null  float32 \n",
      " 39  FIN Flag Count            138007 non-null  int8    \n",
      " 40  SYN Flag Count            138007 non-null  int8    \n",
      " 41  RST Flag Count            138007 non-null  int8    \n",
      " 42  PSH Flag Count            138007 non-null  int8    \n",
      " 43  ACK Flag Count            138007 non-null  int8    \n",
      " 44  URG Flag Count            138007 non-null  int8    \n",
      " 45  ECE Flag Count            138007 non-null  int8    \n",
      " 46  Down/Up Ratio             138007 non-null  float32 \n",
      " 47  Avg Packet Size           138007 non-null  float32 \n",
      " 48  Avg Fwd Segment Size      138007 non-null  float32 \n",
      " 49  Avg Bwd Segment Size      138007 non-null  float32 \n",
      " 50  Subflow Fwd Packets       138007 non-null  int16   \n",
      " 51  Subflow Fwd Bytes         138007 non-null  int32   \n",
      " 52  Subflow Bwd Packets       138007 non-null  int16   \n",
      " 53  Subflow Bwd Bytes         138007 non-null  int32   \n",
      " 54  Init Fwd Win Bytes        138007 non-null  int32   \n",
      " 55  Init Bwd Win Bytes        138007 non-null  int32   \n",
      " 56  Fwd Act Data Packets      138007 non-null  int16   \n",
      " 57  Fwd Seg Size Min          138007 non-null  int32   \n",
      " 58  Active Mean               138007 non-null  float32 \n",
      " 59  Active Std                138007 non-null  float32 \n",
      " 60  Active Max                138007 non-null  float32 \n",
      " 61  Active Min                138007 non-null  float32 \n",
      " 62  Idle Mean                 138007 non-null  float32 \n",
      " 63  Idle Std                  138007 non-null  float32 \n",
      " 64  Idle Max                  138007 non-null  float32 \n",
      " 65  Idle Min                  138007 non-null  float32 \n",
      " 66  Label                     138007 non-null  category\n",
      "dtypes: category(1), float32(45), int16(5), int32(6), int64(2), int8(8)\n",
      "memory usage: 31.5 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Fwd Packets Length Total</th>\n",
       "      <th>Bwd Packets Length Total</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Act Data Packets</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.035663e+07</td>\n",
       "      <td>13.812169</td>\n",
       "      <td>6.636576</td>\n",
       "      <td>4.018699e+03</td>\n",
       "      <td>5.101797e+03</td>\n",
       "      <td>249.267242</td>\n",
       "      <td>132.858826</td>\n",
       "      <td>161.386505</td>\n",
       "      <td>37.345795</td>\n",
       "      <td>246.880920</td>\n",
       "      <td>...</td>\n",
       "      <td>10.525227</td>\n",
       "      <td>-1.175840e+07</td>\n",
       "      <td>7.345708e+04</td>\n",
       "      <td>3.066068e+04</td>\n",
       "      <td>1.140836e+05</td>\n",
       "      <td>5.479841e+04</td>\n",
       "      <td>3.445573e+06</td>\n",
       "      <td>3.282409e+05</td>\n",
       "      <td>3.770895e+06</td>\n",
       "      <td>3.153585e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.853154e+07</td>\n",
       "      <td>70.298079</td>\n",
       "      <td>99.503208</td>\n",
       "      <td>5.141442e+04</td>\n",
       "      <td>1.880300e+05</td>\n",
       "      <td>419.142181</td>\n",
       "      <td>234.306580</td>\n",
       "      <td>241.043732</td>\n",
       "      <td>116.252220</td>\n",
       "      <td>844.078186</td>\n",
       "      <td>...</td>\n",
       "      <td>62.973954</td>\n",
       "      <td>1.112129e+08</td>\n",
       "      <td>5.178554e+05</td>\n",
       "      <td>2.393170e+05</td>\n",
       "      <td>6.899452e+05</td>\n",
       "      <td>4.800613e+05</td>\n",
       "      <td>1.158292e+07</td>\n",
       "      <td>2.158994e+06</td>\n",
       "      <td>1.230213e+07</td>\n",
       "      <td>1.120664e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.408238e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.178000e+03</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.489200e+04</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.600000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.999380e+06</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.064000e+03</td>\n",
       "      <td>1.660000e+02</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>349.500000</td>\n",
       "      <td>14.433757</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.199987e+08</td>\n",
       "      <td>20444.000000</td>\n",
       "      <td>31700.000000</td>\n",
       "      <td>1.526642e+07</td>\n",
       "      <td>5.842950e+07</td>\n",
       "      <td>32120.000000</td>\n",
       "      <td>2131.000000</td>\n",
       "      <td>3015.290527</td>\n",
       "      <td>2221.556152</td>\n",
       "      <td>37960.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18766.000000</td>\n",
       "      <td>1.480000e+03</td>\n",
       "      <td>4.050800e+07</td>\n",
       "      <td>1.100562e+07</td>\n",
       "      <td>4.050800e+07</td>\n",
       "      <td>4.050800e+07</td>\n",
       "      <td>1.192194e+08</td>\n",
       "      <td>6.961402e+07</td>\n",
       "      <td>1.192194e+08</td>\n",
       "      <td>1.192194e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "count   1.380070e+05      138007.000000           138007.000000   \n",
       "mean    1.035663e+07          13.812169                6.636576   \n",
       "std     2.853154e+07          70.298079               99.503208   \n",
       "min     1.000000e+00           1.000000                0.000000   \n",
       "25%     1.178000e+03           2.000000                0.000000   \n",
       "50%     2.489200e+04           3.000000                2.000000   \n",
       "75%     2.999380e+06           8.000000                2.000000   \n",
       "max     1.199987e+08       20444.000000            31700.000000   \n",
       "\n",
       "       Fwd Packets Length Total  Bwd Packets Length Total  \\\n",
       "count              1.380070e+05              1.380070e+05   \n",
       "mean               4.018699e+03              5.101797e+03   \n",
       "std                5.141442e+04              1.880300e+05   \n",
       "min                0.000000e+00              0.000000e+00   \n",
       "25%                1.800000e+01              0.000000e+00   \n",
       "50%                8.600000e+01              0.000000e+00   \n",
       "75%                2.064000e+03              1.660000e+02   \n",
       "max                1.526642e+07              5.842950e+07   \n",
       "\n",
       "       Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
       "count          138007.000000          138007.000000           138007.000000   \n",
       "mean              249.267242             132.858826              161.386505   \n",
       "std               419.142181             234.306580              241.043732   \n",
       "min                 0.000000               0.000000                0.000000   \n",
       "25%                 6.000000               0.000000                6.000000   \n",
       "50%                43.000000              30.000000               39.000000   \n",
       "75%               440.000000             152.000000              349.500000   \n",
       "max             32120.000000            2131.000000             3015.290527   \n",
       "\n",
       "       Fwd Packet Length Std  Bwd Packet Length Max  ...  \\\n",
       "count          138007.000000          138007.000000  ...   \n",
       "mean               37.345795             246.880920  ...   \n",
       "std               116.252220             844.078186  ...   \n",
       "min                 0.000000               0.000000  ...   \n",
       "25%                 0.000000               0.000000  ...   \n",
       "50%                 0.000000               0.000000  ...   \n",
       "75%                14.433757              80.000000  ...   \n",
       "max              2221.556152           37960.000000  ...   \n",
       "\n",
       "       Fwd Act Data Packets  Fwd Seg Size Min   Active Mean    Active Std  \\\n",
       "count         138007.000000      1.380070e+05  1.380070e+05  1.380070e+05   \n",
       "mean              10.525227     -1.175840e+07  7.345708e+04  3.066068e+04   \n",
       "std               62.973954      1.112129e+08  5.178554e+05  2.393170e+05   \n",
       "min                0.000000     -1.408238e+09  0.000000e+00  0.000000e+00   \n",
       "25%                1.000000      2.000000e+01  0.000000e+00  0.000000e+00   \n",
       "50%                1.000000      2.000000e+01  0.000000e+00  0.000000e+00   \n",
       "75%                5.000000      2.000000e+01  0.000000e+00  0.000000e+00   \n",
       "max            18766.000000      1.480000e+03  4.050800e+07  1.100562e+07   \n",
       "\n",
       "         Active Max    Active Min     Idle Mean      Idle Std      Idle Max  \\\n",
       "count  1.380070e+05  1.380070e+05  1.380070e+05  1.380070e+05  1.380070e+05   \n",
       "mean   1.140836e+05  5.479841e+04  3.445573e+06  3.282409e+05  3.770895e+06   \n",
       "std    6.899452e+05  4.800613e+05  1.158292e+07  2.158994e+06  1.230213e+07   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    4.050800e+07  4.050800e+07  1.192194e+08  6.961402e+07  1.192194e+08   \n",
       "\n",
       "           Idle Min  \n",
       "count  1.380070e+05  \n",
       "mean   3.153585e+06  \n",
       "std    1.120664e+07  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    1.192194e+08  \n",
       "\n",
       "[8 rows x 66 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing done by Laurens D'Hooge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n",
    "- Build an agent to classify network flow automatically\n",
    "- Feed a packet that gets classified\n",
    "- Want the classification to be equal to the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_dataset_sampler_df(df, train_frac=0.2, val_frac=0.1, test_frac=0.7):\n",
    "    col = df.columns[-1]\n",
    "    print(col)\n",
    "    cols = df.columns[:-1]\n",
    "    print(cols)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    n = vc.iloc[-1]\n",
    "    print(n)\n",
    "    m = vc.iloc[0]\n",
    "    print(m)\n",
    "    print(int(m-n))\n",
    "    initial_cut = df.loc[df[col] == vc.index[0]].sample(n=int(m-n), replace=False)\n",
    "    print(initial_cut.index)\n",
    "    df = df.drop(index=initial_cut.index)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    print(int(n*train_frac))\n",
    "    train_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*train_frac), replace=False))\n",
    "    train_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=train_df.index)\n",
    "\n",
    "    validation_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*val_frac), replace=False))\n",
    "    validation_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=validation_df.index)\n",
    "\n",
    "    test_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*test_frac), replace=False))\n",
    "    test_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=test_df.index)\n",
    "\n",
    "    return train_df[cols], train_df[col], validation_df[cols], validation_df[col], test_df[cols], test_df[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign           95092\n",
      "DrDoS_NTP        13687\n",
      "TFTP             13032\n",
      "Syn               6734\n",
      "UDP               2031\n",
      "MSSQL             1338\n",
      "DrDoS_MSSQL       1325\n",
      "DrDoS_UDP         1232\n",
      "UDP-lag           1083\n",
      "DrDoS_DNS          682\n",
      "DrDoS_SSDP         473\n",
      "DrDoS_SNMP         410\n",
      "LDAP               330\n",
      "DrDoS_LDAP         210\n",
      "DrDoS_NetBIOS      144\n",
      "Portmap            122\n",
      "NetBIOS             70\n",
      "UDPLag              10\n",
      "WebDDoS              2\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data.drop('Timestamp', inplace=True, axis=1)\n",
    "except:\n",
    "    pass\n",
    "print(data['Label'].value_counts())\n",
    "data['Label'] = data['Label'].astype('object')\n",
    "atk_idx = data.loc[data['Label'] != \"Benign\"].index\n",
    "data.loc[atk_idx, 'Label'] = 1.0\n",
    "data.loc[data.index.difference(atk_idx), 'Label'] = 0.0\n",
    "data['Label'] = data['Label'].astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "Index(['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',\n",
      "       'Fwd Packets Length Total', 'Bwd Packets Length Total',\n",
      "       'Fwd Packet Length Max', 'Fwd Packet Length Min',\n",
      "       'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n",
      "       'Bwd Packet Length Max', 'Bwd Packet Length Min',\n",
      "       'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n",
      "       'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
      "       'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
      "       'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
      "       'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n",
      "       'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s',\n",
      "       'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max',\n",
      "       'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance',\n",
      "       'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count',\n",
      "       'ACK Flag Count', 'URG Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
      "       'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
      "       'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets',\n",
      "       'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes',\n",
      "       'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std',\n",
      "       'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max',\n",
      "       'Idle Min'],\n",
      "      dtype='object')\n",
      "0.0    95092\n",
      "1.0    42915\n",
      "Name: Label, dtype: int64\n",
      "42915\n",
      "95092\n",
      "52177\n",
      "Int64Index([ 84553,  39403,   8726,    936,  57618,  41105,  75989,  56999,\n",
      "             64565,  93925,\n",
      "            ...\n",
      "            121323,  60387,  31045,  77455, 110579,  73652,  37544,  96452,\n",
      "             78202, 125274],\n",
      "           dtype='int64', length=52177)\n",
      "0.0    42915\n",
      "1.0    42915\n",
      "Name: Label, dtype: int64\n",
      "38623\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test  = balancing_dataset_sampler_df(data, train_frac=0.9, val_frac=0.0, test_frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "(77246, 66)\n",
      "(77246,)\n",
      "Validation\n",
      "(0, 66)\n",
      "(0,)\n",
      "Testing\n",
      "(8582, 66)\n",
      "(8582,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"Validation\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(\"Testing\")\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77246, 66)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([  5131,  64569,  92398,  30429, 117258, 133330,  30407,  86480,\n",
      "            109861, 103755,\n",
      "            ...\n",
      "             98717,  47602, 129650,   6199,  21788,    272,  91353,  55966,\n",
      "             14801, 129485],\n",
      "           dtype='int64', length=77246)\n",
      "Int64Index([  5131,  64569,  92398,  30429, 117258, 133330,  30407,  86480,\n",
      "            109861, 103755,\n",
      "            ...\n",
      "             98717,  47602, 129650,   6199,  21788,    272,  91353,  55966,\n",
      "             14801, 129485],\n",
      "           dtype='int64', length=77246)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.index)\n",
    "print(y_train.index)\n",
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom keys -> replace by index\n",
    "\n",
    "x_train = x_train.set_index([pd.Index(range (0, len(x_train)))])\n",
    "y_train = y_train.set_index([pd.Index(range (0, len(y_train)))])\n",
    "x_test = x_test.set_index([pd.Index(range (0, len(x_test)))])\n",
    "y_test = y_test.set_index([pd.Index(range (0, len(y_test)))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=77246, step=1)\n",
      "RangeIndex(start=0, stop=77246, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.index)\n",
    "print(y_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Label\n",
      "0        0.0\n",
      "1        0.0\n",
      "2        0.0\n",
      "3        0.0\n",
      "4        0.0\n",
      "...      ...\n",
      "77241    1.0\n",
      "77242    1.0\n",
      "77243    1.0\n",
      "77244    1.0\n",
      "77245    1.0\n",
      "\n",
      "[77246 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label    0.0\n",
      "Name: 17162, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "print(y_train.iloc[17162,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=77246, step=1)\n",
      "RangeIndex(start=0, stop=77246, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.index)\n",
    "print(x_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdsEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "        # Actions we can take, classify as malicious or non-malicious (later also the correct attack)\n",
    "        # change to 19 if detectiong all different attacks\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "         # All the features we have, len(important_features) - 1 features and 1 label. Label should not be included\n",
    "        self.observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(66,))\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "    \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "        current_label = self.expected_action\n",
    "        obs = self._next_obs()\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {'label': current_label}\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y.iloc[next_obs_idx,:])\n",
    "            obs = self.x.iloc[next_obs_idx,:]\n",
    "\n",
    "        else:\n",
    "            obs = self.x.iloc[self.dataset_idx]\n",
    "            self.expected_action = int(self.y.iloc[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "        return obs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tried hyperparams 1.0e5:\n",
    "####### 53-72 %\n",
    "# learning_rate=5e-4,\n",
    "#         buffer_size=50000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.02,\n",
    "#         train_freq=1,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=1000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=500,\n",
    "#         prioritized_replay=False,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "######## 69%\n",
    "# learning_rate=5e-4,\n",
    "#         buffer_size=50000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.02,\n",
    "#         train_freq=1,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=1000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=10000,\n",
    "#         prioritized_replay=False,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "######## 57 %\n",
    "# DEFAULT\n",
    "######## 59 %\n",
    "# DEFAULT w gamma = 1.0\n",
    "######## 53%\n",
    "# learning_rate=5e-4,\n",
    "#         buffer_size=1000000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.02,\n",
    "#         train_freq=1,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=50000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=500,\n",
    "#         prioritized_replay=False,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "######### 54%\n",
    "# learning_rate=5e-4,\n",
    "#         buffer_size=1000000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.02,\n",
    "#         train_freq=4,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=50000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=500,\n",
    "#         prioritized_replay=False,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "######## 52%\n",
    "# learning_rate=2.5e-4,\n",
    "#         buffer_size=1000000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.02,\n",
    "#         train_freq=4,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=50000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=500,\n",
    "#         prioritized_replay=False,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "######### 17%\n",
    "# learning_rate=2.5e-4,\n",
    "#         buffer_size=1000000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.02,\n",
    "#         train_freq=4,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=50000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=10000,\n",
    "#         prioritized_replay=False,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "### \\/\\/\\/\\/\\/ 1.0e6\n",
    "######### 63 %\n",
    "# learning_rate=2.5e-4,\n",
    "#         buffer_size=1000000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.1,\n",
    "#         train_freq=4,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=50000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=10000,\n",
    "#         prioritized_replay=False,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "######### 37%\n",
    "# gamma=1.0\n",
    "######### error\n",
    "# learning_rate= 5e-4\n",
    "######### 50%\n",
    "# final_explor_frac=0.01\n",
    "######### 50%\n",
    "# learning_rate=5e-4,\n",
    "#         buffer_size=1000000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.02,\n",
    "#         train_freq=4,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=50000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=10000,\n",
    "#         prioritized_replay=False,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "\n",
    "######### 46%\n",
    "# learning_rate=5e-4,\n",
    "#         buffer_size=1000000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.02,\n",
    "#         train_freq=4,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=50000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=10000,\n",
    "#         prioritized_replay=True\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "\n",
    "\n",
    "#### DEZE LAATSTE ZIJN SWS SLECHT DOOR TE KLEIN AANTAL EPISODES (OF WAARDES TE GROOT -> herschalen)\n",
    "\n",
    "##### NOG DOEN\n",
    "# TRAIN FREQ = 4\n",
    "# LEARNING RATE = 0.00025\n",
    "# TARGET NETWORK UPDATE FREQUENCY HOGER\n",
    "### TEST 59%\n",
    "# network='conv_only',\n",
    "#         lr=1e-4,\n",
    "#         buffer_size=10000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.01,\n",
    "#         train_freq=4,\n",
    "#         learning_starts=10000,\n",
    "#         target_network_update_freq=1000,\n",
    "#         gamma=0.99,\n",
    "#         prioritized_replay=True,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         checkpoint_freq=10000,\n",
    "#         checkpoint_path=None,\n",
    "#         dueling=True\n",
    "# ================ gamma:0.99, learning_rate:5.5e-05, final_eps: 0.0325 ==== (0.823, 0.3816687045069323) ===============\n",
    "# ================ gamma:1.0, learning_rate:3.2500000000000004e-05, final_eps: 0.0775 ==== (0.792, 0.4058768286069064) ===============     \n",
    "# ================ gamma:0.99, learning_rate:1e-05, final_eps: 0.05500000000000001 ==== (0.712, 0.45283109433871693) ===============\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train classifier using dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/deepq/dqn.py:129: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:359: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:139: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd2500923d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd2500923d0>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd2500923d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd2500923d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd250077ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd250077ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd250077ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd250077ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281afc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281afc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281afc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281afc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd23806c710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd23806c710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd23806c710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd23806c710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:149: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd238096a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd238096a90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd238096a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd238096a90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281af090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281af090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281af090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281af090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281af090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281af090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281af090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281af090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd238096590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd238096590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd238096590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd238096590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd22812ef90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd22812ef90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd22812ef90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd22812ef90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd228043250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd228043250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd228043250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd228043250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281af210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281af210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281af210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281af210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281af210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281af210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281af210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fd2281af210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:415: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:449: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 99       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 98       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 97       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 96       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 95       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 94       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 93       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 92       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 91       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 89       |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 88       |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 87       |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 86       |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 85       |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 84       |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 83       |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 82       |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 79       |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 78       |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 77       |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 76       |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 75       |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 74       |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 73       |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 71       |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 69       |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 68       |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 67       |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 66       |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 65       |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 64       |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 63       |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 61       |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 60       |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 59       |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 58       |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 57       |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 56       |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 55       |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 54       |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 53       |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 50       |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 49       |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 48       |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 47       |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 46       |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 45       |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 43       |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 42       |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 40       |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 40       |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 39       |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 38       |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 37       |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 36       |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 35       |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 34       |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 33       |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 32       |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 31       |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 29       |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 28       |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 27       |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 26       |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 25       |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 23       |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 22       |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 21       |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 19       |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 18       |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 17       |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 16       |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 15       |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 13       |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 12       |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 11       |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 9        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 8        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 6        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 4        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 101000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 100999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 102000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 101999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 103000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 102999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 104000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 103999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 105000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 104999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 106000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 105999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 107000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 106999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 108000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 107999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 109000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 108999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 110000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 109999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 111000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 110999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 112000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 111999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 113000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 112999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 114000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 113999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 115000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 114999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 116000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 115999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 117000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 116999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 118000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 117999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 119000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 118999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 120000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 119999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 121000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 120999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 122000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 121999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 123000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 122999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 124000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 123999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 125000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 124999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 126000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 125999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 127000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 126999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 128000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 127999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 129000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 128999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 130000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 129999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 131000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 130999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 132000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 131999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 133000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 132999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 134000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 133999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 135000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 134999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 136000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 135999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 137000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 136999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 138000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 137999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 139000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 138999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 140000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 139999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 141000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 140999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 142000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 141999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 143000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 142999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 144000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 143999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 145000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 144999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 146000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 145999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 147000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 146999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 148000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 147999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 149000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 148999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 150000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 149999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 151000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 150999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 152000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 151999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 153000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 152999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 154000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 153999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 155000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 154999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 156000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 155999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 157000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 156999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 158000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 157999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 159000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 158999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 160000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 159999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 161000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 160999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 162000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 161999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 163000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 162999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 164000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 163999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 165000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 164999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 166000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 165999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 167000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 166999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 168000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 167999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 169000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 168999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 170000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 169999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 171000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 170999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 172000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 171999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 173000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 172999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 174000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 173999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 175000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 174999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 176000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 175999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 177000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 176999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 178000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 177999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 179000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 178999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 180000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 179999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 181000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 180999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 182000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 181999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 183000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 182999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 184000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 183999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 185000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 184999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 186000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 185999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 187000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 186999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 188000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 187999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 189000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 188999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 190000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 189999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 191000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 190999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 192000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 191999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 193000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 192999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 194000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 193999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 195000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 194999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 196000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 195999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 197000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 196999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 198000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 197999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 199000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 198999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 200000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 199999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 201000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 200999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 202000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 201999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 203000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 202999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 204000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 203999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 205000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 204999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 206000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 205999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 207000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 206999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 208000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 207999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 209000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 208999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 210000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 209999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 211000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 210999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 212000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 211999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 213000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 212999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 214000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 213999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 215000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 214999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 216000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 215999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 217000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 216999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 218000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 217999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 219000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 218999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 220000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 219999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 221000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 220999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 222000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 221999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 223000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 222999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 224000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 223999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 225000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 224999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 226000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 225999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 227000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 226999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 228000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 227999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 229000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 228999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 230000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 229999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 231000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 230999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 232000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 231999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 233000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 232999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 234000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 233999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 235000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 234999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 236000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 235999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 237000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 236999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 238000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 237999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 239000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 238999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 240000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 239999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 241000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 240999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 242000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 241999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 243000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 242999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 244000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 243999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 245000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 244999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 246000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 245999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 247000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 246999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 248000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 247999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 249000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 248999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 250000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 249999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 251000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 250999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 252000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 251999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 253000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 252999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 254000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 253999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 255000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 254999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 256000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 255999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 257000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 256999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 258000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 257999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 259000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 258999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 260000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 259999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 261000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 260999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 262000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 261999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 263000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 262999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 264000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 263999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 265000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 264999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 266000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 265999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 267000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 266999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 268000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 267999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 269000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 268999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 270000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 269999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 271000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 270999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 272000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 271999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 273000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 272999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 274000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 273999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 275000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 274999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 276000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 275999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 277000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 276999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 278000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 277999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 279000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 278999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 280000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 279999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 281000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 280999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 282000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 281999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 283000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 282999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 284000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 283999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 285000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 284999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 286000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 285999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 287000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 286999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 288000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 287999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 289000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 288999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 290000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 289999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 291000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 290999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 292000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 291999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 293000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 292999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 294000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 293999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 295000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 294999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 296000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 295999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 297000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 296999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 298000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 297999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 299000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 298999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 300000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 299999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 301000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 300999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 302000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 301999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 303000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 302999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 304000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 303999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 305000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 304999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 306000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 305999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 307000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 306999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 308000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 307999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 309000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 308999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 310000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 309999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 311000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 310999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 312000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 311999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 313000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 312999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 314000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 313999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 315000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 314999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 316000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 315999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 317000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 316999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 318000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 317999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 319000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 318999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 320000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 319999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 321000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 320999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 322000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 321999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 323000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 322999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 324000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 323999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 325000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 324999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 326000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 325999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 327000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 326999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 328000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 327999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 329000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 328999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 330000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 329999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 331000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 330999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 332000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 331999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 333000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 332999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 334000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 333999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 335000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 334999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 336000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 335999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 337000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 336999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 338000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 337999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 339000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 338999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 340000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 339999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 341000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 340999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 342000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 341999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 343000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 342999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 344000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 343999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 345000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 344999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 346000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 345999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 347000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 346999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 348000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 347999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 349000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 348999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 350000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 349999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 351000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 350999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 352000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 351999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 353000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 352999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 354000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 353999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 355000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 354999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 356000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 355999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 357000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 356999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 358000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 357999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 359000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 358999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 360000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 359999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 361000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 360999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 362000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 361999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 363000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 362999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 364000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 363999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 365000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 364999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 366000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 365999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 367000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 366999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 368000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 367999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 369000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 368999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 370000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 369999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 371000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 370999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 372000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 371999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 373000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 372999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 374000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 373999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 375000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 374999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 376000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 375999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 377000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 376999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 378000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 377999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 379000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 378999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 380000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 379999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 381000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 380999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 382000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 381999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 383000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 382999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 384000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 383999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 385000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 384999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 386000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 385999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 387000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 386999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 388000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 387999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 389000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 388999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 390000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 389999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 391000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 390999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 392000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 391999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 393000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 392999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 394000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 393999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 395000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 394999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 396000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 395999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 397000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 396999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 398000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 397999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 399000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 398999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 400000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 399999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 401000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 400999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 402000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 401999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 403000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 402999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 404000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 403999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 405000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 404999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 406000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 405999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 407000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 406999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 408000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 407999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 409000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 408999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 410000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 409999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 411000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 410999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 412000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 411999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 413000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 412999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 414000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 413999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 415000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 414999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 416000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 415999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 417000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 416999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 418000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 417999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 419000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 418999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 420000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 419999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 421000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 420999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 422000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 421999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 423000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 422999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 424000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 423999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 425000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 424999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 426000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 425999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 427000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 426999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 428000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 427999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 429000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 428999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 430000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 429999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 431000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 430999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 432000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 431999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 433000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 432999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 434000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 433999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 435000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 434999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 436000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 435999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 437000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 436999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 438000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 437999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 439000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 438999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 440000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 439999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 441000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 440999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 442000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 441999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 443000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 442999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 444000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 443999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 445000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 444999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 446000   |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 445999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 447000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 446999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 448000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 447999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 449000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 448999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 450000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 449999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 451000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 450999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 452000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 451999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 453000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 452999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 454000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 453999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 455000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 454999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 456000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 455999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 457000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 456999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 458000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 457999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 459000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 458999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 460000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 459999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 461000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 460999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 462000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 461999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 463000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 462999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 464000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 463999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 465000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 464999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 466000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 465999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 467000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 466999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 468000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 467999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 469000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 468999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 470000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 469999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 471000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 470999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 472000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 471999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 473000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 472999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 474000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 473999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 475000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 474999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 476000   |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 475999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 477000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 476999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 478000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 477999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 479000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 478999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 480000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 479999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 481000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 480999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 482000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 481999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 483000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 482999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 484000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 483999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 485000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 484999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 486000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 485999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 487000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 486999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 488000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 487999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 489000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 488999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 490000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 489999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 491000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 490999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 492000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 491999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 493000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 492999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 494000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 493999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 495000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 494999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 496000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 495999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 497000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 496999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 498000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 497999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 499000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 498999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 500000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 499999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 501000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 500999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 502000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 501999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 503000   |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 502999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 504000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 503999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 505000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 504999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 506000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 505999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 507000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 506999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 508000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 507999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 509000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 508999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 510000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 509999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 511000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 510999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 512000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 511999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 513000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 512999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 514000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 513999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 515000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 514999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 516000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 515999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 517000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 516999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 518000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 517999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 519000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 518999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 520000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 519999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 521000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 520999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 522000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 521999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 523000   |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 522999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 524000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 523999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 525000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 524999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 526000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 525999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 527000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 526999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 528000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 527999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 529000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 528999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 530000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 529999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 531000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 530999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 532000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 531999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 533000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 532999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 534000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 533999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 535000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 534999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 536000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 535999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 537000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 536999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 538000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 537999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 539000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 538999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 540000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 539999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 541000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 540999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 542000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 541999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 543000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 542999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 544000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 543999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 545000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 544999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 546000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 545999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 547000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 546999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 548000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 547999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 549000   |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 548999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 550000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 549999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 551000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 550999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 552000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 551999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 553000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 552999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 554000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 553999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 555000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 554999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 556000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 555999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 557000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 556999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 558000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 557999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 559000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 558999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 560000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 559999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 561000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 560999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 562000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 561999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 563000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 562999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 564000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 563999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 565000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 564999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 566000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 565999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 567000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 566999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 568000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 567999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 569000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 568999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 570000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 569999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 571000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 570999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 572000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 571999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 573000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 572999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 574000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 573999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 575000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 574999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 576000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 575999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 577000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 576999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 578000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 577999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 579000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 578999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 580000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 579999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 581000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 580999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 582000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 581999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 583000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 582999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 584000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 583999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 585000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 584999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 586000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 585999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 587000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 586999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 588000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 587999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 589000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 588999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 590000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 589999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 591000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 590999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 592000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 591999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 593000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 592999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 594000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 593999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 595000   |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 594999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 596000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 595999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 597000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 596999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 598000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 597999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 599000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 598999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 600000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 599999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 601000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 600999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 602000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 601999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 603000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 602999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 604000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 603999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 605000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 604999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 606000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 605999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 607000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 606999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 608000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 607999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 609000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 608999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 610000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 609999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 611000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 610999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 612000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 611999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 613000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 612999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 614000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 613999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 615000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 614999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 616000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 615999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 617000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 616999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 618000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 617999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 619000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 618999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 620000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 619999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 621000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 620999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 622000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 621999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 623000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 622999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 624000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 623999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 625000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 624999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 626000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 625999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 627000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 626999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 628000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 627999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 629000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 628999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 630000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 629999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 631000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 630999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 632000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 631999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 633000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 632999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 634000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 633999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 635000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 634999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 636000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 635999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 637000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 636999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 638000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 637999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 639000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 638999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 640000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 639999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 641000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 640999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 642000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 641999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 643000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 642999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 644000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 643999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 645000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 644999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 646000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 645999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 647000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 646999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 648000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 647999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 649000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 648999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 650000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 649999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 651000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 650999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 652000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 651999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 653000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 652999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 654000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 653999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 655000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 654999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 656000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 655999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 657000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 656999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 658000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 657999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 659000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 658999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 660000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 659999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 661000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 660999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 662000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 661999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 663000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 662999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 664000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 663999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 665000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 664999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 666000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 665999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 667000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 666999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 668000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 667999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 669000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 668999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 670000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 669999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 671000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 670999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 672000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 671999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 673000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 672999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 674000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 673999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 675000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 674999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 676000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 675999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 677000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 676999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 678000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 677999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 679000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 678999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 680000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 679999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 681000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 680999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 682000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 681999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 683000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 682999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 684000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 683999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 685000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 684999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 686000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 685999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 687000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 686999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 688000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 687999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 689000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 688999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 690000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 689999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 691000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 690999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 692000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 691999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 693000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 692999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 694000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 693999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 695000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 694999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 696000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 695999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 697000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 696999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 698000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 697999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 699000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 698999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 700000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 699999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 701000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 700999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 702000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 701999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 703000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 702999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 704000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 703999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 705000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 704999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 706000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 705999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 707000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 706999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 708000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 707999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 709000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 708999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 710000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 709999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 711000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 710999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 712000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 711999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 713000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 712999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 714000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 713999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 715000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 714999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 716000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 715999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 717000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 716999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 718000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 717999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 719000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 718999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 720000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 719999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 721000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 720999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 722000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 721999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 723000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 722999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 724000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 723999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 725000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 724999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 726000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 725999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 727000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 726999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 728000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 727999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 729000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 728999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 730000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 729999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 731000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 730999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 732000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 731999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 733000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 732999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 734000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 733999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 735000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 734999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 736000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 735999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 737000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 736999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 738000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 737999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 739000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 738999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 740000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 739999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 741000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 740999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 742000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 741999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 743000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 742999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 744000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 743999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 745000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 744999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 746000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 745999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 747000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 746999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 748000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 747999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 749000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 748999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 750000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 749999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 751000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 750999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 752000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 751999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 753000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 752999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 754000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 753999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 755000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 754999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 756000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 755999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 757000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 756999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 758000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 757999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 759000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 758999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 760000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 759999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 761000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 760999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 762000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 761999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 763000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 762999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 764000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 763999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 765000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 764999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 766000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 765999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 767000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 766999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 768000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 767999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 769000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 768999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 770000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 769999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 771000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 770999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 772000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 771999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 773000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 772999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 774000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 773999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 775000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 774999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 776000   |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 775999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 777000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 776999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 778000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 777999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 779000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 778999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 780000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 779999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 781000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 780999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 782000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 781999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 783000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 782999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 784000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 783999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 785000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 784999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 786000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 785999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 787000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 786999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 788000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 787999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 789000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 788999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 790000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 789999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 791000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 790999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 792000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 791999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 793000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 792999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 794000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 793999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 795000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 794999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 796000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 795999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 797000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 796999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 798000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 797999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 799000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 798999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 800000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 799999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 801000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 800999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 802000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 801999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 803000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 802999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 804000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 803999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 805000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 804999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 806000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 805999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 807000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 806999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 808000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 807999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 809000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 808999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 810000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 809999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 811000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 810999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 812000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 811999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 813000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 812999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 814000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 813999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 815000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 814999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 816000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 815999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 817000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 816999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 818000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 817999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 819000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 818999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 820000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 819999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 821000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 820999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 822000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 821999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 823000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 822999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 824000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 823999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 825000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 824999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 826000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 825999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 827000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 826999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 828000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 827999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 829000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 828999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 830000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 829999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 831000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 830999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 832000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 831999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 833000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 832999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 834000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 833999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 835000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 834999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 836000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 835999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 837000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 836999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 838000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 837999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 839000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 838999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 840000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 839999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 841000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 840999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 842000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 841999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 843000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 842999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 844000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 843999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 845000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 844999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 846000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 845999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 847000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 846999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 848000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 847999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 849000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 848999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 850000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 849999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 851000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 850999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 852000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 851999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 853000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 852999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 854000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 853999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 855000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 854999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 856000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 855999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 857000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 856999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 858000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 857999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 859000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 858999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 860000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 859999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 861000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 860999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 862000   |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 861999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 863000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 862999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 864000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 863999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 865000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 864999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 866000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 865999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 867000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 866999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 868000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 867999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 869000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 868999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 870000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 869999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 871000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 870999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 872000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 871999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 873000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 872999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 874000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 873999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 875000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 874999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 876000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 875999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 877000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 876999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 878000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 877999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 879000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 878999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 880000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 879999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 881000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 880999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 882000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 881999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 883000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 882999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 884000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 883999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 885000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 884999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 886000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 885999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 887000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 886999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 888000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 887999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 889000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 888999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 890000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 889999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 891000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 890999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 892000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 891999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 893000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 892999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 894000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 893999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 895000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 894999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 896000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 895999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 897000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 896999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 898000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 897999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 899000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 898999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 900000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 899999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 901000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 900999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 902000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 901999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 903000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 902999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 904000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 903999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 905000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 904999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 906000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 905999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 907000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 906999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 908000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 907999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 909000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 908999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 910000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 909999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 911000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 910999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 912000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 911999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 913000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 912999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 914000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 913999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 915000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 914999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 916000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 915999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 917000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 916999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 918000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 917999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 919000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 918999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 920000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 919999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 921000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 920999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 922000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 921999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 923000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 922999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 924000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 923999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 925000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 924999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 926000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 925999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 927000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 926999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 928000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 927999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 929000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 928999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 930000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 929999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 931000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 930999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 932000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 931999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 933000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 932999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 934000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 933999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 935000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 934999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 936000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 935999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 937000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 936999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 938000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 937999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 939000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 938999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 940000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 939999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 941000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 940999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 942000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 941999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 943000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 942999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 944000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 943999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 945000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 944999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 946000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 945999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 947000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 946999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 948000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 947999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 949000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 948999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 950000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 949999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 951000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 950999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 952000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 951999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 953000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 952999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 954000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 953999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 955000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 954999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 956000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 955999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 957000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 956999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 958000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 957999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 959000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 958999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 960000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 959999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 961000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 960999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 962000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 961999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 963000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 962999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 964000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 963999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 965000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 964999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 966000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 965999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 967000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 966999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 968000   |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 967999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 969000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 968999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 970000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 969999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 971000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 970999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 972000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 971999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 973000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 972999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 974000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 973999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 975000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 974999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 976000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 975999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 977000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 976999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 978000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 977999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 979000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 978999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 980000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 979999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 981000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 980999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 982000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 981999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 983000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 982999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 984000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 983999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 985000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 984999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 986000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 985999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 987000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 986999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 988000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 987999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 989000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 988999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 990000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 989999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 991000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 990999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 992000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 991999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 993000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 992999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 994000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 993999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 995000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 994999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 996000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 995999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 997000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 996999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 998000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 997999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 999000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 998999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 1000000  |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999999   |\n",
      "--------------------------------------\n",
      "Vanilla DQN Training Time: 4554.85537314415\n"
     ]
    }
   ],
   "source": [
    "def ids_ddqn():\n",
    "    env = IdsEnv(images_per_episode=1)\n",
    "    env = bench.Monitor(env, logger.get_dir())\n",
    "\n",
    "    model = deepq.DQN(\n",
    "        MlpPolicy, \n",
    "        env, \n",
    "        policy_kwargs=dict(dueling=False),\n",
    "        double_q=False,\n",
    "        verbose=1, \n",
    "        learning_rate=5.5e-05,\n",
    "        buffer_size=10000,\n",
    "        exploration_fraction=0.1,\n",
    "        exploration_final_eps=0.0325,\n",
    "        train_freq=4,\n",
    "        learning_starts=10000,\n",
    "        target_network_update_freq=1000,\n",
    "        gamma=0.99,\n",
    "        prioritized_replay=False,\n",
    "        prioritized_replay_alpha=0.6,\n",
    "        batch_size=32,\n",
    "#         tensorboard_log=logdir,\n",
    "#         full_tensorboard_log=False,\n",
    "    )\n",
    "    model.learn(\n",
    "        total_timesteps=int(1.0e6),\n",
    "        log_interval=1000,\n",
    "        \n",
    "    )\n",
    "\n",
    "    model.save('vanilla_dqn_cicddos2019_allfeat.pkl')\n",
    "    env.close()\n",
    "    \n",
    "    return model\n",
    "\n",
    "start_time = time.time()\n",
    "ddqn_model = ids_ddqn()\n",
    "print(\"Vanilla DQN Training Time:\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation done...\n",
      "Accuracy: 58.06225953130465%\n",
      "Precision: 24.481231056190254%\n",
      "Recall/TPR/Sensitivity: 74.57386363636364%\n",
      "FPR: 45.180638861765935%\n",
      "F1 score: 0.3686150605581885\n"
     ]
    }
   ],
   "source": [
    "# 0 is benign (positive), 1 is malicious (negative) \n",
    "def ids_eval(model):\n",
    "    TP, FP, TN, FN = 0,0,0,0\n",
    "    env = IdsEnv(images_per_episode=4096, dataset=(x_test, y_test), random=False)\n",
    "    obs, done = env.reset(), False\n",
    "    try:\n",
    "        while True:\n",
    "            obs, done = env.reset(), False\n",
    "            while not done:\n",
    "                obs, rew, done, info = env.step(model.predict(obs)[0])\n",
    "                label = info['label']\n",
    "                if label == 0 and rew > 0:\n",
    "                    TP += 1\n",
    "                if label == 0 and rew == 0:\n",
    "                    FP += 1\n",
    "                if label == 1 and rew > 0:\n",
    "                    TN += 1\n",
    "                if label == 1 and rew == 0:\n",
    "                    FN += 1\n",
    "\n",
    "    except StopIteration:\n",
    "        accuracy = (float(TP + TN) / (TP + FP + FN + TN)) \n",
    "        precision = (float(TP) / (TP + FP))\n",
    "        recall = (float(TP) / (TP + FN)) # = TPR = Sensitivity\n",
    "        FPR = (float(FP) / (TN + FP)) # 1 - specificity\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        print()\n",
    "        print('validation done...')\n",
    "        print('Accuracy: {0}%'.format(accuracy * 100))\n",
    "        print('Precision: {0}%'.format(precision * 100))\n",
    "        print('Recall/TPR/Sensitivity: {0}%'.format(recall * 100))\n",
    "        print('FPR: {0}%'.format(FPR * 100))\n",
    "        print('F1 score: {0}'.format(f1_score))\n",
    "\n",
    "ids_eval(ddqn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
