{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt install python-opengl\n",
    "    !apt install ffmpeg\n",
    "    !apt install xvfb\n",
    "    !pip install PyVirtualDisplay==3.0\n",
    "    !pip install gym==0.21.0\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    # Start virtual display\n",
    "    dis = Display(visible=0, size=(400, 400))\n",
    "    dis.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. DQN\n",
    "\n",
    "[V. Mnih et al., \"Human-level control through deep reinforcement learning.\" Nature, 518\n",
    "(7540):529–533, 2015.](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf)\n",
    "\n",
    "Reinforcement learning is known to be unstable or even to diverge when a nonlinear function approximator such as a neural network is used to represent the action-value (also known as $Q$) function. This instability has several causes: the correlations present in the sequence of observations, the fact that small updates to $Q$ may significantly change the policy and therefore change the data distribution, and the correlations between the action-values ($Q$) and the target values $r + \\gamma \\max_{a'} Q(s', a')$.\n",
    "\n",
    "The authors suggest two key ideas to address these instabilities with a novel variant of Q-learning: Replay buffer and Fixed Q-target.\n",
    "\n",
    "#### Uniformly random sampling from Experience Replay Memory\n",
    "\n",
    "Reinforcement learning agent stores the experiences consecutively in the buffer, so adjacent ($s, a, r, s'$) transitions stored are highly likely to have correlation. To remove this, the agent samples experiences uniformly at random from the pool of stored samples $\\big( (s, a, r, s') \\sim U(D) \\big)$. See sample_batch method of ReplayBuffer class for more details.\n",
    "\n",
    "#### Fixed Q-target\n",
    "\n",
    "DQN uses an iterative update that adjusts the action-values ($Q$) towards target values that are only periodically updated, thereby reducing correlations with the target; if not, it is easily divergy because the target continuously moves. The Q-learning update at iteration $i$ uses the following loss function:\n",
    "\n",
    "$$\n",
    "L_i(\\theta_i) = \\mathbb{E}_{(s,a,r,s') \\sim U(D)} \\big[ \\big( r + \\gamma \\max_{a'} Q(s',a';\\theta_i^-) - Q(s, a; \\theta_i) \\big)^2 \\big]\n",
    "$$\n",
    "\n",
    "in which $\\gamma$ is the discount factor determining the agent’s horizon, $\\theta_i$ are the parameters of the Q-network at iteration $i$ and $\\theta_i^-$ are the network parameters used to compute the target at iteration $i$. The target network parameters $\\theta_i^-$ are only updated with the Q-network parameters ($\\theta_i$) every C steps and are held fixed between individual updates. ($C = 200$ in CartPole-v0)\n",
    "\n",
    "#### For more stability: Gradient clipping\n",
    "\n",
    "The authors also found it helpful to clip the error term from the update $r + \\gamma \\max_{a'} Q(s', a'; \\theta_i^-) - Q(s,a,;\\theta_i)$ to be between -1 and 1. Because the absolute value loss function $|x|$ has a derivative of -1 for all negative values of x and a derivative of 1 for all positive values of x, clipping the squared error to be between -1 and 1 corresponds to using an absolute value loss function for errors outside of the (-1,1) interval. This form of error clipping further improved the stability of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import gym\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Typically, people implement replay buffers with one of the following three data structures:\n",
    "\n",
    "  - collections.deque\n",
    "  - list\n",
    "  - numpy.ndarray\n",
    "  \n",
    "**deque** is very easy to handle once you initialize its maximum length (e.g. deque(maxlen=buffer_size)). However, the indexing operation of deque gets terribly slow as it grows up because it is [internally doubly linked list](https://wiki.python.org/moin/TimeComplexity#collections.deque). On the other hands, **list** is an array, so it is relatively faster than deque when you sample batches at every step. Its amortized cost of  *Get item* is [O(1)](https://wiki.python.org/moin/TimeComplexity#list).\n",
    "\n",
    "Last but not least, let's see **numpy.ndarray**. numpy.ndarray is even faster than list due to the fact that it is [a homogeneous array of fixed-size items](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray), so you can get the benefits of [locality of reference](https://en.wikipedia.org/wiki/Locality_of_reference). Whereas list is an array of pointers to objects, even when all of them are of the same type.\n",
    "\n",
    "Here, we are going to implement a replay buffer using numpy.ndarray.\n",
    "\n",
    "\n",
    "Reference: [OpenAI spinning-up](https://github.com/openai/spinningup/blob/master/spinup/algos/sac/sac.py#L10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "\n",
    "    def store(\n",
    "        self,\n",
    "        obs: np.ndarray,\n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ):\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "        return dict(obs=self.obs_buf[idxs],\n",
    "                    next_obs=self.next_obs_buf[idxs],\n",
    "                    acts=self.acts_buf[idxs],\n",
    "                    rews=self.rews_buf[idxs],\n",
    "                    done=self.done_buf[idxs])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network\n",
    "\n",
    "We are going to use a simple network architecture with three fully connected layers and two non-linearity functions (ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Using the preprocessed datasets by Laurens D'Hooge (https://gitlab.ilabt.imec.be/lpdhooge/clean-ids-collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0         0        491          0     0               0       0    0   \n",
       "1         0        146          0     0               0       0    0   \n",
       "2         0          0          0     0               0       0    0   \n",
       "3         0        232       8153     0               0       0    0   \n",
       "4         0        199        420     0               0       0    0   \n",
       "\n",
       "   num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_RSTO  \\\n",
       "0                  0          0                0  ...         0          0   \n",
       "1                  0          0                0  ...         0          0   \n",
       "2                  0          0                0  ...         0          0   \n",
       "3                  0          1                0  ...         0          0   \n",
       "4                  0          1                0  ...         0          0   \n",
       "\n",
       "   flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
       "0            0          0        0        0        0        0        1   \n",
       "1            0          0        0        0        0        0        1   \n",
       "2            0          0        1        0        0        0        0   \n",
       "3            0          0        0        0        0        0        1   \n",
       "4            0          0        0        0        0        0        1   \n",
       "\n",
       "   flag_SH  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train = pd.read_feather(\"./datasets/nsl-kdd/KDDTrain.feather\")\n",
    "nslkdd_test = pd.read_feather(\"./datasets/nsl-kdd/KDDTest.feather\")\n",
    "# data = pd.concat([nslkdd_test], ignore_index=True)\n",
    "# print(len(data.columns))\n",
    "\n",
    "# nslkdd_train.protocol_type = pd.Categorical(nslkdd_train.protocol_type).codes\n",
    "# nslkdd_train.service = pd.Categorical(nslkdd_train.service).codes\n",
    "# nslkdd_train.flag = pd.Categorical(nslkdd_train.flag).codes\n",
    "\n",
    "\n",
    "# nslkdd_test.protocol_type = pd.Categorical(nslkdd_test.protocol_type).codes\n",
    "# nslkdd_test.service = pd.Categorical(nslkdd_test.service).codes\n",
    "# nslkdd_test.flag = pd.Categorical(nslkdd_test.flag).codes\n",
    "\n",
    "\n",
    "nslkdd_train = pd.get_dummies(nslkdd_train,columns=['protocol_type' ,'service', 'flag'])\n",
    "nslkdd_test = pd.get_dummies(nslkdd_test, columns=['protocol_type' ,'service', 'flag'])\n",
    "nslkdd_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Columns: 123 entries, duration to flag_SH\n",
      "dtypes: float64(15), int64(23), object(1), uint8(84)\n",
      "memory usage: 47.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125973.00000</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>125973.00000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>287.14465</td>\n",
       "      <td>4.556674e+04</td>\n",
       "      <td>1.977911e+04</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.204409</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.395736</td>\n",
       "      <td>0.279250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08917</td>\n",
       "      <td>0.012399</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.019218</td>\n",
       "      <td>0.276655</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.594929</td>\n",
       "      <td>0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2604.51531</td>\n",
       "      <td>5.870331e+06</td>\n",
       "      <td>4.021269e+06</td>\n",
       "      <td>0.014086</td>\n",
       "      <td>0.253530</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>2.149968</td>\n",
       "      <td>0.045239</td>\n",
       "      <td>0.489010</td>\n",
       "      <td>23.942042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28499</td>\n",
       "      <td>0.110661</td>\n",
       "      <td>0.028583</td>\n",
       "      <td>0.137292</td>\n",
       "      <td>0.447346</td>\n",
       "      <td>0.053750</td>\n",
       "      <td>0.031736</td>\n",
       "      <td>0.019719</td>\n",
       "      <td>0.490908</td>\n",
       "      <td>0.046332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.760000e+02</td>\n",
       "      <td>5.160000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42908.00000</td>\n",
       "      <td>1.379964e+09</td>\n",
       "      <td>1.309937e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes           land  \\\n",
       "count  125973.00000  1.259730e+05  1.259730e+05  125973.000000   \n",
       "mean      287.14465  4.556674e+04  1.977911e+04       0.000198   \n",
       "std      2604.51531  5.870331e+06  4.021269e+06       0.014086   \n",
       "min         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "25%         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "50%         0.00000  4.400000e+01  0.000000e+00       0.000000   \n",
       "75%         0.00000  2.760000e+02  5.160000e+02       0.000000   \n",
       "max     42908.00000  1.379964e+09  1.309937e+09       1.000000   \n",
       "\n",
       "       wrong_fragment         urgent            hot  num_failed_logins  \\\n",
       "count   125973.000000  125973.000000  125973.000000      125973.000000   \n",
       "mean         0.022687       0.000111       0.204409           0.001222   \n",
       "std          0.253530       0.014366       2.149968           0.045239   \n",
       "min          0.000000       0.000000       0.000000           0.000000   \n",
       "25%          0.000000       0.000000       0.000000           0.000000   \n",
       "50%          0.000000       0.000000       0.000000           0.000000   \n",
       "75%          0.000000       0.000000       0.000000           0.000000   \n",
       "max          3.000000       3.000000      77.000000           5.000000   \n",
       "\n",
       "           logged_in  num_compromised  ...      flag_REJ      flag_RSTO  \\\n",
       "count  125973.000000    125973.000000  ...  125973.00000  125973.000000   \n",
       "mean        0.395736         0.279250  ...       0.08917       0.012399   \n",
       "std         0.489010        23.942042  ...       0.28499       0.110661   \n",
       "min         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "25%         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "50%         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "75%         1.000000         0.000000  ...       0.00000       0.000000   \n",
       "max         1.000000      7479.000000  ...       1.00000       1.000000   \n",
       "\n",
       "         flag_RSTOS0      flag_RSTR        flag_S0        flag_S1  \\\n",
       "count  125973.000000  125973.000000  125973.000000  125973.000000   \n",
       "mean        0.000818       0.019218       0.276655       0.002897   \n",
       "std         0.028583       0.137292       0.447346       0.053750   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       1.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             flag_S2        flag_S3        flag_SF        flag_SH  \n",
       "count  125973.000000  125973.000000  125973.000000  125973.000000  \n",
       "mean        0.001008       0.000389       0.594929       0.002151  \n",
       "std         0.031736       0.019719       0.490908       0.046332  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       1.000000       0.000000  \n",
       "75%         0.000000       0.000000       1.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 122 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train.info()\n",
    "nslkdd_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_dataset_sampler_df(df, train_frac=0.2, val_frac=0.1, test_frac=0.7):\n",
    "    col = df.columns[-1]\n",
    "    print(col)\n",
    "    cols = df.columns[:-1]\n",
    "    print(cols)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    n = vc.iloc[-1]\n",
    "    print(n)\n",
    "    m = vc.iloc[0]\n",
    "    print(m)\n",
    "    print(int(m-n))\n",
    "    initial_cut = df.loc[df[col] == vc.index[0]].sample(n=int(m-n), replace=False)\n",
    "    print(initial_cut.index)\n",
    "    df = df.drop(index=initial_cut.index)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    print(int(n*train_frac))\n",
    "    train_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*train_frac), replace=False))\n",
    "    train_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=train_df.index)\n",
    "\n",
    "    validation_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*val_frac), replace=False))\n",
    "    validation_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=validation_df.index)\n",
    "\n",
    "    test_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*test_frac), replace=False))\n",
    "    test_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=test_df.index)\n",
    "\n",
    "    return train_df[cols], train_df[col], validation_df[cols], validation_df[col], test_df[cols], test_df[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nslkdd_split_df(train_df, test_df):\n",
    "    train_col = train_df.columns[-1]\n",
    "    print(train_col)\n",
    "    train_cols = train_df.columns[:-1]\n",
    "    print(train_cols)\n",
    "    test_col = test_df.columns[-1]\n",
    "    print(test_col)\n",
    "    test_cols = test_df.columns[:-1]\n",
    "    print(test_cols)\n",
    "\n",
    "    return train_df[train_cols], train_df[train_col], test_df[test_cols], test_df[test_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def malicious_benign(df):\n",
    "    print(df['class'].value_counts())\n",
    "    df['class'] = df['class'].astype('object')\n",
    "    atk_idx = df.loc[df['class'] != \"normal\"].index\n",
    "    df.loc[atk_idx, 'class'] = 1.0\n",
    "    df.loc[df.index.difference(atk_idx), 'class'] = 0.0\n",
    "    df['class'] = df['class'].astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: class, dtype: int64\n",
      "\n",
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "rootkit              13\n",
      "xterm                13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "worm                  2\n",
      "loadmodule            2\n",
      "perl                  2\n",
      "sqlattack             2\n",
      "udpstorm              2\n",
      "phf                   2\n",
      "imap                  1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "malicious_benign(nslkdd_train)\n",
    "print()\n",
    "malicious_benign(nslkdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['service_aol', 'service_harvest', 'service_http_2784',\n",
      "       'service_http_8001', 'service_red_i', 'service_urh_i'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Columns: 117 entries, duration to flag_SH\n",
      "dtypes: float32(1), float64(15), int64(23), uint8(78)\n",
      "memory usage: 46.4 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\AppData\\Local\\Temp\\ipykernel_17864\\366472954.py:1: FutureWarning: Index.__xor__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__xor__.  Use index.symmetric_difference(other) instead.\n",
      "  extra_removables = nslkdd_test.columns ^ nslkdd_train.columns\n"
     ]
    }
   ],
   "source": [
    "extra_removables = nslkdd_test.columns ^ nslkdd_train.columns\n",
    "print(extra_removables)\n",
    "try:\n",
    "    nslkdd_train = nslkdd_train.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    nslkdd_test.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "nslkdd_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag_SH\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR',\n",
      "       'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF'],\n",
      "      dtype='object', length=116)\n",
      "flag_SH\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR',\n",
      "       'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF'],\n",
      "      dtype='object', length=116)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test  = nslkdd_split_df(nslkdd_train, nslkdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()\n",
    "\n",
    "# custom keys -> replace by index\n",
    "\n",
    "x_train = x_train.set_index([pd.Index(range (0, len(x_train)))])\n",
    "y_train = y_train.set_index([pd.Index(range (0, len(y_train)))])\n",
    "x_test = x_test.set_index([pd.Index(range (0, len(x_test)))])\n",
    "y_test = y_test.set_index([pd.Index(range (0, len(y_test)))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Agent\n",
    "\n",
    "Here is a summary of DQNAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "| ---              | ---                                                  |\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|compute_dqn_loss  | return dqn loss.                                     |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|target_hard_update| hard update from the local model to the target model.|\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|plot              | plot the training progresses.                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (ReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        epsilon (float): parameter for epsilon greedy policy\n",
    "        epsilon_decay (float): step size to decrease epsilon\n",
    "        max_epsilon (float): max value of epsilon\n",
    "        min_epsilon (float): min value of epsilon\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including \n",
    "                           state, action, reward, next_state, done\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        epsilon_decay: float,\n",
    "        max_epsilon: float = 1.0,\n",
    "        min_epsilon: float = 0.1,\n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            epsilon_decay (float): step size to decrease epsilon\n",
    "            lr (float): learning rate\n",
    "            max_epsilon (float): max value of epsilon\n",
    "            min_epsilon (float): min value of epsilon\n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.n\n",
    "        \n",
    "        self.env = env\n",
    "        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon = max_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.max_epsilon = max_epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.target_update = target_update\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # epsilon greedy policy\n",
    "        if self.epsilon > np.random.random():\n",
    "            selected_action = self.env.action_space.sample()\n",
    "        else:\n",
    "            selected_action = self.dqn(\n",
    "                torch.FloatTensor(state).to(self.device)\n",
    "            ).argmax()\n",
    "            selected_action = selected_action.detach().cpu().numpy()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        \n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, done, _ = self.env.step(action)\n",
    "\n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            self.memory.store(*self.transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        samples = self.memory.sample_batch()\n",
    "\n",
    "        loss = self._compute_dqn_loss(samples)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        update_cnt = 0\n",
    "        epsilons = []\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state = self.env.reset()\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # linearly decrease epsilon\n",
    "                self.epsilon = max(\n",
    "                    self.min_epsilon, self.epsilon - (\n",
    "                        self.max_epsilon - self.min_epsilon\n",
    "                    ) * self.epsilon_decay\n",
    "                )\n",
    "                epsilons.append(self.epsilon)\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses, epsilons)\n",
    "                \n",
    "        self.env.close()\n",
    "                \n",
    "    def test(self) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        TP, FP, TN, FN = 0,0,0,0\n",
    "        # for recording a video\n",
    "        naive_env = self.env\n",
    "        self.env = IdsEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)\n",
    "\n",
    "        action = self.env.reset()\n",
    "        done = False\n",
    "        count = 0\n",
    "        try:\n",
    "            while True:\n",
    "\n",
    "                done = False\n",
    "                while not done:\n",
    "                    count += 1\n",
    "                    action = self.select_action(action)\n",
    "                    next_action, rew, done, info = self.env.step(action)\n",
    "                    action = next_action\n",
    "                    label = info['label']\n",
    "                    if label == 0 and rew > 0:\n",
    "                        TP += 1\n",
    "                    if label == 0 and rew == 0:\n",
    "                        FP += 1\n",
    "                    if label == 1 and rew > 0:\n",
    "                        TN += 1\n",
    "                    if label == 1 and rew == 0:\n",
    "                        FN += 1\n",
    "        except StopIteration:\n",
    "            accuracy = (float(TP + TN) / (TP + FP + FN + TN)) \n",
    "            precision = (float(TP) / (TP + FP))\n",
    "            try:\n",
    "                recall = (float(TP) / (TP + FN)) # = TPR = Sensitivity\n",
    "            except:\n",
    "                recall = 0\n",
    "            try:\n",
    "                FPR = (float(FP) / (TN + FP)) # 1 - specificity\n",
    "            except:\n",
    "                FPR = 0\n",
    "            try:\n",
    "                f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "            except:\n",
    "                f1_score = 0\n",
    "            print()\n",
    "            print('validation done...')\n",
    "            print('Accuracy: {0}%'.format(accuracy * 100))\n",
    "            print('Precision: {0}%'.format(precision * 100))\n",
    "            print('Recall/TPR/Sensitivity: {0}%'.format(recall * 100))\n",
    "            print('FPR: {0}%'.format(FPR * 100))\n",
    "            print('F1 score: {0}'.format(f1_score))\n",
    "            print('count: {0}'.format(count))\n",
    "        self.env.close()\n",
    "\n",
    "        # reset\n",
    "        self.env = naive_env\n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:\n",
    "        \"\"\"Return dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"].reshape(-1, 1)).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "\n",
    "        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal\n",
    "        #       = r                       otherwise\n",
    "        curr_q_value = self.dqn(state).gather(1, action)\n",
    "        next_q_value = self.dqn_target(\n",
    "            next_state\n",
    "        ).max(dim=1, keepdim=True)[0].detach()\n",
    "        mask = 1 - done\n",
    "        target = (reward + self.gamma * next_q_value * mask).to(self.device)\n",
    "\n",
    "        # calculate dqn loss\n",
    "        loss = F.smooth_l1_loss(curr_q_value, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores: List[float], \n",
    "        losses: List[float], \n",
    "        epsilons: List[float],\n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
    "        plt.plot(scores)\n",
    "        plt.subplot(132)\n",
    "        plt.title('loss')\n",
    "        plt.plot(losses)\n",
    "        plt.subplot(133)\n",
    "        plt.title('epsilons')\n",
    "        plt.plot(epsilons)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "You can see the [code](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py) and [configurations](https://github.com/openai/gym/blob/master/gym/envs/__init__.py#L53) of CartPole-v0 from OpenAI's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdsEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "        # Actions we can take, classify as malicious or non-malicious (later also the correct attack)\n",
    "        # change to 19 if detectiong all different attacks\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "         # All the features we have, len(important_features) - 1 features and 1 label. Label should not be included\n",
    "        self.observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(len(nslkdd_train.columns) - 1,))\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "    \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "        current_label = self.expected_action\n",
    "        obs = self._next_obs()\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {'label': current_label}\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y.iloc[next_obs_idx,:])\n",
    "            obs = self.x.iloc[next_obs_idx,:]\n",
    "\n",
    "        else:\n",
    "            obs = self.x.iloc[self.dataset_idx]\n",
    "            self.expected_action = int(self.y.iloc[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "        return obs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "env = IdsEnv(images_per_episode=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\anaconda3\\envs\\MP\\lib\\site-packages\\gym\\core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[777]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 777\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "seed_torch(seed)\n",
    "env.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames = int(1.0e5)\n",
    "memory_size = 100000\n",
    "batch_size = 128\n",
    "target_update = 10000\n",
    "epsilon_decay = 1 / 10000\n",
    "\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update, epsilon_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN Training Time: 410.5013062953949\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "agent.train(num_frames)\n",
    "print(\"DQN Training Time:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation done...\n",
      "Accuracy: 95.2311241238577%\n",
      "Precision: 95.2245315768392%\n",
      "Recall/TPR/Sensitivity: 99.9906533320871%\n",
      "FPR: 93.7937062937063%\n",
      "F1 score: 0.9754941071876353\n",
      "count: 22543\n"
     ]
    }
   ],
   "source": [
    "agent.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
