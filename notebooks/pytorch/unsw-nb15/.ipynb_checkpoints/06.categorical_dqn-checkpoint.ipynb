{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt install python-opengl\n",
    "    !apt install ffmpeg\n",
    "    !apt install xvfb\n",
    "    !pip install PyVirtualDisplay==3.0\n",
    "    !pip install gym==0.21.0\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    # Start virtual display\n",
    "    dis = Display(visible=0, size=(400, 400))\n",
    "    dis.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. Categorical DQN\n",
    "\n",
    "[M. G. Bellemare et al., \"A Distributional Perspective on Reinforcement Learning.\" arXiv preprint arXiv:1707.06887, 2017.](https://arxiv.org/pdf/1707.06887.pdf)\n",
    "\n",
    "The authors argued the importance of learning the distribution of returns instead of the expected return, and they proposed to model such distributions with probability masses placed on a discrete support $z$, where $z$ is a vector with $N_{atoms} \\in \\mathbb{N}^+$ atoms, defined by $z_i = V_{min} + (i-1) \\frac{V_{max} - V_{min}}{N-1}$ for $i \\in \\{1, ..., N_{atoms}\\}$.\n",
    "\n",
    "The key insight is that return distributions satisfy a variant of Bellman’s equation. For a given state $S_t$ and action $A_t$, the distribution of the returns under the optimal policy $\\pi^{*}$ should match a target distribution defined by taking the distribution for the next state $S_{t+1}$ and action $a^{*}_{t+1} = \\pi^{*}(S_{t+1})$, contracting\n",
    "it towards zero according to the discount, and shifting it by the reward (or distribution of rewards, in the stochastic case). A distributional variant of Q-learning is then derived by first constructing a new support for the target distribution, and then minimizing the Kullbeck-Leibler divergence between the distribution $d_t$ and the target distribution\n",
    "\n",
    "$$\n",
    "d_t' = (R_{t+1} + \\gamma_{t+1} z, p_\\hat{{\\theta}} (S_{t+1}, \\hat{a}^{*}_{t+1})),\\\\\n",
    "D_{KL} (\\phi_z d_t' \\| d_t).\n",
    "$$\n",
    "\n",
    "Here $\\phi_z$ is a L2-projection of the target distribution onto the fixed support $z$, and $\\hat{a}^*_{t+1} = \\arg\\max_{a} q_{\\hat{\\theta}} (S_{t+1}, a)$ is the greedy action with respect to the mean action values $q_{\\hat{\\theta}} (S_{t+1}, a) = z^{T}p_{\\theta}(S_{t+1}, a)$ in state $S_{t+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Please see *01.dqn.ipynb* for detailed description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "\n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ):\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "        return dict(obs=self.obs_buf[idxs],\n",
    "                    next_obs=self.next_obs_buf[idxs],\n",
    "                    acts=self.acts_buf[idxs],\n",
    "                    rews=self.rews_buf[idxs],\n",
    "                    done=self.done_buf[idxs])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network\n",
    "\n",
    "The parametrized distribution can be represented by a neural network, as in DQN, but with atom_size x out_dim outputs. A softmax is applied independently for each action dimension of the output to ensure that the distribution for each action is appropriately normalized.\n",
    "\n",
    "To estimate q-values, we use inner product of each action's softmax distribution and support which is the set of atoms $\\{z_i = V_{min} + i\\Delta z: 0 \\le i < N\\}, \\Delta z = \\frac{V_{max} - V_{min}}{N-1}$.\n",
    "\n",
    "$$\n",
    "Q(s_t, a_t) = \\sum_i z_i p_i(s_t, a_t), \\\\\n",
    "\\text{where } p_i \\text{ is the probability of } z_i \\text{ (the output of softmax)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_dim: int, \n",
    "        out_dim: int, \n",
    "        atom_size: int, \n",
    "        support: torch.Tensor\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.support = support\n",
    "        self.out_dim = out_dim\n",
    "        self.atom_size = atom_size\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128, out_dim * atom_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        dist = self.dist(x)\n",
    "        q = torch.sum(dist * self.support, dim=2)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def dist(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Get distribution for atoms.\"\"\"\n",
    "        q_atoms = self.layers(x).view(-1, self.out_dim, self.atom_size)\n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "        dist = dist.clamp(min=1e-3)  # for avoiding nans\n",
    "        \n",
    "        return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0         0        491          0     0               0       0    0   \n",
       "1         0        146          0     0               0       0    0   \n",
       "2         0          0          0     0               0       0    0   \n",
       "3         0        232       8153     0               0       0    0   \n",
       "4         0        199        420     0               0       0    0   \n",
       "\n",
       "   num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_RSTO  \\\n",
       "0                  0          0                0  ...         0          0   \n",
       "1                  0          0                0  ...         0          0   \n",
       "2                  0          0                0  ...         0          0   \n",
       "3                  0          1                0  ...         0          0   \n",
       "4                  0          1                0  ...         0          0   \n",
       "\n",
       "   flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
       "0            0          0        0        0        0        0        1   \n",
       "1            0          0        0        0        0        0        1   \n",
       "2            0          0        1        0        0        0        0   \n",
       "3            0          0        0        0        0        0        1   \n",
       "4            0          0        0        0        0        0        1   \n",
       "\n",
       "   flag_SH  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train = pd.read_feather(\"./datasets/nsl-kdd/KDDTrain.feather\")\n",
    "nslkdd_test = pd.read_feather(\"./datasets/nsl-kdd/KDDTest.feather\")\n",
    "# data = pd.concat([nslkdd_test], ignore_index=True)\n",
    "# print(len(data.columns))\n",
    "\n",
    "# nslkdd_train.protocol_type = pd.Categorical(nslkdd_train.protocol_type).codes\n",
    "# nslkdd_train.service = pd.Categorical(nslkdd_train.service).codes\n",
    "# nslkdd_train.flag = pd.Categorical(nslkdd_train.flag).codes\n",
    "\n",
    "\n",
    "# nslkdd_test.protocol_type = pd.Categorical(nslkdd_test.protocol_type).codes\n",
    "# nslkdd_test.service = pd.Categorical(nslkdd_test.service).codes\n",
    "# nslkdd_test.flag = pd.Categorical(nslkdd_test.flag).codes\n",
    "\n",
    "\n",
    "nslkdd_train = pd.get_dummies(nslkdd_train,columns=['protocol_type' ,'service', 'flag'])\n",
    "nslkdd_test = pd.get_dummies(nslkdd_test, columns=['protocol_type' ,'service', 'flag'])\n",
    "nslkdd_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Columns: 123 entries, duration to flag_SH\n",
      "dtypes: float64(15), int64(23), object(1), uint8(84)\n",
      "memory usage: 47.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125973.00000</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>125973.00000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>287.14465</td>\n",
       "      <td>4.556674e+04</td>\n",
       "      <td>1.977911e+04</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.204409</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.395736</td>\n",
       "      <td>0.279250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08917</td>\n",
       "      <td>0.012399</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.019218</td>\n",
       "      <td>0.276655</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.594929</td>\n",
       "      <td>0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2604.51531</td>\n",
       "      <td>5.870331e+06</td>\n",
       "      <td>4.021269e+06</td>\n",
       "      <td>0.014086</td>\n",
       "      <td>0.253530</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>2.149968</td>\n",
       "      <td>0.045239</td>\n",
       "      <td>0.489010</td>\n",
       "      <td>23.942042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28499</td>\n",
       "      <td>0.110661</td>\n",
       "      <td>0.028583</td>\n",
       "      <td>0.137292</td>\n",
       "      <td>0.447346</td>\n",
       "      <td>0.053750</td>\n",
       "      <td>0.031736</td>\n",
       "      <td>0.019719</td>\n",
       "      <td>0.490908</td>\n",
       "      <td>0.046332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.760000e+02</td>\n",
       "      <td>5.160000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42908.00000</td>\n",
       "      <td>1.379964e+09</td>\n",
       "      <td>1.309937e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes           land  \\\n",
       "count  125973.00000  1.259730e+05  1.259730e+05  125973.000000   \n",
       "mean      287.14465  4.556674e+04  1.977911e+04       0.000198   \n",
       "std      2604.51531  5.870331e+06  4.021269e+06       0.014086   \n",
       "min         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "25%         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "50%         0.00000  4.400000e+01  0.000000e+00       0.000000   \n",
       "75%         0.00000  2.760000e+02  5.160000e+02       0.000000   \n",
       "max     42908.00000  1.379964e+09  1.309937e+09       1.000000   \n",
       "\n",
       "       wrong_fragment         urgent            hot  num_failed_logins  \\\n",
       "count   125973.000000  125973.000000  125973.000000      125973.000000   \n",
       "mean         0.022687       0.000111       0.204409           0.001222   \n",
       "std          0.253530       0.014366       2.149968           0.045239   \n",
       "min          0.000000       0.000000       0.000000           0.000000   \n",
       "25%          0.000000       0.000000       0.000000           0.000000   \n",
       "50%          0.000000       0.000000       0.000000           0.000000   \n",
       "75%          0.000000       0.000000       0.000000           0.000000   \n",
       "max          3.000000       3.000000      77.000000           5.000000   \n",
       "\n",
       "           logged_in  num_compromised  ...      flag_REJ      flag_RSTO  \\\n",
       "count  125973.000000    125973.000000  ...  125973.00000  125973.000000   \n",
       "mean        0.395736         0.279250  ...       0.08917       0.012399   \n",
       "std         0.489010        23.942042  ...       0.28499       0.110661   \n",
       "min         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "25%         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "50%         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "75%         1.000000         0.000000  ...       0.00000       0.000000   \n",
       "max         1.000000      7479.000000  ...       1.00000       1.000000   \n",
       "\n",
       "         flag_RSTOS0      flag_RSTR        flag_S0        flag_S1  \\\n",
       "count  125973.000000  125973.000000  125973.000000  125973.000000   \n",
       "mean        0.000818       0.019218       0.276655       0.002897   \n",
       "std         0.028583       0.137292       0.447346       0.053750   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       1.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             flag_S2        flag_S3        flag_SF        flag_SH  \n",
       "count  125973.000000  125973.000000  125973.000000  125973.000000  \n",
       "mean        0.001008       0.000389       0.594929       0.002151  \n",
       "std         0.031736       0.019719       0.490908       0.046332  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       1.000000       0.000000  \n",
       "75%         0.000000       0.000000       1.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 122 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train.info()\n",
    "nslkdd_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_dataset_sampler_df(df, train_frac=0.2, val_frac=0.1, test_frac=0.7):\n",
    "    col = df.columns[-1]\n",
    "    print(col)\n",
    "    cols = df.columns[:-1]\n",
    "    print(cols)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    n = vc.iloc[-1]\n",
    "    print(n)\n",
    "    m = vc.iloc[0]\n",
    "    print(m)\n",
    "    print(int(m-n))\n",
    "    initial_cut = df.loc[df[col] == vc.index[0]].sample(n=int(m-n), replace=False)\n",
    "    print(initial_cut.index)\n",
    "    df = df.drop(index=initial_cut.index)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    print(int(n*train_frac))\n",
    "    train_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*train_frac), replace=False))\n",
    "    train_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=train_df.index)\n",
    "\n",
    "    validation_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*val_frac), replace=False))\n",
    "    validation_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=validation_df.index)\n",
    "\n",
    "    test_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*test_frac), replace=False))\n",
    "    test_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=test_df.index)\n",
    "\n",
    "    return train_df[cols], train_df[col], validation_df[cols], validation_df[col], test_df[cols], test_df[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nslkdd_split_df(train_df, test_df):\n",
    "    train_col = train_df.columns[-1]\n",
    "    print(train_col)\n",
    "    train_cols = train_df.columns[:-1]\n",
    "    print(train_cols)\n",
    "    test_col = test_df.columns[-1]\n",
    "    print(test_col)\n",
    "    test_cols = test_df.columns[:-1]\n",
    "    print(test_cols)\n",
    "\n",
    "    return train_df[train_cols], train_df[train_col], test_df[test_cols], test_df[test_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def malicious_benign(df):\n",
    "    print(df['class'].value_counts())\n",
    "    df['class'] = df['class'].astype('object')\n",
    "    atk_idx = df.loc[df['class'] != \"normal\"].index\n",
    "    df.loc[atk_idx, 'class'] = 1.0\n",
    "    df.loc[df.index.difference(atk_idx), 'class'] = 0.0\n",
    "    df['class'] = df['class'].astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: class, dtype: int64\n",
      "\n",
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "rootkit              13\n",
      "xterm                13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "worm                  2\n",
      "loadmodule            2\n",
      "perl                  2\n",
      "sqlattack             2\n",
      "udpstorm              2\n",
      "phf                   2\n",
      "imap                  1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "malicious_benign(nslkdd_train)\n",
    "print()\n",
    "malicious_benign(nslkdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['service_aol', 'service_harvest', 'service_http_2784',\n",
      "       'service_http_8001', 'service_red_i', 'service_urh_i'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Columns: 117 entries, duration to flag_SH\n",
      "dtypes: float32(1), float64(15), int64(23), uint8(78)\n",
      "memory usage: 46.4 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\AppData\\Local\\Temp\\ipykernel_14864\\366472954.py:1: FutureWarning: Index.__xor__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__xor__.  Use index.symmetric_difference(other) instead.\n",
      "  extra_removables = nslkdd_test.columns ^ nslkdd_train.columns\n"
     ]
    }
   ],
   "source": [
    "extra_removables = nslkdd_test.columns ^ nslkdd_train.columns\n",
    "print(extra_removables)\n",
    "try:\n",
    "    nslkdd_train = nslkdd_train.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    nslkdd_test.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "nslkdd_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag_SH\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR',\n",
      "       'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF'],\n",
      "      dtype='object', length=116)\n",
      "flag_SH\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR',\n",
      "       'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF'],\n",
      "      dtype='object', length=116)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test  = nslkdd_split_df(nslkdd_train, nslkdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()\n",
    "\n",
    "# custom keys -> replace by index\n",
    "\n",
    "x_train = x_train.set_index([pd.Index(range (0, len(x_train)))])\n",
    "y_train = y_train.set_index([pd.Index(range (0, len(y_train)))])\n",
    "x_test = x_test.set_index([pd.Index(range (0, len(x_test)))])\n",
    "y_test = y_test.set_index([pd.Index(range (0, len(y_test)))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical DQN Agent\n",
    "\n",
    "\n",
    "Here is a summary of DQNAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "| ---              | ---                                                  |\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|compute_dqn_loss  | return dqn loss.                                     |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|target_hard_update| hard update from the local model to the target model.|\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|plot              | plot the training progresses.                        |\n",
    "\n",
    "All differences from pure DQN are noted with comments *Categorical DQN*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (ReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        epsilon (float): parameter for epsilon greedy policy\n",
    "        epsilon_decay (float): step size to decrease epsilon\n",
    "        max_epsilon (float): max value of epsilon\n",
    "        min_epsilon (float): min value of epsilon\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including\n",
    "                           state, action, reward, next_state, done\n",
    "        v_min (float): min value of support\n",
    "        v_max (float): max value of support\n",
    "        atom_size (int): the unit number of support\n",
    "        support (torch.Tensor): support for categorical dqn\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        epsilon_decay: float,\n",
    "        max_epsilon: float = 1.0,\n",
    "        min_epsilon: float = 0.1,\n",
    "        gamma: float = 0.99,\n",
    "        # Categorical DQN parameters\n",
    "        v_min: float = 0.0,\n",
    "        v_max: float = 200.0,\n",
    "        atom_size: int = 51,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            epsilon_decay (float): step size to decrease epsilon\n",
    "            lr (float): learning rate\n",
    "            max_epsilon (float): max value of epsilon\n",
    "            min_epsilon (float): min value of epsilon\n",
    "            gamma (float): discount factor\n",
    "            v_min (float): min value of support\n",
    "            v_max (float): max value of support\n",
    "            atom_size (int): the unit number of support\n",
    "        \"\"\"\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.n\n",
    "        \n",
    "        self.env = env\n",
    "        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon = max_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.max_epsilon = max_epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.target_update = target_update\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(self.device)\n",
    "        \n",
    "        # Categorical DQN parameters\n",
    "        self.v_min = v_min\n",
    "        self.v_max = v_max\n",
    "        self.atom_size = atom_size\n",
    "        self.support = torch.linspace(\n",
    "            self.v_min, self.v_max, self.atom_size\n",
    "        ).to(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(\n",
    "            obs_dim, action_dim, atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target = Network(\n",
    "            obs_dim, action_dim, atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # epsilon greedy policy\n",
    "        if self.epsilon > np.random.random():\n",
    "            selected_action = self.env.action_space.sample()\n",
    "        else:\n",
    "            selected_action = self.dqn(\n",
    "                torch.FloatTensor(state).to(self.device),\n",
    "            ).argmax()\n",
    "            selected_action = selected_action.detach().cpu().numpy()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        \n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, done, _ = self.env.step(action)\n",
    "\n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            self.memory.store(*self.transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        samples = self.memory.sample_batch()\n",
    "\n",
    "        loss = self._compute_dqn_loss(samples)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        update_cnt = 0\n",
    "        epsilons = []\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state = self.env.reset()\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # linearly decrease epsilon\n",
    "                self.epsilon = max(\n",
    "                    self.min_epsilon, self.epsilon - (\n",
    "                        self.max_epsilon - self.min_epsilon\n",
    "                    ) * self.epsilon_decay\n",
    "                )\n",
    "                epsilons.append(self.epsilon)\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses, epsilons)\n",
    "                \n",
    "        self.env.close()\n",
    "                \n",
    "    def test(self) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        TP, FP, TN, FN = 0,0,0,0\n",
    "        # for recording a video\n",
    "        naive_env = self.env\n",
    "        self.env = IdsEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)\n",
    "\n",
    "        action = self.env.reset()\n",
    "        done = False\n",
    "        count = 0\n",
    "        try:\n",
    "            while True:\n",
    "\n",
    "                done = False\n",
    "                while not done:\n",
    "                    count += 1\n",
    "                    action = self.select_action(action)\n",
    "                    next_action, rew, done, info = self.env.step(action)\n",
    "                    action = next_action\n",
    "                    label = info['label']\n",
    "                    if label == 0 and rew > 0:\n",
    "                        TP += 1\n",
    "                    if label == 0 and rew == 0:\n",
    "                        FP += 1\n",
    "                    if label == 1 and rew > 0:\n",
    "                        TN += 1\n",
    "                    if label == 1 and rew == 0:\n",
    "                        FN += 1\n",
    "        except StopIteration:\n",
    "            accuracy = (float(TP + TN) / (TP + FP + FN + TN)) \n",
    "            precision = (float(TP) / (TP + FP))\n",
    "            try:\n",
    "                recall = (float(TP) / (TP + FN)) # = TPR = Sensitivity\n",
    "            except:\n",
    "                recall = 0\n",
    "            try:\n",
    "                FPR = (float(FP) / (TN + FP)) # 1 - specificity\n",
    "            except:\n",
    "                FPR = 0\n",
    "            try:\n",
    "                f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "            except:\n",
    "                f1_score = 0\n",
    "            print()\n",
    "            print('validation done...')\n",
    "            print('Accuracy: {0}%'.format(accuracy * 100))\n",
    "            print('Precision: {0}%'.format(precision * 100))\n",
    "            print('Recall/TPR/Sensitivity: {0}%'.format(recall * 100))\n",
    "            print('FPR: {0}%'.format(FPR * 100))\n",
    "            print('F1 score: {0}'.format(f1_score))\n",
    "            print('count: {0}'.format(count))\n",
    "        self.env.close()\n",
    "\n",
    "        # reset\n",
    "        self.env = naive_env\n",
    "\n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:\n",
    "        \"\"\"Return categorical dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"]).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "        \n",
    "        # Categorical DQN algorithm\n",
    "        delta_z = float(self.v_max - self.v_min) / (self.atom_size - 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_action = self.dqn_target(next_state).argmax(1)\n",
    "            next_dist = self.dqn_target.dist(next_state)\n",
    "            next_dist = next_dist[range(self.batch_size), next_action]\n",
    "\n",
    "            t_z = reward + (1 - done) * self.gamma * self.support\n",
    "            t_z = t_z.clamp(min=self.v_min, max=self.v_max)\n",
    "            b = (t_z - self.v_min) / delta_z\n",
    "            l = b.floor().long()\n",
    "            u = b.ceil().long()\n",
    "\n",
    "            offset = (\n",
    "                torch.linspace(\n",
    "                    0, (self.batch_size - 1) * self.atom_size, self.batch_size\n",
    "                ).long()\n",
    "                .unsqueeze(1)\n",
    "                .expand(self.batch_size, self.atom_size)\n",
    "                .to(self.device)\n",
    "            )\n",
    "\n",
    "            proj_dist = torch.zeros(next_dist.size(), device=self.device)\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (l + offset).view(-1), (next_dist * (u.float() - b)).view(-1)\n",
    "            )\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (u + offset).view(-1), (next_dist * (b - l.float())).view(-1)\n",
    "            )\n",
    "\n",
    "        dist = self.dqn.dist(state)\n",
    "        log_p = torch.log(dist[range(self.batch_size), action])\n",
    "\n",
    "        loss = -(proj_dist * log_p).sum(1).mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores: List[float], \n",
    "        losses: List[float], \n",
    "        epsilons: List[float],\n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
    "        plt.plot(scores)\n",
    "        plt.subplot(132)\n",
    "        plt.title('loss')\n",
    "        plt.plot(losses)\n",
    "        plt.subplot(133)\n",
    "        plt.title('epsilons')\n",
    "        plt.plot(epsilons)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "You can see the [code](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py) and [configurations](https://github.com/openai/gym/blob/master/gym/envs/__init__.py#L53) of CartPole-v0 from OpenAI's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdsEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "        # Actions we can take, classify as malicious or non-malicious (later also the correct attack)\n",
    "        # change to 19 if detectiong all different attacks\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "         # All the features we have, len(important_features) - 1 features and 1 label. Label should not be included\n",
    "        self.observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(len(nslkdd_train.columns) - 1,))\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "    \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "        current_label = self.expected_action\n",
    "        obs = self._next_obs()\n",
    "        \n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {'label': current_label}\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y.iloc[next_obs_idx,:])\n",
    "            obs = self.x.iloc[next_obs_idx,:]\n",
    "\n",
    "        else:\n",
    "            obs = self.x.iloc[self.dataset_idx]\n",
    "            self.expected_action = int(self.y.iloc[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "        return obs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "env = IdsEnv(images_per_episode=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\anaconda3\\envs\\MP\\lib\\site-packages\\gym\\core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[777]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 777\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "seed_torch(seed)\n",
    "env.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames = int(1.0e5)\n",
    "memory_size = 100000\n",
    "batch_size = 128\n",
    "target_update = 10000\n",
    "epsilon_decay = 1 / 10000\n",
    "\n",
    "# train\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update, epsilon_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.train(num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Run the trained agent (1 episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation done...\n",
      "Accuracy: 95.12909236092626%\n",
      "Precision: 95.12216832079754%\n",
      "Recall/TPR/Sensitivity: 99.9906432748538%\n",
      "FPR: 93.91602399314482%\n",
      "F1 score: 0.9749566645379071\n",
      "count: 22543\n"
     ]
    }
   ],
   "source": [
    "agent.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
