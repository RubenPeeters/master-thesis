{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'baselines' already exists and is not an empty directory.\n",
      "/project/finals/baselines\n",
      "Obtaining file:///project/finals/baselines\n",
      "Collecting gym<0.16.0,>=0.15.4\n",
      "  Downloading gym-0.15.7.tar.gz (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 13.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (1.4.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (4.46.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (0.15.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (1.4.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (7.1.2)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.5 MB 25.7 MB/s eta 0:00:01    |███▍                            | 6.3 MB 25.7 MB/s eta 0:00:03     |████                            | 7.5 MB 25.7 MB/s eta 0:00:03     |████▋                           | 8.7 MB 25.7 MB/s eta 0:00:03     |███████▎                        | 13.9 MB 25.7 MB/s eta 0:00:02     |███████████████▏                | 28.8 MB 48.5 MB/s eta 0:00:01     |█████████████████▋              | 33.3 MB 48.5 MB/s eta 0:00:01     |███████████████████▊            | 37.3 MB 48.5 MB/s eta 0:00:01     |████████████████████▍           | 38.5 MB 48.5 MB/s eta 0:00:01     |████████████████████████████▏   | 53.3 MB 48.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /opt/conda/lib/python3.7/site-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.18.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.15.0)\n",
      "Collecting pyglet<=1.5.0,>=1.4.0\n",
      "  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 9.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 19.7 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: gym, future\n",
      "  Building wheel for gym (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.15.7-py3-none-any.whl size=1648839 sha256=de59c489434fd6538efbd20156a3bf55c1994beb86d204f3089b2fad1afb555a\n",
      "  Stored in directory: /home/rppeeter/.cache/pip/wheels/be/72/05/d3dfcfc2a31bbf886112b6373881bdf2e9e00d2c943f3b4f91\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=2934bcdf1205655fb541ed54b20be26227994a119e047c72776b79b626d37258\n",
      "  Stored in directory: /home/rppeeter/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "Successfully built gym future\n",
      "\u001b[31mERROR: gym 0.15.7 has requirement cloudpickle~=1.2.0, but you'll have cloudpickle 1.4.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: future, pyglet, gym, opencv-python, baselines\n",
      "  Running setup.py develop for baselines\n",
      "Successfully installed baselines future-0.18.2 gym-0.15.7 opencv-python-4.5.5.64 pyglet-1.5.0\n",
      "Collecting stable-baselines\n",
      "  Downloading stable_baselines-2.10.2-py3-none-any.whl (240 kB)\n",
      "\u001b[K     |████████████████████████████████| 240 kB 18.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (1.4.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (1.0.4)\n",
      "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (0.15.7)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (4.5.5.64)\n",
      "Requirement already satisfied: cloudpickle>=0.5.5 in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (1.4.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (3.2.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (0.15.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas->stable-baselines) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->stable-baselines) (2020.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines) (1.15.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines) (1.5.0)\n",
      "Collecting atari-py~=0.2.0; extra == \"atari\"\n",
      "  Downloading atari_py-0.2.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 22.0 MB/s eta 0:00:01     |██████████████████              | 1.6 MB 22.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Pillow; extra == \"atari\" in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines) (7.1.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines) (0.10.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines) (0.18.2)\n",
      "Installing collected packages: stable-baselines, atari-py\n",
      "Successfully installed atari-py-0.2.9 stable-baselines-2.10.2\n",
      "Collecting tensorflow==1.14.0\n",
      "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 109.3 MB 100 kB/s  eta 0:00:01    |███████                         | 23.9 MB 11.6 MB/s eta 0:00:08     |████████▏                       | 28.0 MB 11.6 MB/s eta 0:00:07     |████████████▎                   | 41.9 MB 28.4 MB/s eta 0:00:03     |████████████▋                   | 43.2 MB 28.4 MB/s eta 0:00:03     |████████████████▉               | 57.6 MB 28.4 MB/s eta 0:00:02     |██████████████████████▌         | 76.9 MB 49.5 MB/s eta 0:00:01     |████████████████████████▏       | 82.4 MB 49.5 MB/s eta 0:00:01     |███████████████████████████▎    | 93.0 MB 28.7 MB/s eta 0:00:01     |███████████████████████████▋    | 94.2 MB 28.7 MB/s eta 0:00:01     |█████████████████████████████▌  | 100.8 MB 28.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (3.11.4)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.2.0)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.34.2)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
      "\u001b[K     |████████████████████████████████| 488 kB 18.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.9.0)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 20.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.29.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (47.1.1.post20200529)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.6.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.0)\n",
      "Installing collected packages: keras-applications, astor, tensorflow-estimator, tensorboard, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.2.0\n",
      "    Uninstalling tensorflow-estimator-2.2.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.2.2\n",
      "    Uninstalling tensorboard-2.2.2:\n",
      "      Successfully uninstalled tensorboard-2.2.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.2.0\n",
      "    Uninstalling tensorflow-2.2.0:\n",
      "      Successfully uninstalled tensorflow-2.2.0\n",
      "Successfully installed astor-0.8.1 keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
      "Collecting tensorflow-gpu==1.14.0\n",
      "  Downloading tensorflow_gpu-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (377.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 377.1 MB 10 kB/s  eta 0:00:012   |▉                               | 9.7 MB 19.2 MB/s eta 0:00:20     |██                              | 23.8 MB 19.2 MB/s eta 0:00:19     |██▍                             | 28.0 MB 19.2 MB/s eta 0:00:19     |██▊                             | 32.0 MB 27.0 MB/s eta 0:00:13     |███▎                            | 38.5 MB 27.0 MB/s eta 0:00:13     |██████▍                         | 75.6 MB 31.4 MB/s eta 0:00:10     |███████                         | 82.5 MB 31.4 MB/s eta 0:00:10     |███████▊                        | 91.6 MB 26.9 MB/s eta 0:00:11     |███████▉                        | 92.9 MB 26.9 MB/s eta 0:00:11     |████████▎                       | 97.0 MB 26.9 MB/s eta 0:00:11     |█████████                       | 105.2 MB 26.9 MB/s eta 0:00:11     |██████████▉                     | 127.5 MB 53.2 MB/s eta 0:00:05     |███████████                     | 128.7 MB 53.2 MB/s eta 0:00:05     |███████████▏                    | 131.5 MB 53.2 MB/s eta 0:00:05     |████████████                    | 142.2 MB 27.9 MB/s eta 0:00:09     |██████████████                  | 166.0 MB 27.9 MB/s eta 0:00:08     |██████████████▌                 | 170.7 MB 23.8 MB/s eta 0:00:09     |███████████████▏                | 178.6 MB 23.8 MB/s eta 0:00:09     |███████████████▍                | 180.9 MB 23.8 MB/s eta 0:00:09     |███████████████▌                | 183.2 MB 23.8 MB/s eta 0:00:09     |███████████████▋                | 184.3 MB 23.8 MB/s eta 0:00:09     |███████████████▊                | 185.4 MB 23.8 MB/s eta 0:00:09     |███████████████▉                | 186.5 MB 23.8 MB/s eta 0:00:09     |████████████████▏               | 189.9 MB 23.6 MB/s eta 0:00:08     |████████████████▍               | 193.4 MB 23.6 MB/s eta 0:00:08     |█████████████████               | 199.9 MB 23.6 MB/s eta 0:00:08     |█████████████████▍              | 204.9 MB 23.6 MB/s eta 0:00:08     |██████████████████              | 211.2 MB 22.0 MB/s eta 0:00:08     |██████████████████▏             | 214.3 MB 22.0 MB/s eta 0:00:08     |██████████████████▌             | 218.5 MB 22.0 MB/s eta 0:00:08     |██████████████████▋             | 219.5 MB 22.0 MB/s eta 0:00:08     |██████████████████▊             | 220.5 MB 22.0 MB/s eta 0:00:08     |████████████████████▌           | 241.3 MB 32.2 MB/s eta 0:00:05     |█████████████████████           | 246.5 MB 32.2 MB/s eta 0:00:05     |█████████████████████▎          | 250.7 MB 32.2 MB/s eta 0:00:04     |█████████████████████▍          | 251.8 MB 32.2 MB/s eta 0:00:04     |█████████████████████▋          | 254.9 MB 10.2 MB/s eta 0:00:12     |█████████████████████▊          | 256.0 MB 10.2 MB/s eta 0:00:12     |███████████████████████▎        | 274.5 MB 10.2 MB/s eta 0:00:11     |████████████████████████        | 283.8 MB 7.4 MB/s eta 0:00:13     |████████████████████████▏       | 284.8 MB 7.4 MB/s eta 0:00:13     |████████████████████████▎       | 286.8 MB 7.4 MB/s eta 0:00:13     |████████████████████████▍       | 287.7 MB 7.4 MB/s eta 0:00:13     |████████████████████████▊       | 290.7 MB 7.4 MB/s eta 0:00:12     |████████████████████████▊       | 291.8 MB 7.4 MB/s eta 0:00:12     |████████████████████████▉       | 292.8 MB 7.4 MB/s eta 0:00:12     |██████████████████████████▍     | 310.4 MB 9.6 MB/s eta 0:00:07     |██████████████████████████▍     | 311.4 MB 9.6 MB/s eta 0:00:07     |███████████████████████████▎    | 321.4 MB 7.4 MB/s eta 0:00:08     |███████████████████████████▉    | 328.5 MB 7.4 MB/s eta 0:00:07     |████████████████████████████    | 329.4 MB 7.4 MB/s eta 0:00:07     |████████████████████████████    | 330.4 MB 7.4 MB/s eta 0:00:07     |█████████████████████████████▋  | 348.5 MB 11.5 MB/s eta 0:00:03     |█████████████████████████████▋  | 349.5 MB 11.5 MB/s eta 0:00:03     |█████████████████████████████▊  | 350.5 MB 11.5 MB/s eta 0:00:03     |█████████████████████████████▉  | 351.5 MB 11.5 MB/s eta 0:00:03     |██████████████████████████████  | 354.5 MB 11.5 MB/s eta 0:00:02     |██████████████████████████████▋ | 360.6 MB 7.1 MB/s eta 0:00:03     |███████████████████████████████ | 366.5 MB 7.1 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (3.11.4)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.29.0)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<1.15.0,>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14.0) (47.1.1.post20200529)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.6.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.1.0)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-1.14.0\n",
      "Requirement already satisfied: gym in /opt/conda/lib/python3.7/site-packages (0.15.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gym) (1.15.0)\n",
      "Collecting cloudpickle~=1.2.0\n",
      "  Downloading cloudpickle-1.2.2-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /opt/conda/lib/python3.7/site-packages (from gym) (1.18.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from gym) (1.4.1)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.18.2)\n",
      "\u001b[31mERROR: distributed 2.18.0 has requirement cloudpickle>=1.3.0, but you'll have cloudpickle 1.2.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: cloudpickle\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 1.4.1\n",
      "    Uninstalling cloudpickle-1.4.1:\n",
      "      Successfully uninstalled cloudpickle-1.4.1\n",
      "Successfully installed cloudpickle-1.2.2\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-7.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.7 MB 29.3 MB/s eta 0:00:01   |███████████▎                    | 9.4 MB 8.6 MB/s eta 0:00:03     |██████████████▍                 | 12.0 MB 8.6 MB/s eta 0:00:02     |███████████████▉                | 13.2 MB 8.6 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from pyarrow) (1.18.5)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-7.0.0\n",
      "Found existing installation: tensorboard-plugin-wit 1.6.0.post3\n",
      "Uninstalling tensorboard-plugin-wit-1.6.0.post3:\n",
      "  Successfully uninstalled tensorboard-plugin-wit-1.6.0.post3\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/openai/baselines.git\n",
    "%cd baselines\n",
    "!pip install -e .\n",
    "!pip install stable-baselines\n",
    "!pip install --upgrade tensorflow==1.14.0\n",
    "!pip install --upgrade tensorflow-gpu==1.14.0\n",
    "!pip install gym\n",
    "!pip install pyarrow\n",
    "!pip uninstall --yes tensorboard-plugin-wit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 13371101191345577359,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 1551977477232836168\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 4905980035791745987\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gym\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from datetime import datetime\n",
    "\n",
    "from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "\n",
    "from stable_baselines import deepq\n",
    "from stable_baselines import bench\n",
    "from stable_baselines import logger\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from baselines.common.tf_util import make_session\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/finals\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "logdir = \"Training/Logs/DQN/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Fwd Packets Length Total</th>\n",
       "      <th>Bwd Packets Length Total</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2944.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DrDoS_DNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2896.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1448.0</td>\n",
       "      <td>1448.0</td>\n",
       "      <td>1448.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DrDoS_DNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2526.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DrDoS_DNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2944.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DrDoS_DNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2944.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DrDoS_DNS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "0              1                  2                       0   \n",
       "1              1                  2                       0   \n",
       "2              1                  2                       0   \n",
       "3              1                  2                       0   \n",
       "4              1                  2                       0   \n",
       "\n",
       "   Fwd Packets Length Total  Bwd Packets Length Total  Fwd Packet Length Max  \\\n",
       "0                    2944.0                       0.0                 1472.0   \n",
       "1                    2896.0                       0.0                 1448.0   \n",
       "2                    2526.0                       0.0                 1263.0   \n",
       "3                    2944.0                       0.0                 1472.0   \n",
       "4                    2944.0                       0.0                 1472.0   \n",
       "\n",
       "   Fwd Packet Length Min  Fwd Packet Length Mean  Fwd Packet Length Std  \\\n",
       "0                 1472.0                  1472.0                    0.0   \n",
       "1                 1448.0                  1448.0                    0.0   \n",
       "2                 1263.0                  1263.0                    0.0   \n",
       "3                 1472.0                  1472.0                    0.0   \n",
       "4                 1472.0                  1472.0                    0.0   \n",
       "\n",
       "   Bwd Packet Length Max  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
       "0                    0.0  ...              1472          0.0         0.0   \n",
       "1                    0.0  ...              1480          0.0         0.0   \n",
       "2                    0.0  ...                 0          0.0         0.0   \n",
       "3                    0.0  ...                20          0.0         0.0   \n",
       "4                    0.0  ...                -1          0.0         0.0   \n",
       "\n",
       "   Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min      Label  \n",
       "0         0.0         0.0        0.0       0.0       0.0       0.0  DrDoS_DNS  \n",
       "1         0.0         0.0        0.0       0.0       0.0       0.0  DrDoS_DNS  \n",
       "2         0.0         0.0        0.0       0.0       0.0       0.0  DrDoS_DNS  \n",
       "3         0.0         0.0        0.0       0.0       0.0       0.0  DrDoS_DNS  \n",
       "4         0.0         0.0        0.0       0.0       0.0       0.0  DrDoS_DNS  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cicddos2019 = pd.read_feather(\"/project/datasets/clean-ids-collection/cic-ddos2019/clean/cicddos2019.feather\")\n",
    "# cicdos2017 = pd.read_feather(\"/project/datasets/clean-ids-collection/cic-dos2017/clean/cicdos2017.feather\")\n",
    "# cicids2017 = pd.read_feather(\"/project/datasets/clean-ids-collection/cic-ids2017/clean/cicids2017.feather\")\n",
    "data = pd.concat([cicddos2019], ignore_index=True)\n",
    "print(len(data.columns))\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "cicdos2017_features = [\"Init Bwd Win Bytes\",  \"Idle Min\", \"ACK Flag Count\", \"Fwd Packet Length Min\", \"Fwd PSH Flags\"]\n",
    "cicids2017_features = [\"Protocol\", \"Avg Bwd Segment Size\", \"Packet Length Max\", \"Bwd Packet Length Min\", \"Fwd IAT Mean\"]\n",
    "cicddos2019_features = [\"URG Flag Count\", \"Down/Up Ratio\", \"Bwd Packet Length Min\", \"ACK Flag Count\", \"Fwd Packets Length Total\"]\n",
    "important_features = cicddos2019_features + [\"Label\", \"Timestamp\"] # Adding Timestamp for custom environment logic\n",
    "important_features = list(set(important_features))\n",
    "print(len(important_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removable_features = data.columns ^ important_features\n",
    "# print(removable_features.shape)\n",
    "# skinny_data = data.drop(labels=removable_features, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 138007 entries, 0 to 138006\n",
      "Data columns (total 67 columns):\n",
      " #   Column                    Non-Null Count   Dtype   \n",
      "---  ------                    --------------   -----   \n",
      " 0   Flow Duration             138007 non-null  int32   \n",
      " 1   Total Fwd Packets         138007 non-null  int16   \n",
      " 2   Total Backward Packets    138007 non-null  int16   \n",
      " 3   Fwd Packets Length Total  138007 non-null  float32 \n",
      " 4   Bwd Packets Length Total  138007 non-null  float32 \n",
      " 5   Fwd Packet Length Max     138007 non-null  float32 \n",
      " 6   Fwd Packet Length Min     138007 non-null  float32 \n",
      " 7   Fwd Packet Length Mean    138007 non-null  float32 \n",
      " 8   Fwd Packet Length Std     138007 non-null  float32 \n",
      " 9   Bwd Packet Length Max     138007 non-null  float32 \n",
      " 10  Bwd Packet Length Min     138007 non-null  float32 \n",
      " 11  Bwd Packet Length Mean    138007 non-null  float32 \n",
      " 12  Bwd Packet Length Std     138007 non-null  float32 \n",
      " 13  Flow Bytes/s              138007 non-null  float32 \n",
      " 14  Flow Packets/s            138007 non-null  float32 \n",
      " 15  Flow IAT Mean             138007 non-null  float32 \n",
      " 16  Flow IAT Std              138007 non-null  float32 \n",
      " 17  Flow IAT Max              138007 non-null  float32 \n",
      " 18  Flow IAT Min              138007 non-null  float32 \n",
      " 19  Fwd IAT Total             138007 non-null  float32 \n",
      " 20  Fwd IAT Mean              138007 non-null  float32 \n",
      " 21  Fwd IAT Std               138007 non-null  float32 \n",
      " 22  Fwd IAT Max               138007 non-null  float32 \n",
      " 23  Fwd IAT Min               138007 non-null  float32 \n",
      " 24  Bwd IAT Total             138007 non-null  float32 \n",
      " 25  Bwd IAT Mean              138007 non-null  float32 \n",
      " 26  Bwd IAT Std               138007 non-null  float32 \n",
      " 27  Bwd IAT Max               138007 non-null  float32 \n",
      " 28  Bwd IAT Min               138007 non-null  float32 \n",
      " 29  Fwd PSH Flags             138007 non-null  int8    \n",
      " 30  Fwd Header Length         138007 non-null  int64   \n",
      " 31  Bwd Header Length         138007 non-null  int64   \n",
      " 32  Fwd Packets/s             138007 non-null  float32 \n",
      " 33  Bwd Packets/s             138007 non-null  float32 \n",
      " 34  Packet Length Min         138007 non-null  float32 \n",
      " 35  Packet Length Max         138007 non-null  float32 \n",
      " 36  Packet Length Mean        138007 non-null  float32 \n",
      " 37  Packet Length Std         138007 non-null  float32 \n",
      " 38  Packet Length Variance    138007 non-null  float32 \n",
      " 39  FIN Flag Count            138007 non-null  int8    \n",
      " 40  SYN Flag Count            138007 non-null  int8    \n",
      " 41  RST Flag Count            138007 non-null  int8    \n",
      " 42  PSH Flag Count            138007 non-null  int8    \n",
      " 43  ACK Flag Count            138007 non-null  int8    \n",
      " 44  URG Flag Count            138007 non-null  int8    \n",
      " 45  ECE Flag Count            138007 non-null  int8    \n",
      " 46  Down/Up Ratio             138007 non-null  float32 \n",
      " 47  Avg Packet Size           138007 non-null  float32 \n",
      " 48  Avg Fwd Segment Size      138007 non-null  float32 \n",
      " 49  Avg Bwd Segment Size      138007 non-null  float32 \n",
      " 50  Subflow Fwd Packets       138007 non-null  int16   \n",
      " 51  Subflow Fwd Bytes         138007 non-null  int32   \n",
      " 52  Subflow Bwd Packets       138007 non-null  int16   \n",
      " 53  Subflow Bwd Bytes         138007 non-null  int32   \n",
      " 54  Init Fwd Win Bytes        138007 non-null  int32   \n",
      " 55  Init Bwd Win Bytes        138007 non-null  int32   \n",
      " 56  Fwd Act Data Packets      138007 non-null  int16   \n",
      " 57  Fwd Seg Size Min          138007 non-null  int32   \n",
      " 58  Active Mean               138007 non-null  float32 \n",
      " 59  Active Std                138007 non-null  float32 \n",
      " 60  Active Max                138007 non-null  float32 \n",
      " 61  Active Min                138007 non-null  float32 \n",
      " 62  Idle Mean                 138007 non-null  float32 \n",
      " 63  Idle Std                  138007 non-null  float32 \n",
      " 64  Idle Max                  138007 non-null  float32 \n",
      " 65  Idle Min                  138007 non-null  float32 \n",
      " 66  Label                     138007 non-null  category\n",
      "dtypes: category(1), float32(45), int16(5), int32(6), int64(2), int8(8)\n",
      "memory usage: 31.5 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Fwd Packets Length Total</th>\n",
       "      <th>Bwd Packets Length Total</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Act Data Packets</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>138007.000000</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "      <td>1.380070e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.035663e+07</td>\n",
       "      <td>13.812169</td>\n",
       "      <td>6.636576</td>\n",
       "      <td>4.018699e+03</td>\n",
       "      <td>5.101797e+03</td>\n",
       "      <td>249.267242</td>\n",
       "      <td>132.858826</td>\n",
       "      <td>161.386505</td>\n",
       "      <td>37.345795</td>\n",
       "      <td>246.880920</td>\n",
       "      <td>...</td>\n",
       "      <td>10.525227</td>\n",
       "      <td>-1.175840e+07</td>\n",
       "      <td>7.345708e+04</td>\n",
       "      <td>3.066068e+04</td>\n",
       "      <td>1.140836e+05</td>\n",
       "      <td>5.479841e+04</td>\n",
       "      <td>3.445573e+06</td>\n",
       "      <td>3.282409e+05</td>\n",
       "      <td>3.770895e+06</td>\n",
       "      <td>3.153585e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.853154e+07</td>\n",
       "      <td>70.298079</td>\n",
       "      <td>99.503208</td>\n",
       "      <td>5.141442e+04</td>\n",
       "      <td>1.880300e+05</td>\n",
       "      <td>419.142181</td>\n",
       "      <td>234.306580</td>\n",
       "      <td>241.043732</td>\n",
       "      <td>116.252220</td>\n",
       "      <td>844.078186</td>\n",
       "      <td>...</td>\n",
       "      <td>62.973954</td>\n",
       "      <td>1.112129e+08</td>\n",
       "      <td>5.178554e+05</td>\n",
       "      <td>2.393170e+05</td>\n",
       "      <td>6.899452e+05</td>\n",
       "      <td>4.800613e+05</td>\n",
       "      <td>1.158292e+07</td>\n",
       "      <td>2.158994e+06</td>\n",
       "      <td>1.230213e+07</td>\n",
       "      <td>1.120664e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.408238e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.178000e+03</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.489200e+04</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.600000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.999380e+06</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.064000e+03</td>\n",
       "      <td>1.660000e+02</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>349.500000</td>\n",
       "      <td>14.433757</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.199987e+08</td>\n",
       "      <td>20444.000000</td>\n",
       "      <td>31700.000000</td>\n",
       "      <td>1.526642e+07</td>\n",
       "      <td>5.842950e+07</td>\n",
       "      <td>32120.000000</td>\n",
       "      <td>2131.000000</td>\n",
       "      <td>3015.290527</td>\n",
       "      <td>2221.556152</td>\n",
       "      <td>37960.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18766.000000</td>\n",
       "      <td>1.480000e+03</td>\n",
       "      <td>4.050800e+07</td>\n",
       "      <td>1.100562e+07</td>\n",
       "      <td>4.050800e+07</td>\n",
       "      <td>4.050800e+07</td>\n",
       "      <td>1.192194e+08</td>\n",
       "      <td>6.961402e+07</td>\n",
       "      <td>1.192194e+08</td>\n",
       "      <td>1.192194e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "count   1.380070e+05      138007.000000           138007.000000   \n",
       "mean    1.035663e+07          13.812169                6.636576   \n",
       "std     2.853154e+07          70.298079               99.503208   \n",
       "min     1.000000e+00           1.000000                0.000000   \n",
       "25%     1.178000e+03           2.000000                0.000000   \n",
       "50%     2.489200e+04           3.000000                2.000000   \n",
       "75%     2.999380e+06           8.000000                2.000000   \n",
       "max     1.199987e+08       20444.000000            31700.000000   \n",
       "\n",
       "       Fwd Packets Length Total  Bwd Packets Length Total  \\\n",
       "count              1.380070e+05              1.380070e+05   \n",
       "mean               4.018699e+03              5.101797e+03   \n",
       "std                5.141442e+04              1.880300e+05   \n",
       "min                0.000000e+00              0.000000e+00   \n",
       "25%                1.800000e+01              0.000000e+00   \n",
       "50%                8.600000e+01              0.000000e+00   \n",
       "75%                2.064000e+03              1.660000e+02   \n",
       "max                1.526642e+07              5.842950e+07   \n",
       "\n",
       "       Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
       "count          138007.000000          138007.000000           138007.000000   \n",
       "mean              249.267242             132.858826              161.386505   \n",
       "std               419.142181             234.306580              241.043732   \n",
       "min                 0.000000               0.000000                0.000000   \n",
       "25%                 6.000000               0.000000                6.000000   \n",
       "50%                43.000000              30.000000               39.000000   \n",
       "75%               440.000000             152.000000              349.500000   \n",
       "max             32120.000000            2131.000000             3015.290527   \n",
       "\n",
       "       Fwd Packet Length Std  Bwd Packet Length Max  ...  \\\n",
       "count          138007.000000          138007.000000  ...   \n",
       "mean               37.345795             246.880920  ...   \n",
       "std               116.252220             844.078186  ...   \n",
       "min                 0.000000               0.000000  ...   \n",
       "25%                 0.000000               0.000000  ...   \n",
       "50%                 0.000000               0.000000  ...   \n",
       "75%                14.433757              80.000000  ...   \n",
       "max              2221.556152           37960.000000  ...   \n",
       "\n",
       "       Fwd Act Data Packets  Fwd Seg Size Min   Active Mean    Active Std  \\\n",
       "count         138007.000000      1.380070e+05  1.380070e+05  1.380070e+05   \n",
       "mean              10.525227     -1.175840e+07  7.345708e+04  3.066068e+04   \n",
       "std               62.973954      1.112129e+08  5.178554e+05  2.393170e+05   \n",
       "min                0.000000     -1.408238e+09  0.000000e+00  0.000000e+00   \n",
       "25%                1.000000      2.000000e+01  0.000000e+00  0.000000e+00   \n",
       "50%                1.000000      2.000000e+01  0.000000e+00  0.000000e+00   \n",
       "75%                5.000000      2.000000e+01  0.000000e+00  0.000000e+00   \n",
       "max            18766.000000      1.480000e+03  4.050800e+07  1.100562e+07   \n",
       "\n",
       "         Active Max    Active Min     Idle Mean      Idle Std      Idle Max  \\\n",
       "count  1.380070e+05  1.380070e+05  1.380070e+05  1.380070e+05  1.380070e+05   \n",
       "mean   1.140836e+05  5.479841e+04  3.445573e+06  3.282409e+05  3.770895e+06   \n",
       "std    6.899452e+05  4.800613e+05  1.158292e+07  2.158994e+06  1.230213e+07   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    4.050800e+07  4.050800e+07  1.192194e+08  6.961402e+07  1.192194e+08   \n",
       "\n",
       "           Idle Min  \n",
       "count  1.380070e+05  \n",
       "mean   3.153585e+06  \n",
       "std    1.120664e+07  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    1.192194e+08  \n",
       "\n",
       "[8 rows x 66 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing done by Laurens D'Hooge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n",
    "- Build an agent to classify network flow automatically\n",
    "- Feed a packet that gets classified\n",
    "- Want the classification to be equal to the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_dataset_sampler_df(df, train_frac=0.2, val_frac=0.1, test_frac=0.7):\n",
    "    col = df.columns[-1]\n",
    "    print(col)\n",
    "    cols = df.columns[:-1]\n",
    "    print(cols)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    n = vc.iloc[-1]\n",
    "    print(n)\n",
    "    m = vc.iloc[0]\n",
    "    print(m)\n",
    "    print(int(m-n))\n",
    "    initial_cut = df.loc[df[col] == vc.index[0]].sample(n=int(m-n), replace=False)\n",
    "    print(initial_cut.index)\n",
    "    df = df.drop(index=initial_cut.index)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    print(int(n*train_frac))\n",
    "    train_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*train_frac), replace=False))\n",
    "    train_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=train_df.index)\n",
    "\n",
    "    validation_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*val_frac), replace=False))\n",
    "    validation_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=validation_df.index)\n",
    "\n",
    "    test_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*test_frac), replace=False))\n",
    "    test_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=test_df.index)\n",
    "\n",
    "    return train_df[cols], train_df[col], validation_df[cols], validation_df[col], test_df[cols], test_df[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign           95092\n",
      "DrDoS_NTP        13687\n",
      "TFTP             13032\n",
      "Syn               6734\n",
      "UDP               2031\n",
      "MSSQL             1338\n",
      "DrDoS_MSSQL       1325\n",
      "DrDoS_UDP         1232\n",
      "UDP-lag           1083\n",
      "DrDoS_DNS          682\n",
      "DrDoS_SSDP         473\n",
      "DrDoS_SNMP         410\n",
      "LDAP               330\n",
      "DrDoS_LDAP         210\n",
      "DrDoS_NetBIOS      144\n",
      "Portmap            122\n",
      "NetBIOS             70\n",
      "UDPLag              10\n",
      "WebDDoS              2\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data.drop('Timestamp', inplace=True, axis=1)\n",
    "except:\n",
    "    pass\n",
    "print(data['Label'].value_counts())\n",
    "data['Label'] = data['Label'].astype('object')\n",
    "atk_idx = data.loc[data['Label'] != \"Benign\"].index\n",
    "data.loc[atk_idx, 'Label'] = 1.0\n",
    "data.loc[data.index.difference(atk_idx), 'Label'] = 0.0\n",
    "data['Label'] = data['Label'].astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "Index(['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',\n",
      "       'Fwd Packets Length Total', 'Bwd Packets Length Total',\n",
      "       'Fwd Packet Length Max', 'Fwd Packet Length Min',\n",
      "       'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n",
      "       'Bwd Packet Length Max', 'Bwd Packet Length Min',\n",
      "       'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n",
      "       'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
      "       'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
      "       'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
      "       'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n",
      "       'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s',\n",
      "       'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max',\n",
      "       'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance',\n",
      "       'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count',\n",
      "       'ACK Flag Count', 'URG Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
      "       'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
      "       'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets',\n",
      "       'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes',\n",
      "       'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std',\n",
      "       'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max',\n",
      "       'Idle Min'],\n",
      "      dtype='object')\n",
      "0.0    95092\n",
      "1.0    42915\n",
      "Name: Label, dtype: int64\n",
      "42915\n",
      "95092\n",
      "52177\n",
      "Int64Index([107697,  93937,  93214, 108462,  96743, 121447,  79579,    801,\n",
      "             71681,  57733,\n",
      "            ...\n",
      "            123977,   4594, 136030,   3147,  75736, 125358, 118541,  37706,\n",
      "            103452,  82650],\n",
      "           dtype='int64', length=52177)\n",
      "0.0    42915\n",
      "1.0    42915\n",
      "Name: Label, dtype: int64\n",
      "38623\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test  = balancing_dataset_sampler_df(data, train_frac=0.9, val_frac=0.0, test_frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "(77246, 66)\n",
      "(77246,)\n",
      "Validation\n",
      "(0, 66)\n",
      "(0,)\n",
      "Testing\n",
      "(8582, 66)\n",
      "(8582,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"Validation\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(\"Testing\")\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77246, 66)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 68753, 124782, 109139,  75761, 115498,  84166, 116687,  62579,\n",
      "            119017,  84349,\n",
      "            ...\n",
      "             21090, 131056,  46986, 101067,  99608,  79416,  47788,  49970,\n",
      "             46657,  20702],\n",
      "           dtype='int64', length=77246)\n",
      "Int64Index([ 68753, 124782, 109139,  75761, 115498,  84166, 116687,  62579,\n",
      "            119017,  84349,\n",
      "            ...\n",
      "             21090, 131056,  46986, 101067,  99608,  79416,  47788,  49970,\n",
      "             46657,  20702],\n",
      "           dtype='int64', length=77246)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.index)\n",
    "print(y_train.index)\n",
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom keys -> replace by index\n",
    "\n",
    "x_train = x_train.set_index([pd.Index(range (0, len(x_train)))])\n",
    "y_train = y_train.set_index([pd.Index(range (0, len(y_train)))])\n",
    "x_test = x_test.set_index([pd.Index(range (0, len(x_test)))])\n",
    "y_test = y_test.set_index([pd.Index(range (0, len(y_test)))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=77246, step=1)\n",
      "RangeIndex(start=0, stop=77246, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.index)\n",
    "print(y_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Label\n",
      "0        0.0\n",
      "1        0.0\n",
      "2        0.0\n",
      "3        0.0\n",
      "4        0.0\n",
      "...      ...\n",
      "77241    1.0\n",
      "77242    1.0\n",
      "77243    1.0\n",
      "77244    1.0\n",
      "77245    1.0\n",
      "\n",
      "[77246 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label    0.0\n",
      "Name: 17162, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "print(y_train.iloc[17162,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=77246, step=1)\n",
      "RangeIndex(start=0, stop=77246, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.index)\n",
    "print(x_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdsEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "        # Actions we can take, classify as malicious or non-malicious (later also the correct attack)\n",
    "        # change to 19 if detectiong all different attacks\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "         # All the features we have, len(important_features) - 1 features and 1 label. Label should not be included\n",
    "        self.observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(66,))\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "    \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "        current_label = self.expected_action\n",
    "        obs = self._next_obs()\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {'label': current_label}\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y.iloc[next_obs_idx,:])\n",
    "            obs = self.x.iloc[next_obs_idx,:]\n",
    "\n",
    "        else:\n",
    "            obs = self.x.iloc[self.dataset_idx]\n",
    "            self.expected_action = int(self.y.iloc[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "        return obs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tried hyperparams 1.0e5:\n",
    "####### 53-72 %\n",
    "# learning_rate=5e-4,\n",
    "#         buffer_size=50000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.02,\n",
    "#         train_freq=1,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=1000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=500,\n",
    "#         prioritized_replay=False,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "######## 69%\n",
    "# learning_rate=5e-4,\n",
    "#         buffer_size=50000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.02,\n",
    "#         train_freq=1,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=1000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=10000,\n",
    "#         prioritized_replay=False,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "######## 57 %\n",
    "# DEFAULT\n",
    "######## 59 %\n",
    "# DEFAULT w gamma = 1.0\n",
    "######## 53%\n",
    "# learning_rate=5e-4,\n",
    "#         buffer_size=1000000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.02,\n",
    "#         train_freq=1,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=50000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=500,\n",
    "#         prioritized_replay=False,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "######### 54%\n",
    "# learning_rate=5e-4,\n",
    "#         buffer_size=1000000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.02,\n",
    "#         train_freq=4,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=50000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=500,\n",
    "#         prioritized_replay=False,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "######## 52%\n",
    "# learning_rate=2.5e-4,\n",
    "#         buffer_size=1000000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.02,\n",
    "#         train_freq=4,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=50000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=500,\n",
    "#         prioritized_replay=False,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "######### 17%\n",
    "# learning_rate=2.5e-4,\n",
    "#         buffer_size=1000000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.02,\n",
    "#         train_freq=4,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=50000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=10000,\n",
    "#         prioritized_replay=False,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "### \\/\\/\\/\\/\\/ 1.0e6\n",
    "######### 63 %\n",
    "# learning_rate=2.5e-4,\n",
    "#         buffer_size=1000000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.1,\n",
    "#         train_freq=4,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=50000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=10000,\n",
    "#         prioritized_replay=False,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "######### 37%\n",
    "# gamma=1.0\n",
    "######### error\n",
    "# learning_rate= 5e-4\n",
    "######### 50%\n",
    "# final_explor_frac=0.01\n",
    "######### 50%\n",
    "# learning_rate=5e-4,\n",
    "#         buffer_size=1000000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.02,\n",
    "#         train_freq=4,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=50000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=10000,\n",
    "#         prioritized_replay=False,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "\n",
    "######### 46%\n",
    "# learning_rate=5e-4,\n",
    "#         buffer_size=1000000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.02,\n",
    "#         train_freq=4,\n",
    "#         batch_size=32,\n",
    "#         learning_starts=50000,\n",
    "#         gamma=1.0,\n",
    "#         target_network_update_freq=10000,\n",
    "#         prioritized_replay=True\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         prioritized_replay_beta0=0.4,\n",
    "#         prioritized_replay_beta_iters=None,\n",
    "#         prioritized_replay_eps=1e-6,\n",
    "#         param_noise=False,\n",
    "\n",
    "\n",
    "#### DEZE LAATSTE ZIJN SWS SLECHT DOOR TE KLEIN AANTAL EPISODES (OF WAARDES TE GROOT -> herschalen)\n",
    "\n",
    "##### NOG DOEN\n",
    "# TRAIN FREQ = 4\n",
    "# LEARNING RATE = 0.00025\n",
    "# TARGET NETWORK UPDATE FREQUENCY HOGER\n",
    "### TEST 59%\n",
    "# network='conv_only',\n",
    "#         lr=1e-4,\n",
    "#         buffer_size=10000,\n",
    "#         exploration_fraction=0.1,\n",
    "#         exploration_final_eps=0.01,\n",
    "#         train_freq=4,\n",
    "#         learning_starts=10000,\n",
    "#         target_network_update_freq=1000,\n",
    "#         gamma=0.99,\n",
    "#         prioritized_replay=True,\n",
    "#         prioritized_replay_alpha=0.6,\n",
    "#         checkpoint_freq=10000,\n",
    "#         checkpoint_path=None,\n",
    "#         dueling=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train classifier using dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HP_LEARNING_RATE = hp.HParam('learning_rate', hp.RealInterval(0.00001, 0.0001))\n",
    "# HP_FINAL_EPS = hp.HParam('exploration_final_eps', hp.RealInterval(0.01, 0.1))\n",
    "# HP_GAMMA = hp.HParam('gamma', hp.Discrete([0.99, 1.0]))\n",
    "\n",
    "# METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "# with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "#   hp.hparams_config(\n",
    "#     hparams=[HP_LEARNING_RATE, HP_FINAL_EPS, HP_GAMMA],\n",
    "#     metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "#   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/deepq/dqn.py:129: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:359: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:139: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/deepq/policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f843c0d25d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f843c0d25d0>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f843c0d25d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f843c0d25d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c064210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c064210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c064210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c064210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c064210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c064210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c064210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c064210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c064210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c064210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c064210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c064210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:149: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f843c071410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f843c071410>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f843c071410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f843c071410>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c071a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c071a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c071a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c071a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c071f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c071f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c071f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c071f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c071f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c071f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c071f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c071f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f843c050810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f843c050810>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f843c050810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f843c050810>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84340c8750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84340c8750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84340c8750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84340c8750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84340c80d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84340c80d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84340c80d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84340c80d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84340c80d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84340c80d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84340c80d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84340c80d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:415: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/deepq/build_graph.py:449: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 60       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 50       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 40       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:0.99, learning_rate:1e-05, final_eps: 0.01 ==== (0.595, 0.4908920451586072) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f832ec7dd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f832ec7dd10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f832ec7dd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f832ec7dd10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831e92cc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831e92cc10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831e92cc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831e92cc10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831e92cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831e92cdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831e92cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831e92cdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84340a2490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84340a2490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84340a2490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84340a2490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83342a7590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83342a7590>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83342a7590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83342a7590>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c0644d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c0644d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c0644d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c0644d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c09fa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c09fa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c09fa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c09fa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c09fa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c09fa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c09fa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c09fa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f843c0b8890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f843c0b8890>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f843c0b8890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f843c0b8890>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831d07c490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831d07c490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831d07c490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831d07c490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843406d850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843406d850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843406d850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843406d850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c0b8090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c0b8090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c0b8090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c0b8090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 61       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 32       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 22       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 12       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:0.99, learning_rate:1e-05, final_eps: 0.0325 ==== (0.373, 0.483602109176542) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cbb0310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cbb0310>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cbb0310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cbb0310>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cbb0510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cbb0510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cbb0510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cbb0510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cbb0690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cbb0690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cbb0690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cbb0690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cbb0690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cbb0690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cbb0690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cbb0690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cad3590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cad3590>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cad3590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cad3590>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cad3590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cad3590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cad3590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cad3590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cad3d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cad3d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cad3d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cad3d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb61d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb61d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb61d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb61d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f84340a2810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f84340a2810>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f84340a2810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f84340a2810>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb45a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb45a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb45a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb45a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb45a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb45a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb45a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb45a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb45a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb45a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb45a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb45a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 71       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 43       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 33       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:0.99, learning_rate:1e-05, final_eps: 0.05500000000000001 ==== (0.712, 0.45283109433871693) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c5c7250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c5c7250>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c5c7250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c5c7250>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c5c7b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c5c7b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c5c7b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c5c7b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c5c7b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c5c7b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c5c7b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c5c7b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831eabbed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831eabbed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831eabbed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831eabbed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c56a810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c56a810>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c56a810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c56a810>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c54a8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c54a8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c54a8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c54a8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c0437d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c0437d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c0437d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f843c0437d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831ea81590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831ea81590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831ea81590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831ea81590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c56af10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c56af10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c56af10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c56af10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832ec5e210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832ec5e210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832ec5e210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832ec5e210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb5e990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb5e990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb5e990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb5e990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c56a810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c56a810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c56a810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c56a810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 63       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 53       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 35       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 26       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 16       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:0.99, learning_rate:1e-05, final_eps: 0.0775 ==== (0.386, 0.4868305660083393) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cbcc910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cbcc910>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cbcc910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cbcc910>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c0691d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c0691d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c0691d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c0691d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c069610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c069610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c069610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c069610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cac9490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cac9490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cac9490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cac9490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cca4610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cca4610>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cca4610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cca4610>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832ee77850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832ee77850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832ee77850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f832ee77850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831ed2ded0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831ed2ded0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831ed2ded0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831ed2ded0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c4fc510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c4fc510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c4fc510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c4fc510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c57b790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c57b790>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c57b790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c57b790>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b8c7b750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b8c7b750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b8c7b750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b8c7b750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831ea1c7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831ea1c7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831ea1c7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831ea1c7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287fd2590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287fd2590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287fd2590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287fd2590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 60       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 50       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 40       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:1.0, learning_rate:1e-05, final_eps: 0.01 ==== (0.437, 0.49601512073726134) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287a48490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287a48490>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287a48490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287a48490>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287a48690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287a48690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287a48690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287a48690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c555710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c555710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c555710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c555710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb5e950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb5e950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb5e950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cb5e950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c0c9490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c0c9490>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c0c9490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c0c9490>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c0c9490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c0c9490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c0c9490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c0c9490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cabde10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cabde10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cabde10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cabde10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83a0249990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83a0249990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83a0249990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83a0249990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831ccb1510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831ccb1510>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831ccb1510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831ccb1510>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287fd4110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287fd4110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287fd4110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287fd4110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b857c750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b857c750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b857c750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b857c750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b857c750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b857c750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b857c750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b857c750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 61       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 32       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 22       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 12       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:1.0, learning_rate:1e-05, final_eps: 0.0325 ==== (0.413, 0.4923728262201316) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82874e4450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82874e4450>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82874e4450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82874e4450>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82874e4e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82874e4e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82874e4e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82874e4e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82874e4e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82874e4e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82874e4e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82874e4e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82874e4e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82874e4e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82874e4e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82874e4e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287468c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287468c90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287468c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287468c90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b8c7db10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b8c7db10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b8c7db10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b8c7db10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b8c7da50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b8c7da50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b8c7da50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b8c7da50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cbcc1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cbcc1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cbcc1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831cbcc1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828748a150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828748a150>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828748a150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828748a150>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287468490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287468490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287468490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287468490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287468490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287468490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287468490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287468490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287468490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287468490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287468490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287468490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 71       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 43       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 33       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:1.0, learning_rate:1e-05, final_eps: 0.05500000000000001 ==== (0.341, 0.474045356479736) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828765bed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828765bed0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828765bed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828765bed0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286f0a310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286f0a310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286f0a310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286f0a310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286f0a3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286f0a3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286f0a3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286f0a3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286f0a190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286f0a190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286f0a190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286f0a190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8286ea9e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8286ea9e50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8286ea9e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8286ea9e50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c251fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c251fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c251fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c251fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c0d4410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c0d4410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c0d4410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c0d4410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c646410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c646410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c646410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c646410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8286eeffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8286eeffd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8286eeffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8286eeffd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c2517d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c2517d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c2517d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c2517d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c2517d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c2517d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c2517d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c2517d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c2517d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c2517d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c2517d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c2517d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 63       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 53       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 35       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 26       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 16       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:1.0, learning_rate:1e-05, final_eps: 0.0775 ==== (0.277, 0.4475164801434691) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82869a0550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82869a0550>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82869a0550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82869a0550>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82869a0750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82869a0750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82869a0750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82869a0750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c6f8350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c6f8350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c6f8350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c6f8350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828783fd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828783fd10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828783fd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828783fd10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828709aed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828709aed0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828709aed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828709aed0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287e69e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287e69e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287e69e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287e69e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287643bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287643bd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287643bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287643bd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287643bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287643bd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287643bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287643bd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83b8d483d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83b8d483d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83b8d483d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83b8d483d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828709ab50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828709ab50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828709ab50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828709ab50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828709a250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828709a250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828709a250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828709a250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828709a250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828709a250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828709a250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828709a250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 60       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 50       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 40       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:0.99, learning_rate:3.2500000000000004e-05, final_eps: 0.01 ==== (0.313, 0.4637143517295966) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828643c610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828643c610>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828643c610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828643c610>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828643cf90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828643cf90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828643cf90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828643cf90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828643cd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828643cd10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828643cd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828643cd10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828643cd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828643cd10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828643cd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828643cd10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82863dab10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82863dab10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82863dab10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82863dab10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b8d48c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b8d48c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b8d48c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b8d48c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831ee31510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831ee31510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831ee31510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831ee31510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c3e20d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c3e20d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c3e20d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c3e20d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82869ad7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82869ad7d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82869ad7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82869ad7d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287455b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287455b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287455b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287455b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82863fd910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82863fd910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82863fd910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82863fd910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82863fd910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82863fd910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82863fd910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82863fd910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 61       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 32       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 22       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 12       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:0.99, learning_rate:3.2500000000000004e-05, final_eps: 0.0325 ==== (0.38, 0.48538644398046393) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285e5e150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285e5e150>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285e5e150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285e5e150>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e5e350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e5e350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e5e350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e5e350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e5e550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e5e550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e5e550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e5e550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828764f110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828764f110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828764f110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828764f110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285d6d150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285d6d150>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285d6d150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285d6d150>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7d810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7d810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7d810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7d810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7da50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7da50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7da50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7da50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285df8f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285df8f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285df8f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285df8f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285d6d4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285d6d4d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285d6d4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285d6d4d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82863e1290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82863e1290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82863e1290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82863e1290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82863e19d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82863e19d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82863e19d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82863e19d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285df8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285df8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285df8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285df8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 71       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 43       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 33       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:0.99, learning_rate:3.2500000000000004e-05, final_eps: 0.05500000000000001 ==== (0.545, 0.49797088268291345) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82858f7210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82858f7210>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82858f7210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82858f7210>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82858f7ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82858f7ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82858f7ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82858f7ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82858f7a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82858f7a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82858f7a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82858f7a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82858f7b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82858f7b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82858f7b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82858f7b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285785a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285785a10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285785a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285785a10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285821110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285821110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285821110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285821110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285893dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285893dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285893dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285893dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82858f7890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82858f7890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82858f7890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82858f7890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285df8910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285df8910>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285df8910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285df8910>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7d6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7d6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7d6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7d6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7d210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7d210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7d210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7d210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7d210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7d210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7d210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285e7d210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 63       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 53       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 35       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 26       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 16       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:0.99, learning_rate:3.2500000000000004e-05, final_eps: 0.0775 ==== (0.355, 0.478513322698543) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828617fd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828617fd10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828617fd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f828617fd10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286526b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286526b10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286526b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286526b10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82860be750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82860be750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82860be750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82860be750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82860be750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82860be750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82860be750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82860be750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83340882d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83340882d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83340882d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83340882d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828615ac90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828615ac90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828615ac90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828615ac90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285d7a610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285d7a610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285d7a610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285d7a610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828531cd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828531cd50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828531cd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828531cd50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285d7a750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285d7a750>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285d7a750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285d7a750>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828615ac90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828615ac90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828615ac90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828615ac90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8334088750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8334088750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8334088750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8334088750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82867ea810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82867ea810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82867ea810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82867ea810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 60       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 50       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 40       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:1.0, learning_rate:3.2500000000000004e-05, final_eps: 0.01 ==== (0.48, 0.49959983987187184) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284db8290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284db8290>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284db8290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284db8290>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284db8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284db8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284db8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284db8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284db89d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284db89d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284db89d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284db89d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284db8590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284db8590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284db8590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284db8590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284cba950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284cba950>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284cba950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284cba950>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284d4e3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284d4e3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284d4e3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284d4e3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284d4e710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284d4e710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284d4e710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284d4e710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284d4e710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284d4e710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284d4e710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284d4e710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284d4e3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284d4e3d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284d4e3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284d4e3d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285df9c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285df9c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285df9c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285df9c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285df9c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285df9c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285df9c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285df9c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284d4e3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284d4e3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284d4e3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284d4e3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 61       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 32       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 22       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 12       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:1.0, learning_rate:3.2500000000000004e-05, final_eps: 0.0325 ==== (0.647, 0.47790270976423643) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82847d2290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82847d2290>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82847d2290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82847d2290>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82847d2cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82847d2cd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82847d2cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82847d2cd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82847d29d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82847d29d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82847d29d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82847d29d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82847d2290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82847d2290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82847d2290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82847d2290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285fff950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285fff950>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285fff950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285fff950>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284741b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284741b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284741b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284741b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284783c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284783c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284783c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284783c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bc7a4050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bc7a4050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bc7a4050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bc7a4050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cd3fbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cd3fbd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cd3fbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831cd3fbd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285edb5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285edb5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285edb5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285edb5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8334088e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8334088e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8334088e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8334088e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285fff890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285fff890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285fff890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285fff890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 71       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 43       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 33       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:1.0, learning_rate:3.2500000000000004e-05, final_eps: 0.05500000000000001 ==== (0.601, 0.48969276082049645) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284fd8890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284fd8890>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284fd8890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284fd8890>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284275110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284275110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284275110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284275110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284275590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284275590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284275590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284275590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284275590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284275590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284275590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284275590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82841a5490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82841a5490>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82841a5490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f82841a5490>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284214fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284214fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284214fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284214fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828422e310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828422e310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828422e310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828422e310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828422e310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828422e310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828422e310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828422e310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284794e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284794e50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284794e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284794e50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828422ead0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828422ead0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828422ead0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828422ead0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828422ead0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828422ead0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828422ead0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828422ead0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286186310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286186310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286186310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286186310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 63       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 53       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 35       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 26       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 16       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:1.0, learning_rate:3.2500000000000004e-05, final_eps: 0.0775 ==== (0.792, 0.4058768286069064) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285f8b3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285f8b3d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285f8b3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285f8b3d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285f8b590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285f8b590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285f8b590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285f8b590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285f8b950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285f8b950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285f8b950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285f8b950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285f8b3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285f8b3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285f8b3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285f8b3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287ddffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287ddffd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287ddffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287ddffd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284887cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284887cd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284887cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284887cd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82847bd190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82847bd190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82847bd190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82847bd190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82841f1390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82841f1390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82841f1390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82841f1390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284774690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284774690>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284774690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284774690>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286c3aad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286c3aad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286c3aad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286c3aad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284193190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284193190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284193190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284193190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284774690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284774690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284774690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284774690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 60       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 50       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 40       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:0.99, learning_rate:5.5e-05, final_eps: 0.01 ==== (0.558, 0.4966246067202068) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827f7ac490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827f7ac490>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827f7ac490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827f7ac490>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f7acdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f7acdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f7acdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f7acdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f7acdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f7acdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f7acdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f7acdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285fafdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285fafdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285fafdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285fafdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827f6cc290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827f6cc290>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827f6cc290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827f6cc290>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f7283d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f7283d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f7283d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f7283d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bc7a4a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bc7a4a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bc7a4a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bc7a4a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284197810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284197810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284197810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284197810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284778cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284778cd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284778cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8284778cd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f745e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f745e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f745e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f745e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286338990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286338990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286338990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286338990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f74b290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f74b290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f74b290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f74b290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 61       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 32       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 22       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 12       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:0.99, learning_rate:5.5e-05, final_eps: 0.0325 ==== (0.823, 0.3816687045069323) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827f14d0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827f14d0d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827f14d0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827f14d0d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f14d1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f14d1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f14d1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f14d1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828784cf90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828784cf90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828784cf90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828784cf90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828784ca50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828784ca50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828784ca50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828784ca50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83a034e490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83a034e490>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83a034e490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83a034e490>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82842b3210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82842b3210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82842b3210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82842b3210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82844f5110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82844f5110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82844f5110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82844f5110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287f37890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287f37890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287f37890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287f37890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285fbd610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285fbd610>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285fbd610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8285fbd610>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287f37c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287f37c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287f37c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287f37c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f6cd890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f6cd890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f6cd890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f6cd890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82844f5750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82844f5750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82844f5750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82844f5750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 71       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 43       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 33       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:0.99, learning_rate:5.5e-05, final_eps: 0.05500000000000001 ==== (0.519, 0.49963886958482323) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ebe50d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ebe50d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ebe50d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ebe50d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ebe5950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ebe5950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ebe5950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ebe5950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ebe5950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ebe5950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ebe5950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ebe5950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82842b3990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82842b3990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82842b3990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82842b3990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827eb852d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827eb852d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827eb852d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827eb852d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f9211d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f9211d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f9211d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f9211d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83343c5b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83343c5b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83343c5b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83343c5b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f759150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f759150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f759150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f759150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827eb851d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827eb851d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827eb851d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827eb851d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828542cd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828542cd90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828542cd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828542cd90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828542cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828542cdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828542cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828542cdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828542cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828542cdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828542cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f828542cdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 63       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 53       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 35       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 26       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 16       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:0.99, learning_rate:5.5e-05, final_eps: 0.0775 ==== (0.53, 0.49909918853871116) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e6016d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e6016d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e6016d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e6016d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f745250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f745250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f745250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f745250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e601fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e601fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e601fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e601fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285178a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285178a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285178a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285178a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e5a7e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e5a7e90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e5a7e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e5a7e90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82852b4750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82852b4750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82852b4750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82852b4750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e63d950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e63d950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e63d950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e63d950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285113950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285113950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285113950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8285113950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e633390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e633390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e633390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e633390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82852b4650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82852b4650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82852b4650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f82852b4650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e63d850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e63d850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e63d850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e63d850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e63d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e63d550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e63d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e63d550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 60       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 50       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 40       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:1.0, learning_rate:5.5e-05, final_eps: 0.01 ==== (0.74, 0.43863424398922624) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e0a5150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e0a5150>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e0a5150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e0a5150>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e0a5350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e0a5350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e0a5350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e0a5350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e5ea290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e5ea290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e5ea290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e5ea290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e5ea290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e5ea290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e5ea290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e5ea290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83c851e3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83c851e3d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83c851e3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83c851e3d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e7ec650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e7ec650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e7ec650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e7ec650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e5b3650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e5b3650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e5b3650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e5b3650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ecd1890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ecd1890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ecd1890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ecd1890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e7ecd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e7ecd10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e7ecd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827e7ecd10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e7ec8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e7ec8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e7ec8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e7ec8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e0b5b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e0b5b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e0b5b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e0b5b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284e84950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284e84950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284e84950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8284e84950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 61       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 32       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 22       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 12       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:1.0, learning_rate:5.5e-05, final_eps: 0.0325 ==== (0.279, 0.4485075250204839) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827db3d090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827db3d090>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827db3d090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827db3d090>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827db3de50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827db3de50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827db3de50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827db3de50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827db3de50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827db3de50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827db3de50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827db3de50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827db3de50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827db3de50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827db3de50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827db3de50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827f337410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827f337410>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827f337410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827f337410>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e10f750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e10f750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e10f750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e10f750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827fbe5290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827fbe5290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827fbe5290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827fbe5290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827fbe5290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827fbe5290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827fbe5290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827fbe5290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827fa888d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827fa888d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827fa888d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827fa888d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827dad2b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827dad2b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827dad2b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827dad2b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827dad2cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827dad2cd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827dad2cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827dad2cd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827fa88dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827fa88dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827fa88dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827fa88dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 71       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 43       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 33       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:1.0, learning_rate:5.5e-05, final_eps: 0.05500000000000001 ==== (0.572, 0.494788843851597) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827dc437d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827dc437d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827dc437d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827dc437d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d5700d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d5700d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d5700d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d5700d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d5708d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d5708d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d5708d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d5708d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e0b6d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e0b6d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e0b6d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e0b6d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827dc9df10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827dc9df10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827dc9df10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827dc9df10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e5b3490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e5b3490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e5b3490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e5b3490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827dc9d910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827dc9d910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827dc9d910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827dc9d910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827eacf3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827eacf3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827eacf3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827eacf3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827faf9ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827faf9ed0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827faf9ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827faf9ed0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d56a350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d56a350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d56a350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d56a350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e7ec790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e7ec790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e7ec790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e7ec790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e7ec790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e7ec790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e7ec790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827e7ec790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 63       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 53       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 35       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 26       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 16       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:1.0, learning_rate:5.5e-05, final_eps: 0.0775 ==== (0.418, 0.4932301693935601) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827cffa3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827cffa3d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827cffa3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827cffa3d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cffa5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cffa5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cffa5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cffa5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cffa810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cffa810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cffa810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cffa810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286c5ead0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286c5ead0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286c5ead0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286c5ead0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827d4eb750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827d4eb750>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827d4eb750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827d4eb750>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cf8fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cf8fd50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cf8fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cf8fd50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d6ff750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d6ff750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d6ff750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d6ff750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4fac10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4fac10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4fac10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4fac10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827dafe850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827dafe850>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827dafe850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827dafe850>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827daa57d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827daa57d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827daa57d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827daa57d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83a00d0dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83a00d0dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83a00d0dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83a00d0dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cfa95d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cfa95d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cfa95d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cfa95d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 60       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 50       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 40       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:0.99, learning_rate:7.75e-05, final_eps: 0.01 ==== (0.411, 0.49201524366629135) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ca15350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ca15350>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ca15350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ca15350>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ca15d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ca15d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ca15d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ca15d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ca15d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ca15d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ca15d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ca15d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ca15350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ca15350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ca15350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ca15350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827c9b3dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827c9b3dd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827c9b3dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827c9b3dd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4fd950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4fd950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4fd950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4fd950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4fd950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4fd950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4fd950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4fd950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4fd950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4fd950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4fd950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4fd950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827d577ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827d577ad0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827d577ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827d577ad0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f50b090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f50b090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f50b090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f50b090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f50b090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f50b090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f50b090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f50b090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827eacf750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827eacf750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827eacf750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827eacf750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 61       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 32       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 22       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 12       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:0.99, learning_rate:7.75e-05, final_eps: 0.0325 ==== (0.354, 0.4782091592598368) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827cb4a9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827cb4a9d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827cb4a9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827cb4a9d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c4b8290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c4b8290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c4b8290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c4b8290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ef70ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ef70ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ef70ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ef70ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4d6910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4d6910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4d6910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d4d6910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827cbda8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827cbda8d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827cbda8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827cbda8d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c4b8110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c4b8110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c4b8110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c4b8110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287d98cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287d98cd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287d98cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287d98cd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d164590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d164590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d164590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d164590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827d5deb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827d5deb90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827d5deb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827d5deb90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d5deb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d5deb90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d5deb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d5deb90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d5deb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d5deb90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d5deb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827d5deb90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83a00d03d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83a00d03d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83a00d03d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83a00d03d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 71       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 43       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 33       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:0.99, learning_rate:7.75e-05, final_eps: 0.05500000000000001 ==== (0.6, 0.48989794855663565) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827bed1550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827bed1550>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827bed1550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827bed1550>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bed1750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bed1750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bed1750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bed1750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bed1e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bed1e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bed1e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bed1e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cb77710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cb77710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cb77710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827cb77710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287d98950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287d98950>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287d98950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287d98950>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287d85090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287d85090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287d85090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8287d85090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bed9650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bed9650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bed9650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bed9650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f0d8a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f0d8a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f0d8a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f0d8a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287d98e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287d98e10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287d98e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8287d98e10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c515a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c515a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c515a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c515a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827befd310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827befd310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827befd310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827befd310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bed9790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bed9790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bed9790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bed9790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 63       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 53       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 35       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 26       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 16       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:0.99, learning_rate:7.75e-05, final_eps: 0.0775 ==== (0.433, 0.4954906659060289) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827b96c490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827b96c490>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827b96c490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827b96c490>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b96cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b96cdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b96cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b96cdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b96cc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b96cc10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b96cc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b96cc10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b96cf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b96cf50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b96cf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b96cf50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827eef5890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827eef5890>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827eef5890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827eef5890>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c60db50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c60db50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c60db50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c60db50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f0d8890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f0d8890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f0d8890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827f0d8890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b844f490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b844f490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b844f490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83b844f490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827eef5090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827eef5090>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827eef5090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827eef5090>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b9201d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b9201d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b9201d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b9201d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b9200d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b9200d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b9200d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b9200d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b9200d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b9200d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b9200d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b9200d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 60       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 50       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 40       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 30       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 10       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.2      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 1        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:1.0, learning_rate:7.75e-05, final_eps: 0.01 ==== (0.558, 0.4966246067202068) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827b38d150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827b38d150>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827b38d150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827b38d150>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b38d250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b38d250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b38d250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b38d250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286d21b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286d21b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286d21b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286d21b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286d21b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286d21b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286d21b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8286d21b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ba94f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ba94f10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ba94f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ba94f10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c225090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c225090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c225090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c225090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b90dcd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b90dcd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b90dcd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b90dcd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b8d40d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b8d40d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b8d40d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b8d40d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c20d050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c20d050>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c20d050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f831c20d050>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c20da10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c20da10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c20da10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c20da10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c20d6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c20d6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c20d6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f831c20d6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c530090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c530090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c530090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c530090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 61       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 32       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 22       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 12       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 3        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:1.0, learning_rate:7.75e-05, final_eps: 0.0325 ==== (0.402, 0.49030194778320024) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ae25150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ae25150>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ae25150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ae25150>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ae257d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ae257d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ae257d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ae257d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ae25ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ae25ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ae25ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ae25ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bee4050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bee4050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bee4050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827bee4050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ae3d6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ae3d6d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ae3d6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827ae3d6d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c110750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c110750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c110750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c110750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c530190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c530190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c530190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c530190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c530190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c530190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c530190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827c530190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827bdf9250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827bdf9250>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827bdf9250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827bdf9250>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ad8d350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ad8d350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ad8d350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ad8d350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ad8dc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ad8dc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ad8dc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ad8dc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ce25cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ce25cd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ce25cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ce25cd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 71       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 52       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 43       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 33       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 24       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 14       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.3      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 5        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:1.0, learning_rate:7.75e-05, final_eps: 0.05500000000000001 ==== (0.614, 0.4868305660083393) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827a8af750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827a8af750>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827a8af750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827a8af750>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827a84b650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827a84b650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827a84b650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827a84b650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827a84b190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827a84b190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827a84b190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827a84b190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ce25a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ce25a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ce25a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ce25a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827a82ca10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827a82ca10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827a82ca10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827a82ca10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ae31a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ae31a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ae31a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827ae31a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827a7eab10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827a7eab10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827a7eab10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827a7eab10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b7859d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b7859d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b7859d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827b7859d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827a7ea3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827a7ea3d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827a7ea3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f827a7ea3d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827adc6910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827adc6910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827adc6910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827adc6910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827adc6910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827adc6910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827adc6910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827adc6910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827a82c550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827a82c550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827a82c550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f827a82c550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 999      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 81       |\n",
      "| episodes                | 2000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 1999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 72       |\n",
      "| episodes                | 3000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 2999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 63       |\n",
      "| episodes                | 4000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 3999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 53       |\n",
      "| episodes                | 5000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 4999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 44       |\n",
      "| episodes                | 6000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 5999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 35       |\n",
      "| episodes                | 7000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 6999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 26       |\n",
      "| episodes                | 8000     |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 7999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 16       |\n",
      "| episodes                | 9000     |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 8999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 10000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 9999     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 11000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 10999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 12000    |\n",
      "| mean 100 episode reward | 0.8      |\n",
      "| steps                   | 11999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 13000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 12999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 14000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 13999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 15000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 14999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 16000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 15999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 17000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 16999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 18000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 17999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 19000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 18999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 20000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 19999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 21000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 20999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 22000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 21999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 23000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 22999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 24000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 23999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 25000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 24999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 26000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 25999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 27000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 26999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 28000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 27999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 29000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 28999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 30000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 29999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 31000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 30999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 32000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 31999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 33000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 32999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 34000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 33999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 35000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 34999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 36000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 35999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 37000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 36999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 38000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 37999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 39000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 38999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 40000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 39999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 41000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 40999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 42000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 41999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 43000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 42999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 44000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 43999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 45000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 44999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 46000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 45999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 47000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 46999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 48000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 47999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 49000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 48999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 50000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 49999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 51000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 50999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 52000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 51999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 53000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 52999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 54000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 53999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 55000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 54999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 56000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 55999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 57000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 56999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 58000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 57999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 59000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 58999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 60000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 59999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 61000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 60999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 62000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 61999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 63000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 62999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 64000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 63999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 65000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 64999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 66000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 65999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 67000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 66999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 68000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 67999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 69000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 68999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 70000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 69999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 71000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 70999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 72000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 71999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 73000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 72999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 74000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 73999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 75000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 74999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 76000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 75999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 77000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 76999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 78000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 77999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 79000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 78999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 80000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 79999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 81000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 80999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 82000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 81999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 83000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 82999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 84000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 83999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 85000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 84999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 86000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 85999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 87000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 86999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 88000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 87999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 89000    |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| steps                   | 88999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 90000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 89999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 91000    |\n",
      "| mean 100 episode reward | 0.4      |\n",
      "| steps                   | 90999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 92000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 91999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 93000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 92999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 94000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 93999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 95000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 94999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 96000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 95999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 97000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 96999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 98000    |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| steps                   | 97999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 99000    |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 98999    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 7        |\n",
      "| episodes                | 100000   |\n",
      "| mean 100 episode reward | 0.5      |\n",
      "| steps                   | 99999    |\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================ gamma:1.0, learning_rate:7.75e-05, final_eps: 0.0775 ==== (0.567, 0.495490665906029) =============== \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines.common.evaluation import evaluate_policy\n",
    "def ids_ddqn(learning_rate, final_eps, gamma):\n",
    "    env = IdsEnv(images_per_episode=1)\n",
    "    env = bench.Monitor(env, logger.get_dir())\n",
    "\n",
    "    model = deepq.DQN(\n",
    "        MlpPolicy, \n",
    "        env, \n",
    "        policy_kwargs=dict(dueling=False),\n",
    "        double_q=False,\n",
    "        verbose=1, \n",
    "        learning_rate=learning_rate,\n",
    "        buffer_size=10000,\n",
    "        exploration_fraction=0.1,\n",
    "        exploration_final_eps=final_eps,\n",
    "        train_freq=4,\n",
    "        learning_starts=10000,\n",
    "        target_network_update_freq=1000,\n",
    "        gamma=gamma,\n",
    "        prioritized_replay=False,\n",
    "        prioritized_replay_alpha=0.6,\n",
    "        batch_size=32,\n",
    "#         tensorboard_log=logdir,\n",
    "#         full_tensorboard_log=False,\n",
    "    )\n",
    "    model.learn(\n",
    "        total_timesteps=int(1.0e5),\n",
    "        log_interval=1000,\n",
    "        \n",
    "    )\n",
    "\n",
    "#     model.save('vanilla_dqn_cicddos2019_allfeat.pkl')\n",
    "    \n",
    "    print(f'\\n\\n\\n\\n\\n\\n================ gamma:{gamma}, learning_rate:{learning_rate}, final_eps: {final_eps} ==== {evaluate_policy(model, env, n_eval_episodes=1000)} =============== \\n\\n\\n\\n\\n')\n",
    "    env.close()\n",
    "\n",
    "for learning_rate in np.linspace(0.00001,0.0001,4,endpoint=False):\n",
    "    for gamma in [0.99, 1.0]:\n",
    "        for final_eps in np.linspace(0.01,0.1,4,endpoint=False):\n",
    "            ids_ddqn(learning_rate, final_eps, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ddqn_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d5325b08a0b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F1 score: {0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mids_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddqn_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ddqn_model' is not defined"
     ]
    }
   ],
   "source": [
    "# 0 is benign (positive), 1 is malicious (negative) \n",
    "def ids_eval(model):\n",
    "    TP, FP, TN, FN = 0,0,0,0\n",
    "    env = IdsEnv(images_per_episode=4096, dataset=(x_test, y_test), random=False)\n",
    "    obs, done = env.reset(), False\n",
    "    try:\n",
    "        while True:\n",
    "            obs, done = env.reset(), False\n",
    "            while not done:\n",
    "                obs, rew, done, info = env.step(model.predict(obs)[0])\n",
    "                label = info['label']\n",
    "                if label == 0 and rew > 0:\n",
    "                    TP += 1\n",
    "                if label == 0 and rew == 0:\n",
    "                    FP += 1\n",
    "                if label == 1 and rew > 0:\n",
    "                    TN += 1\n",
    "                if label == 1 and rew == 0:\n",
    "                    FN += 1\n",
    "\n",
    "    except StopIteration:\n",
    "        accuracy = (float(TP + TN) / (TP + FP + FN + TN)) \n",
    "        precision = (float(TP) / (TP + FP))\n",
    "        recall = (float(TP) / (TP + FN)) # = TPR = Sensitivity\n",
    "        FPR = (float(FP) / (TN + FP)) # 1 - specificity\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        print()\n",
    "        print('validation done...')\n",
    "        print('Accuracy: {0}%'.format(accuracy * 100))\n",
    "        print('Precision: {0}%'.format(precision * 100))\n",
    "        print('Recall/TPR/Sensitivity: {0}%'.format(recall * 100))\n",
    "        print('FPR: {0}%'.format(FPR * 100))\n",
    "        print('F1 score: {0}'.format(f1_score))\n",
    "\n",
    "ids_eval(ddqn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
