{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt install python-opengl\n",
    "    !apt install ffmpeg\n",
    "    !apt install xvfb\n",
    "    !pip install PyVirtualDisplay==3.0\n",
    "    !pip install gym==0.21.0\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    # Start virtual display\n",
    "    dis = Display(visible=0, size=(400, 400))\n",
    "    dis.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Prioritized Experience Replay (PER)\n",
    "\n",
    "[T. Schaul et al., \"Prioritized Experience Replay.\" arXiv preprint arXiv:1511.05952, 2015.](https://arxiv.org/pdf/1511.05952.pdf)\n",
    "\n",
    "Using a replay memory leads to design choices at two levels: which experiences to store, and which experiences to replay (and how to do so). This paper addresses only the latter: making the most effective use of the replay memory for learning, assuming that its contents are outside of our control.\n",
    "\n",
    "The central component of prioritized replay is the criterion by which the importance of each transition is measured. A reasonable approach is to use the magnitude of a transition’s TD error $\\delta$, which indicates how ‘surprising’\n",
    "or unexpected the transition is. This algorithm stores the last encountered TD error along with each transition in the replay memory. The transition with the largest absolute TD error is replayed from the memory. A Q-learning update\n",
    "is applied to this transition, which updates the weights in proportion to the TD error. One thing to note that new transitions arrive without a known TD-error, so it puts them at maximal priority in order to guarantee that all experience is seen at least once. (see *store* method)\n",
    "\n",
    "We might use 2 ideas to deal with TD-error: 1. greedy TD-error prioritization, 2. stochastic prioritization. However, greedy TD-error prioritization has a severe drawback. Greedy prioritization focuses on a small subset of the experience: errors shrink slowly, especially when using function approximation, meaning that the initially high error transitions get replayed frequently. This lack of diversity that makes the system prone to over-fitting. To overcome this issue, we will use a stochastic sampling method that interpolates between pure greedy prioritization and uniform random sampling.\n",
    "\n",
    "$$\n",
    "P(i) = \\frac{p_i^{\\alpha}}{\\sum_k p_k^{\\alpha}}\n",
    "$$\n",
    "\n",
    "where $p_i > 0$ is the priority of transition $i$. The exponent $\\alpha$ determines how much prioritization is used, with $\\alpha = 0$ corresponding to the uniform case. In practice, we use additional term $\\epsilon$ in order to guarantee all transactions can be possibly sampled: $p_i = |\\delta_i| + \\epsilon$, where $\\epsilon$ is a small positive constant.\n",
    "\n",
    "One more. Let's recall one of the main ideas of DQN. To remove correlation of observations, it uses uniformly random sampling from the replay buffer. Prioritized replay introduces bias because it doesn't sample experiences uniformly at random due to the sampling proportion correspoding to TD-error. We can correct this bias by using importance-sampling (IS) weights\n",
    "\n",
    "$$\n",
    "w_i = \\big( \\frac{1}{N} \\cdot \\frac{1}{P(i)} \\big)^\\beta\n",
    "$$\n",
    "\n",
    "that fully compensates for the non-uniform probabilities $P(i)$ if $\\beta = 1$. These weights can be folded into the Q-learning update by using $w_i\\delta_i$ instead of $\\delta_i$. In typical reinforcement learning scenarios, the unbiased nature of the updates is most important near convergence at the end of training, We therefore exploit the flexibility of annealing the amount of importance-sampling correction over time, by defining a schedule on the exponent $\\beta$ that reaches 1 only at the end of learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "\n",
    "if IN_COLAB and not os.path.exists(\"segment_tree.py\"):\n",
    "    # download segment tree module\n",
    "    !wget https://raw.githubusercontent.com/curt-park/rainbow-is-all-you-need/master/segment_tree.py\n",
    "        \n",
    "# from segment_tree import MinSegmentTree, SumSegmentTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class SegmentTree:\n",
    "    \"\"\" Create SegmentTree.\n",
    "\n",
    "    Taken from OpenAI baselines github repository:\n",
    "    https://github.com/openai/baselines/blob/master/baselines/common/segment_tree.py\n",
    "\n",
    "    Attributes:\n",
    "        capacity (int)\n",
    "        tree (list)\n",
    "        operation (function)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, capacity: int, operation: Callable, init_value: float):\n",
    "        \"\"\"Initialization.\n",
    "\n",
    "        Args:\n",
    "            capacity (int)\n",
    "            operation (function)\n",
    "            init_value (float)\n",
    "\n",
    "        \"\"\"\n",
    "        assert (\n",
    "            capacity > 0 and capacity & (capacity - 1) == 0\n",
    "        ), \"capacity must be positive and a power of 2.\"\n",
    "        self.capacity = capacity\n",
    "        self.tree = [init_value for _ in range(2 * capacity)]\n",
    "        self.operation = operation\n",
    "\n",
    "    def _operate_helper(\n",
    "        self, start: int, end: int, node: int, node_start: int, node_end: int\n",
    "    ) -> float:\n",
    "        \"\"\"Returns result of operation in segment.\"\"\"\n",
    "        if start == node_start and end == node_end:\n",
    "            return self.tree[node]\n",
    "        mid = (node_start + node_end) // 2\n",
    "        if end <= mid:\n",
    "            return self._operate_helper(start, end, 2 * node, node_start, mid)\n",
    "        else:\n",
    "            if mid + 1 <= start:\n",
    "                return self._operate_helper(start, end, 2 * node + 1, mid + 1, node_end)\n",
    "            else:\n",
    "                return self.operation(\n",
    "                    self._operate_helper(start, mid, 2 * node, node_start, mid),\n",
    "                    self._operate_helper(mid + 1, end, 2 * node + 1, mid + 1, node_end),\n",
    "                )\n",
    "\n",
    "    def operate(self, start: int = 0, end: int = 0) -> float:\n",
    "        \"\"\"Returns result of applying `self.operation`.\"\"\"\n",
    "        if end <= 0:\n",
    "            end += self.capacity\n",
    "        end -= 1\n",
    "\n",
    "        return self._operate_helper(start, end, 1, 0, self.capacity - 1)\n",
    "\n",
    "    def __setitem__(self, idx: int, val: float):\n",
    "        \"\"\"Set value in tree.\"\"\"\n",
    "        idx += self.capacity\n",
    "        self.tree[idx] = val\n",
    "\n",
    "        idx //= 2\n",
    "        while idx >= 1:\n",
    "            self.tree[idx] = self.operation(self.tree[2 * idx], self.tree[2 * idx + 1])\n",
    "            idx //= 2\n",
    "\n",
    "    def __getitem__(self, idx: int) -> float:\n",
    "        \"\"\"Get real value in leaf node of tree.\"\"\"\n",
    "        assert 0 <= idx < self.capacity\n",
    "\n",
    "        return self.tree[self.capacity + idx]\n",
    "\n",
    "\n",
    "class SumSegmentTree(SegmentTree):\n",
    "    \"\"\" Create SumSegmentTree.\n",
    "\n",
    "    Taken from OpenAI baselines github repository:\n",
    "    https://github.com/openai/baselines/blob/master/baselines/common/segment_tree.py\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, capacity: int):\n",
    "        \"\"\"Initialization.\n",
    "\n",
    "        Args:\n",
    "            capacity (int)\n",
    "\n",
    "        \"\"\"\n",
    "        super(SumSegmentTree, self).__init__(\n",
    "            capacity=capacity, operation=operator.add, init_value=0.0\n",
    "        )\n",
    "\n",
    "    def sum(self, start: int = 0, end: int = 0) -> float:\n",
    "        \"\"\"Returns arr[start] + ... + arr[end].\"\"\"\n",
    "        return super(SumSegmentTree, self).operate(start, end)\n",
    "\n",
    "    def retrieve(self, upperbound: float) -> int:\n",
    "        \"\"\"Find the highest index `i` about upper bound in the tree\"\"\"\n",
    "        # TODO: Check assert case and fix bug\n",
    "        assert 0 <= upperbound <= self.sum() + 1e-5, \"upperbound: {}\".format(upperbound)\n",
    "\n",
    "        idx = 1\n",
    "\n",
    "        while idx < self.capacity:  # while non-leaf\n",
    "            left = 2 * idx\n",
    "            right = left + 1\n",
    "            if self.tree[left] > upperbound:\n",
    "                idx = 2 * idx\n",
    "            else:\n",
    "                upperbound -= self.tree[left]\n",
    "                idx = right\n",
    "        return idx - self.capacity\n",
    "\n",
    "\n",
    "class MinSegmentTree(SegmentTree):\n",
    "    \"\"\" Create SegmentTree.\n",
    "\n",
    "    Taken from OpenAI baselines github repository:\n",
    "    https://github.com/openai/baselines/blob/master/baselines/common/segment_tree.py\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, capacity: int):\n",
    "        \"\"\"Initialization.\n",
    "\n",
    "        Args:\n",
    "            capacity (int)\n",
    "\n",
    "        \"\"\"\n",
    "        super(MinSegmentTree, self).__init__(\n",
    "            capacity=capacity, operation=min, init_value=float(\"inf\")\n",
    "        )\n",
    "\n",
    "    def min(self, start: int = 0, end: int = 0) -> float:\n",
    "        \"\"\"Returns min(arr[start], ...,  arr[end]).\"\"\"\n",
    "        return super(MinSegmentTree, self).operate(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Please see *01.dqn.ipynb* for detailed description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "\n",
    "    def store(\n",
    "        self,\n",
    "        obs: np.ndarray,\n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ):\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "        return dict(obs=self.obs_buf[idxs],\n",
    "                    next_obs=self.next_obs_buf[idxs],\n",
    "                    acts=self.acts_buf[idxs],\n",
    "                    rews=self.rews_buf[idxs],\n",
    "                    done=self.done_buf[idxs])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prioritized replay Buffer\n",
    "\n",
    "The key concept of PER's implementation is *Segment Tree*. It efficiently stores and samples transitions while managing the priorities of them. We recommend you understand how it works before you move on. Here are references for you:\n",
    "\n",
    "- In Korean: https://mrsyee.github.io/rl/2019/01/25/PER-sumtree/\n",
    "- In English: https://www.geeksforgeeks.org/segment-tree-set-1-sum-of-given-range/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer(ReplayBuffer):\n",
    "    \"\"\"Prioritized Replay buffer.\n",
    "    \n",
    "    Attributes:\n",
    "        max_priority (float): max priority\n",
    "        tree_ptr (int): next index of tree\n",
    "        alpha (float): alpha parameter for prioritized replay buffer\n",
    "        sum_tree (SumSegmentTree): sum tree for prior\n",
    "        min_tree (MinSegmentTree): min tree for min prior to get max weight\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int,\n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        alpha: float = 0.6\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        assert alpha >= 0\n",
    "        \n",
    "        super(PrioritizedReplayBuffer, self).__init__(obs_dim, size, batch_size)\n",
    "        self.max_priority, self.tree_ptr = 1.0, 0\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # capacity must be positive and a power of 2.\n",
    "        tree_capacity = 1\n",
    "        while tree_capacity < self.max_size:\n",
    "            tree_capacity *= 2\n",
    "\n",
    "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
    "        self.min_tree = MinSegmentTree(tree_capacity)\n",
    "        \n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: int, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool\n",
    "    ):\n",
    "        \"\"\"Store experience and priority.\"\"\"\n",
    "        super().store(obs, act, rew, next_obs, done)\n",
    "        \n",
    "        self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "        self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "        self.tree_ptr = (self.tree_ptr + 1) % self.max_size\n",
    "\n",
    "    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        assert len(self) >= self.batch_size\n",
    "        assert beta > 0\n",
    "        \n",
    "        indices = self._sample_proportional()\n",
    "        \n",
    "        obs = self.obs_buf[indices]\n",
    "        next_obs = self.next_obs_buf[indices]\n",
    "        acts = self.acts_buf[indices]\n",
    "        rews = self.rews_buf[indices]\n",
    "        done = self.done_buf[indices]\n",
    "        weights = np.array([self._calculate_weight(i, beta) for i in indices])\n",
    "        \n",
    "        return dict(\n",
    "            obs=obs,\n",
    "            next_obs=next_obs,\n",
    "            acts=acts,\n",
    "            rews=rews,\n",
    "            done=done,\n",
    "            weights=weights,\n",
    "            indices=indices,\n",
    "        )\n",
    "        \n",
    "    def update_priorities(self, indices: List[int], priorities: np.ndarray):\n",
    "        \"\"\"Update priorities of sampled transitions.\"\"\"\n",
    "        assert len(indices) == len(priorities)\n",
    "\n",
    "        for idx, priority in zip(indices, priorities):\n",
    "            assert priority > 0\n",
    "            assert 0 <= idx < len(self)\n",
    "\n",
    "            self.sum_tree[idx] = priority ** self.alpha\n",
    "            self.min_tree[idx] = priority ** self.alpha\n",
    "\n",
    "            self.max_priority = max(self.max_priority, priority)\n",
    "            \n",
    "    def _sample_proportional(self) -> List[int]:\n",
    "        \"\"\"Sample indices based on proportions.\"\"\"\n",
    "        indices = []\n",
    "        p_total = self.sum_tree.sum(0, len(self) - 1)\n",
    "        segment = p_total / self.batch_size\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "            upperbound = random.uniform(a, b)\n",
    "            idx = self.sum_tree.retrieve(upperbound)\n",
    "            indices.append(idx)\n",
    "            \n",
    "        return indices\n",
    "    \n",
    "    def _calculate_weight(self, idx: int, beta: float):\n",
    "        \"\"\"Calculate the weight of the experience at idx.\"\"\"\n",
    "        # get max weight\n",
    "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
    "        max_weight = (p_min * len(self)) ** (-beta)\n",
    "        \n",
    "        # calculate weights\n",
    "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
    "        weight = (p_sample * len(self)) ** (-beta)\n",
    "        weight = weight / max_weight\n",
    "        \n",
    "        return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network\n",
    "\n",
    "We are going to use a simple network architecture with three fully connected layers and two non-linearity functions (ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0         0        491          0     0               0       0    0   \n",
       "1         0        146          0     0               0       0    0   \n",
       "2         0          0          0     0               0       0    0   \n",
       "3         0        232       8153     0               0       0    0   \n",
       "4         0        199        420     0               0       0    0   \n",
       "\n",
       "   num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_RSTO  \\\n",
       "0                  0          0                0  ...         0          0   \n",
       "1                  0          0                0  ...         0          0   \n",
       "2                  0          0                0  ...         0          0   \n",
       "3                  0          1                0  ...         0          0   \n",
       "4                  0          1                0  ...         0          0   \n",
       "\n",
       "   flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
       "0            0          0        0        0        0        0        1   \n",
       "1            0          0        0        0        0        0        1   \n",
       "2            0          0        1        0        0        0        0   \n",
       "3            0          0        0        0        0        0        1   \n",
       "4            0          0        0        0        0        0        1   \n",
       "\n",
       "   flag_SH  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train = pd.read_feather(\"./datasets/nsl-kdd/KDDTrain.feather\")\n",
    "nslkdd_test = pd.read_feather(\"./datasets/nsl-kdd/KDDTest.feather\")\n",
    "# data = pd.concat([nslkdd_test], ignore_index=True)\n",
    "# print(len(data.columns))\n",
    "\n",
    "# nslkdd_train.protocol_type = pd.Categorical(nslkdd_train.protocol_type).codes\n",
    "# nslkdd_train.service = pd.Categorical(nslkdd_train.service).codes\n",
    "# nslkdd_train.flag = pd.Categorical(nslkdd_train.flag).codes\n",
    "\n",
    "\n",
    "# nslkdd_test.protocol_type = pd.Categorical(nslkdd_test.protocol_type).codes\n",
    "# nslkdd_test.service = pd.Categorical(nslkdd_test.service).codes\n",
    "# nslkdd_test.flag = pd.Categorical(nslkdd_test.flag).codes\n",
    "\n",
    "\n",
    "nslkdd_train = pd.get_dummies(nslkdd_train,columns=['protocol_type' ,'service', 'flag'])\n",
    "nslkdd_test = pd.get_dummies(nslkdd_test, columns=['protocol_type' ,'service', 'flag'])\n",
    "nslkdd_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Columns: 123 entries, duration to flag_SH\n",
      "dtypes: float64(15), int64(23), object(1), uint8(84)\n",
      "memory usage: 47.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125973.00000</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>125973.00000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>287.14465</td>\n",
       "      <td>4.556674e+04</td>\n",
       "      <td>1.977911e+04</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.204409</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.395736</td>\n",
       "      <td>0.279250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08917</td>\n",
       "      <td>0.012399</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.019218</td>\n",
       "      <td>0.276655</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.594929</td>\n",
       "      <td>0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2604.51531</td>\n",
       "      <td>5.870331e+06</td>\n",
       "      <td>4.021269e+06</td>\n",
       "      <td>0.014086</td>\n",
       "      <td>0.253530</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>2.149968</td>\n",
       "      <td>0.045239</td>\n",
       "      <td>0.489010</td>\n",
       "      <td>23.942042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28499</td>\n",
       "      <td>0.110661</td>\n",
       "      <td>0.028583</td>\n",
       "      <td>0.137292</td>\n",
       "      <td>0.447346</td>\n",
       "      <td>0.053750</td>\n",
       "      <td>0.031736</td>\n",
       "      <td>0.019719</td>\n",
       "      <td>0.490908</td>\n",
       "      <td>0.046332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.760000e+02</td>\n",
       "      <td>5.160000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42908.00000</td>\n",
       "      <td>1.379964e+09</td>\n",
       "      <td>1.309937e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes           land  \\\n",
       "count  125973.00000  1.259730e+05  1.259730e+05  125973.000000   \n",
       "mean      287.14465  4.556674e+04  1.977911e+04       0.000198   \n",
       "std      2604.51531  5.870331e+06  4.021269e+06       0.014086   \n",
       "min         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "25%         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "50%         0.00000  4.400000e+01  0.000000e+00       0.000000   \n",
       "75%         0.00000  2.760000e+02  5.160000e+02       0.000000   \n",
       "max     42908.00000  1.379964e+09  1.309937e+09       1.000000   \n",
       "\n",
       "       wrong_fragment         urgent            hot  num_failed_logins  \\\n",
       "count   125973.000000  125973.000000  125973.000000      125973.000000   \n",
       "mean         0.022687       0.000111       0.204409           0.001222   \n",
       "std          0.253530       0.014366       2.149968           0.045239   \n",
       "min          0.000000       0.000000       0.000000           0.000000   \n",
       "25%          0.000000       0.000000       0.000000           0.000000   \n",
       "50%          0.000000       0.000000       0.000000           0.000000   \n",
       "75%          0.000000       0.000000       0.000000           0.000000   \n",
       "max          3.000000       3.000000      77.000000           5.000000   \n",
       "\n",
       "           logged_in  num_compromised  ...      flag_REJ      flag_RSTO  \\\n",
       "count  125973.000000    125973.000000  ...  125973.00000  125973.000000   \n",
       "mean        0.395736         0.279250  ...       0.08917       0.012399   \n",
       "std         0.489010        23.942042  ...       0.28499       0.110661   \n",
       "min         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "25%         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "50%         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "75%         1.000000         0.000000  ...       0.00000       0.000000   \n",
       "max         1.000000      7479.000000  ...       1.00000       1.000000   \n",
       "\n",
       "         flag_RSTOS0      flag_RSTR        flag_S0        flag_S1  \\\n",
       "count  125973.000000  125973.000000  125973.000000  125973.000000   \n",
       "mean        0.000818       0.019218       0.276655       0.002897   \n",
       "std         0.028583       0.137292       0.447346       0.053750   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       1.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             flag_S2        flag_S3        flag_SF        flag_SH  \n",
       "count  125973.000000  125973.000000  125973.000000  125973.000000  \n",
       "mean        0.001008       0.000389       0.594929       0.002151  \n",
       "std         0.031736       0.019719       0.490908       0.046332  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       1.000000       0.000000  \n",
       "75%         0.000000       0.000000       1.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 122 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train.info()\n",
    "nslkdd_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_dataset_sampler_df(df, train_frac=0.2, val_frac=0.1, test_frac=0.7):\n",
    "    col = df.columns[-1]\n",
    "    print(col)\n",
    "    cols = df.columns[:-1]\n",
    "    print(cols)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    n = vc.iloc[-1]\n",
    "    print(n)\n",
    "    m = vc.iloc[0]\n",
    "    print(m)\n",
    "    print(int(m-n))\n",
    "    initial_cut = df.loc[df[col] == vc.index[0]].sample(n=int(m-n), replace=False)\n",
    "    print(initial_cut.index)\n",
    "    df = df.drop(index=initial_cut.index)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    print(int(n*train_frac))\n",
    "    train_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*train_frac), replace=False))\n",
    "    train_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=train_df.index)\n",
    "\n",
    "    validation_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*val_frac), replace=False))\n",
    "    validation_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=validation_df.index)\n",
    "\n",
    "    test_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*test_frac), replace=False))\n",
    "    test_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=test_df.index)\n",
    "\n",
    "    return train_df[cols], train_df[col], validation_df[cols], validation_df[col], test_df[cols], test_df[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nslkdd_split_df(train_df, test_df):\n",
    "    train_col = train_df.columns[-1]\n",
    "    print(train_col)\n",
    "    train_cols = train_df.columns[:-1]\n",
    "    print(train_cols)\n",
    "    test_col = test_df.columns[-1]\n",
    "    print(test_col)\n",
    "    test_cols = test_df.columns[:-1]\n",
    "    print(test_cols)\n",
    "\n",
    "    return train_df[train_cols], train_df[train_col], test_df[test_cols], test_df[test_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def malicious_benign(df):\n",
    "    print(df['class'].value_counts())\n",
    "    df['class'] = df['class'].astype('object')\n",
    "    atk_idx = df.loc[df['class'] != \"normal\"].index\n",
    "    df.loc[atk_idx, 'class'] = 1.0\n",
    "    df.loc[df.index.difference(atk_idx), 'class'] = 0.0\n",
    "    df['class'] = df['class'].astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: class, dtype: int64\n",
      "\n",
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "rootkit              13\n",
      "xterm                13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "worm                  2\n",
      "loadmodule            2\n",
      "perl                  2\n",
      "sqlattack             2\n",
      "udpstorm              2\n",
      "phf                   2\n",
      "imap                  1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "malicious_benign(nslkdd_train)\n",
    "print()\n",
    "malicious_benign(nslkdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['service_aol', 'service_harvest', 'service_http_2784',\n",
      "       'service_http_8001', 'service_red_i', 'service_urh_i'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Columns: 117 entries, duration to flag_SH\n",
      "dtypes: float32(1), float64(15), int64(23), uint8(78)\n",
      "memory usage: 46.4 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\AppData\\Local\\Temp\\ipykernel_22972\\366472954.py:1: FutureWarning: Index.__xor__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__xor__.  Use index.symmetric_difference(other) instead.\n",
      "  extra_removables = nslkdd_test.columns ^ nslkdd_train.columns\n"
     ]
    }
   ],
   "source": [
    "extra_removables = nslkdd_test.columns ^ nslkdd_train.columns\n",
    "print(extra_removables)\n",
    "try:\n",
    "    nslkdd_train = nslkdd_train.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    nslkdd_test.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "nslkdd_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag_SH\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR',\n",
      "       'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF'],\n",
      "      dtype='object', length=116)\n",
      "flag_SH\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR',\n",
      "       'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF'],\n",
      "      dtype='object', length=116)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test  = nslkdd_split_df(nslkdd_train, nslkdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()\n",
    "\n",
    "# custom keys -> replace by index\n",
    "\n",
    "x_train = x_train.set_index([pd.Index(range (0, len(x_train)))])\n",
    "y_train = y_train.set_index([pd.Index(range (0, len(y_train)))])\n",
    "x_test = x_test.set_index([pd.Index(range (0, len(x_test)))])\n",
    "y_test = y_test.set_index([pd.Index(range (0, len(y_test)))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN + PER Agent\n",
    "\n",
    "Here is a summary of DQNAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "| ---              | ---                                                  |\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|compute_dqn_loss  | return dqn loss.                                     |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|target_hard_update| hard update from the local model to the target model.|\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|plot              | plot the training progresses.                        |\n",
    "\n",
    "\n",
    "All differences from pure DQN are noted with comments - PER.\n",
    "\n",
    "#### __init__\n",
    "\n",
    "Here, we use PrioritizedReplayBuffer, instead of ReplayBuffer, and use hold 2 more parameters beta and priority epsilon which are used to calculate weights and new priorities respectively.\n",
    "\n",
    "#### compute_dqn_loss & update_model\n",
    "\n",
    "It returns every loss per each sample for importance sampling before average. After updating the nework, it is necessary to update priorities of all sampled experiences.\n",
    "\n",
    "#### train\n",
    "\n",
    "beta linearly increases to 1 at every training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (ReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        epsilon (float): parameter for epsilon greedy policy\n",
    "        epsilon_decay (float): step size to decrease epsilon\n",
    "        max_epsilon (float): max value of epsilon\n",
    "        min_epsilon (float): min value of epsilon\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including \n",
    "                           state, action, reward, next_state, done\n",
    "        beta (float): determines how much importance sampling is used\n",
    "        prior_eps (float): guarantees every transition can be sampled\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        epsilon_decay: float,\n",
    "        max_epsilon: float = 1.0,\n",
    "        min_epsilon: float = 0.1,\n",
    "        gamma: float = 0.99,\n",
    "        # PER parameters\n",
    "        alpha: float = 0.2,\n",
    "        beta: float = 0.6,\n",
    "        prior_eps: float = 1e-6,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            epsilon_decay (float): step size to decrease epsilon\n",
    "            lr (float): learning rate\n",
    "            max_epsilon (float): max value of epsilon\n",
    "            min_epsilon (float): min value of epsilon\n",
    "            gamma (float): discount factor\n",
    "            alpha (float): determines how much prioritization is used\n",
    "            beta (float): determines how much importance sampling is used\n",
    "            prior_eps (float): guarantees every transition can be sampled\n",
    "        \"\"\"\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.n\n",
    "        \n",
    "        self.env = env\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon = max_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.max_epsilon = max_epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.target_update = target_update\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "        \n",
    "        # PER\n",
    "        # In DQN, We used \"ReplayBuffer(obs_dim, memory_size, batch_size)\"\n",
    "        self.beta = beta\n",
    "        self.prior_eps = prior_eps\n",
    "        self.memory = PrioritizedReplayBuffer(\n",
    "            obs_dim, memory_size, batch_size, alpha\n",
    "        )\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # epsilon greedy policy\n",
    "        if self.epsilon > np.random.random():\n",
    "            selected_action = self.env.action_space.sample()\n",
    "        else:\n",
    "            selected_action = self.dqn(\n",
    "                torch.FloatTensor(state).to(self.device)\n",
    "            ).argmax()\n",
    "            selected_action = selected_action.detach().cpu().numpy()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        \n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, done, _ = self.env.step(action)\n",
    "\n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            self.memory.store(*self.transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        # PER needs beta to calculate weights\n",
    "        samples = self.memory.sample_batch(self.beta)\n",
    "        weights = torch.FloatTensor(\n",
    "            samples[\"weights\"].reshape(-1, 1)\n",
    "        ).to(self.device)\n",
    "        indices = samples[\"indices\"]\n",
    "\n",
    "        # PER: importance sampling before average\n",
    "        elementwise_loss = self._compute_dqn_loss(samples)\n",
    "        loss = torch.mean(elementwise_loss * weights)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # PER: update priorities\n",
    "        loss_for_prior = elementwise_loss.detach().cpu().numpy()\n",
    "        new_priorities = loss_for_prior + self.prior_eps\n",
    "        self.memory.update_priorities(indices, new_priorities)\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        update_cnt = 0\n",
    "        epsilons = []\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "            # PER: increase beta\n",
    "            fraction = min(frame_idx / num_frames, 1.0)\n",
    "            self.beta = self.beta + fraction * (1.0 - self.beta)\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state = self.env.reset()\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # linearly decrease epsilon\n",
    "                self.epsilon = max(\n",
    "                    self.min_epsilon, self.epsilon - (\n",
    "                        self.max_epsilon - self.min_epsilon\n",
    "                    ) * self.epsilon_decay\n",
    "                )\n",
    "                epsilons.append(self.epsilon)\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses, epsilons)\n",
    "                \n",
    "        self.env.close()\n",
    "                \n",
    "    def test(self) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        TP, FP, TN, FN = 0,0,0,0\n",
    "        # for recording a video\n",
    "        naive_env = self.env\n",
    "        self.env = IdsEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)\n",
    "\n",
    "        action = self.env.reset()\n",
    "        done = False\n",
    "        count = 0\n",
    "        try:\n",
    "            while True:\n",
    "                     \n",
    "                done = False\n",
    "                while not done:\n",
    "                    count += 1\n",
    "                    action = self.select_action(action)\n",
    "                    next_action, rew, done, info = self.env.step(action)\n",
    "                    action = next_action\n",
    "                    label = info['label']\n",
    "                    if label == 0 and rew > 0:\n",
    "                        TP += 1\n",
    "                    if label == 0 and rew == 0:\n",
    "                        FP += 1\n",
    "                    if label == 1 and rew > 0:\n",
    "                        TN += 1\n",
    "                    if label == 1 and rew == 0:\n",
    "                        FN += 1\n",
    "        except StopIteration:\n",
    "            accuracy = (float(TP + TN) / (TP + FP + FN + TN)) \n",
    "            precision = (float(TP) / (TP + FP))\n",
    "            try:\n",
    "                recall = (float(TP) / (TP + FN)) # = TPR = Sensitivity\n",
    "            except:\n",
    "                recall = 0\n",
    "            try:\n",
    "                FPR = (float(FP) / (TN + FP)) # 1 - specificity\n",
    "            except:\n",
    "                FPR = 0\n",
    "            try:\n",
    "                f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "            except:\n",
    "                f1_score = 0\n",
    "            print()\n",
    "            print('validation done...')\n",
    "            print('Accuracy: {0}%'.format(accuracy * 100))\n",
    "            print('Precision: {0}%'.format(precision * 100))\n",
    "            print('Recall/TPR/Sensitivity: {0}%'.format(recall * 100))\n",
    "            print('FPR: {0}%'.format(FPR * 100))\n",
    "            print('F1 score: {0}'.format(f1_score))\n",
    "            print('count: {0}'.format(count))\n",
    "        self.env.close()\n",
    "        \n",
    "        # reset\n",
    "        self.env = naive_env\n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:\n",
    "        \"\"\"Return dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"].reshape(-1, 1)).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "\n",
    "        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal\n",
    "        #       = r                       otherwise\n",
    "        curr_q_value = self.dqn(state).gather(1, action)\n",
    "        next_q_value = self.dqn_target(\n",
    "            next_state\n",
    "        ).max(dim=1, keepdim=True)[0].detach()\n",
    "        mask = 1 - done\n",
    "        target = (reward + self.gamma * next_q_value * mask).to(self.device)\n",
    "\n",
    "        # calculate element-wise dqn loss\n",
    "        elementwise_loss = F.smooth_l1_loss(curr_q_value, target, reduction=\"none\")\n",
    "\n",
    "        return elementwise_loss\n",
    "    \n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores: List[float], \n",
    "        losses: List[float], \n",
    "        epsilons: List[float],\n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
    "        plt.plot(scores)\n",
    "        plt.subplot(132)\n",
    "        plt.title('loss')\n",
    "        plt.plot(losses)\n",
    "        plt.subplot(133)\n",
    "        plt.title('epsilons')\n",
    "        plt.plot(epsilons)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "You can see the [code](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py) and [configurations](https://github.com/openai/gym/blob/master/gym/envs/__init__.py#L53) of CartPole-v0 from OpenAI's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdsEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "        # Actions we can take, classify as malicious or non-malicious (later also the correct attack)\n",
    "        # change to 19 if detectiong all different attacks\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "         # All the features we have, len(important_features) - 1 features and 1 label. Label should not be included\n",
    "        self.observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(len(nslkdd_train.columns) - 1,))\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "    \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "        current_label = self.expected_action\n",
    "        obs = self._next_obs()\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {'label': current_label}\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y.iloc[next_obs_idx,:])\n",
    "            obs = self.x.iloc[next_obs_idx,:]\n",
    "\n",
    "        else:\n",
    "            obs = self.x.iloc[self.dataset_idx]\n",
    "            self.expected_action = int(self.y.iloc[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "        return obs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "env = IdsEnv(images_per_episode=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\anaconda3\\envs\\MP\\lib\\site-packages\\gym\\core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[777]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 777\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "seed_torch(seed)\n",
    "env.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames = int(1.0e5)\n",
    "memory_size = 100000\n",
    "batch_size = 128\n",
    "target_update = 10000\n",
    "epsilon_decay = 1 / 10000\n",
    "\n",
    "# train\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update, epsilon_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.train(num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Run the trained agent (1 episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation done...\n",
      "Accuracy: 94.8806671990063%\n",
      "Precision: 94.88628777426676%\n",
      "Recall/TPR/Sensitivity: 99.97655334114889%\n",
      "FPR: 94.41248972884141%\n",
      "F1 score: 0.9736493583595925\n",
      "count: 22543\n"
     ]
    }
   ],
   "source": [
    "agent.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
