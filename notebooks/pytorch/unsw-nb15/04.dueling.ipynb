{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt install python-opengl\n",
    "    !apt install ffmpeg\n",
    "    !apt install xvfb\n",
    "    !pip install PyVirtualDisplay==3.0\n",
    "    !pip install gym==0.21.0\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    # Start virtual display\n",
    "    dis = Display(visible=0, size=(400, 400))\n",
    "    dis.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Dueling Network\n",
    "\n",
    "[Z. Wang et al., \"Dueling Network Architectures for Deep Reinforcement Learning.\" arXiv preprint arXiv:1511.06581, 2015.](https://arxiv.org/pdf/1511.06581.pdf)\n",
    "\n",
    "The proposed network architecture, which is named *dueling architecture*, explicitly separates the representation of state values and (state-dependent) action advantages. \n",
    "\n",
    "![fig1](https://user-images.githubusercontent.com/14961526/60322956-c2f0b600-99bb-11e9-9ed4-443bd14bc3b0.png)\n",
    "\n",
    "The dueling network automatically produces separate estimates of the state value function and advantage function, without any extra supervision. Intuitively, the dueling architecture can learn which states are (or are not) valuable, without having to learn the effect of each action for each state. This is particularly useful in states where its actions do not affect the environment in any relevant way. \n",
    "\n",
    "The dueling architecture represents both the value $V(s)$ and advantage $A(s, a)$ functions with a single deep model whose output combines the two to produce a state-action value $Q(s, a)$. Unlike in advantage updating, the representation and algorithm are decoupled by construction.\n",
    "\n",
    "$$A^\\pi (s, a) = Q^\\pi (s, a) - V^\\pi (s).$$\n",
    "\n",
    "The value function $V$ measures the how good it is to be in a particular state $s$. The $Q$ function, however, measures the the value of choosing a particular action when in this state. Now, using the definition of advantage, we might be tempted to construct the aggregating module as follows:\n",
    "\n",
    "$$Q(s, a; \\theta, \\alpha, \\beta) = V (s; \\theta, \\beta) + A(s, a; \\theta, \\alpha),$$\n",
    "\n",
    "where $\\theta$ denotes the parameters of the convolutional layers, while $\\alpha$ and $\\beta$ are the parameters of the two streams of fully-connected layers.\n",
    "\n",
    "Unfortunately, the above equation is unidentifiable in the sense that given $Q$ we cannot recover $V$ and $A$ uniquely; for example, there are uncountable pairs of $V$ and $A$ that make $Q$ values to zero. To address this issue of identifiability, we can force the advantage function estimator to have zero advantage at the chosen action. That is, we let the last module of the network implement the forward mapping.\n",
    "\n",
    "$$\n",
    "Q(s, a; \\theta, \\alpha, \\beta) = V (s; \\theta, \\beta) + \\big( A(s, a; \\theta, \\alpha) - \\max_{a' \\in |\\mathcal{A}|} A(s, a'; \\theta, \\alpha) \\big).\n",
    "$$\n",
    "\n",
    "This formula guarantees that we can recover the unique $V$ and $A$, but the optimization is not so stable because the advantages have to compensate any change to the optimal actionâ€™s advantage. Due to the reason, an alternative module that replaces the max operator with an average is proposed:\n",
    "\n",
    "$$\n",
    "Q(s, a; \\theta, \\alpha, \\beta) = V (s; \\theta, \\beta) + \\big( A(s, a; \\theta, \\alpha) - \\frac{1}{|\\mathcal{A}|} \\sum_{a'} A(s, a'; \\theta, \\alpha) \\big).\n",
    "$$\n",
    "\n",
    "Unlike the max advantage form, in this formula, the advantages only need to change as fast as the mean, so it increases the stability of optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "from torch.nn.utils import clip_grad_norm_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class SegmentTree:\n",
    "    \"\"\" Create SegmentTree.\n",
    "\n",
    "    Taken from OpenAI baselines github repository:\n",
    "    https://github.com/openai/baselines/blob/master/baselines/common/segment_tree.py\n",
    "\n",
    "    Attributes:\n",
    "        capacity (int)\n",
    "        tree (list)\n",
    "        operation (function)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, capacity: int, operation: Callable, init_value: float):\n",
    "        \"\"\"Initialization.\n",
    "\n",
    "        Args:\n",
    "            capacity (int)\n",
    "            operation (function)\n",
    "            init_value (float)\n",
    "\n",
    "        \"\"\"\n",
    "        assert (\n",
    "            capacity > 0 and capacity & (capacity - 1) == 0\n",
    "        ), \"capacity must be positive and a power of 2.\"\n",
    "        self.capacity = capacity\n",
    "        self.tree = [init_value for _ in range(2 * capacity)]\n",
    "        self.operation = operation\n",
    "\n",
    "    def _operate_helper(\n",
    "        self, start: int, end: int, node: int, node_start: int, node_end: int\n",
    "    ) -> float:\n",
    "        \"\"\"Returns result of operation in segment.\"\"\"\n",
    "        if start == node_start and end == node_end:\n",
    "            return self.tree[node]\n",
    "        mid = (node_start + node_end) // 2\n",
    "        if end <= mid:\n",
    "            return self._operate_helper(start, end, 2 * node, node_start, mid)\n",
    "        else:\n",
    "            if mid + 1 <= start:\n",
    "                return self._operate_helper(start, end, 2 * node + 1, mid + 1, node_end)\n",
    "            else:\n",
    "                return self.operation(\n",
    "                    self._operate_helper(start, mid, 2 * node, node_start, mid),\n",
    "                    self._operate_helper(mid + 1, end, 2 * node + 1, mid + 1, node_end),\n",
    "                )\n",
    "\n",
    "    def operate(self, start: int = 0, end: int = 0) -> float:\n",
    "        \"\"\"Returns result of applying `self.operation`.\"\"\"\n",
    "        if end <= 0:\n",
    "            end += self.capacity\n",
    "        end -= 1\n",
    "\n",
    "        return self._operate_helper(start, end, 1, 0, self.capacity - 1)\n",
    "\n",
    "    def __setitem__(self, idx: int, val: float):\n",
    "        \"\"\"Set value in tree.\"\"\"\n",
    "        idx += self.capacity\n",
    "        self.tree[idx] = val\n",
    "\n",
    "        idx //= 2\n",
    "        while idx >= 1:\n",
    "            self.tree[idx] = self.operation(self.tree[2 * idx], self.tree[2 * idx + 1])\n",
    "            idx //= 2\n",
    "\n",
    "    def __getitem__(self, idx: int) -> float:\n",
    "        \"\"\"Get real value in leaf node of tree.\"\"\"\n",
    "        assert 0 <= idx < self.capacity\n",
    "\n",
    "        return self.tree[self.capacity + idx]\n",
    "\n",
    "\n",
    "class SumSegmentTree(SegmentTree):\n",
    "    \"\"\" Create SumSegmentTree.\n",
    "\n",
    "    Taken from OpenAI baselines github repository:\n",
    "    https://github.com/openai/baselines/blob/master/baselines/common/segment_tree.py\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, capacity: int):\n",
    "        \"\"\"Initialization.\n",
    "\n",
    "        Args:\n",
    "            capacity (int)\n",
    "\n",
    "        \"\"\"\n",
    "        super(SumSegmentTree, self).__init__(\n",
    "            capacity=capacity, operation=operator.add, init_value=0.0\n",
    "        )\n",
    "\n",
    "    def sum(self, start: int = 0, end: int = 0) -> float:\n",
    "        \"\"\"Returns arr[start] + ... + arr[end].\"\"\"\n",
    "        return super(SumSegmentTree, self).operate(start, end)\n",
    "\n",
    "    def retrieve(self, upperbound: float) -> int:\n",
    "        \"\"\"Find the highest index `i` about upper bound in the tree\"\"\"\n",
    "        # TODO: Check assert case and fix bug\n",
    "        assert 0 <= upperbound <= self.sum() + 1e-5, \"upperbound: {}\".format(upperbound)\n",
    "\n",
    "        idx = 1\n",
    "\n",
    "        while idx < self.capacity:  # while non-leaf\n",
    "            left = 2 * idx\n",
    "            right = left + 1\n",
    "            if self.tree[left] > upperbound:\n",
    "                idx = 2 * idx\n",
    "            else:\n",
    "                upperbound -= self.tree[left]\n",
    "                idx = right\n",
    "        return idx - self.capacity\n",
    "\n",
    "\n",
    "class MinSegmentTree(SegmentTree):\n",
    "    \"\"\" Create SegmentTree.\n",
    "\n",
    "    Taken from OpenAI baselines github repository:\n",
    "    https://github.com/openai/baselines/blob/master/baselines/common/segment_tree.py\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, capacity: int):\n",
    "        \"\"\"Initialization.\n",
    "\n",
    "        Args:\n",
    "            capacity (int)\n",
    "\n",
    "        \"\"\"\n",
    "        super(MinSegmentTree, self).__init__(\n",
    "            capacity=capacity, operation=min, init_value=float(\"inf\")\n",
    "        )\n",
    "\n",
    "    def min(self, start: int = 0, end: int = 0) -> float:\n",
    "        \"\"\"Returns min(arr[start], ...,  arr[end]).\"\"\"\n",
    "        return super(MinSegmentTree, self).operate(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Please see *01.dqn.ipynb* for detailed description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "\n",
    "    def store(\n",
    "        self,\n",
    "        obs: np.ndarray,\n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ):\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "        return dict(obs=self.obs_buf[idxs],\n",
    "                    next_obs=self.next_obs_buf[idxs],\n",
    "                    acts=self.acts_buf[idxs],\n",
    "                    rews=self.rews_buf[idxs],\n",
    "                    done=self.done_buf[idxs])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dueling Network\n",
    "\n",
    "Carefully take a look at advantage and value layers separated from feature layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        # set common feature layer\n",
    "        self.feature_layer = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # set advantage layer\n",
    "        self.advantage_layer = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, out_dim),\n",
    "        )\n",
    "\n",
    "        # set value layer\n",
    "        self.value_layer = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        feature = self.feature_layer(x)\n",
    "        \n",
    "        value = self.value_layer(feature)\n",
    "        advantage = self.advantage_layer(feature)\n",
    "\n",
    "        q = value + advantage - advantage.mean(dim=-1, keepdim=True)\n",
    "        \n",
    "        return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0         0        491          0     0               0       0    0   \n",
       "1         0        146          0     0               0       0    0   \n",
       "2         0          0          0     0               0       0    0   \n",
       "3         0        232       8153     0               0       0    0   \n",
       "4         0        199        420     0               0       0    0   \n",
       "\n",
       "   num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_RSTO  \\\n",
       "0                  0          0                0  ...         0          0   \n",
       "1                  0          0                0  ...         0          0   \n",
       "2                  0          0                0  ...         0          0   \n",
       "3                  0          1                0  ...         0          0   \n",
       "4                  0          1                0  ...         0          0   \n",
       "\n",
       "   flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
       "0            0          0        0        0        0        0        1   \n",
       "1            0          0        0        0        0        0        1   \n",
       "2            0          0        1        0        0        0        0   \n",
       "3            0          0        0        0        0        0        1   \n",
       "4            0          0        0        0        0        0        1   \n",
       "\n",
       "   flag_SH  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train = pd.read_feather(\"./datasets/nsl-kdd/KDDTrain.feather\")\n",
    "nslkdd_test = pd.read_feather(\"./datasets/nsl-kdd/KDDTest.feather\")\n",
    "# data = pd.concat([nslkdd_test], ignore_index=True)\n",
    "# print(len(data.columns))\n",
    "\n",
    "# nslkdd_train.protocol_type = pd.Categorical(nslkdd_train.protocol_type).codes\n",
    "# nslkdd_train.service = pd.Categorical(nslkdd_train.service).codes\n",
    "# nslkdd_train.flag = pd.Categorical(nslkdd_train.flag).codes\n",
    "\n",
    "\n",
    "# nslkdd_test.protocol_type = pd.Categorical(nslkdd_test.protocol_type).codes\n",
    "# nslkdd_test.service = pd.Categorical(nslkdd_test.service).codes\n",
    "# nslkdd_test.flag = pd.Categorical(nslkdd_test.flag).codes\n",
    "\n",
    "\n",
    "nslkdd_train = pd.get_dummies(nslkdd_train,columns=['protocol_type' ,'service', 'flag'])\n",
    "nslkdd_test = pd.get_dummies(nslkdd_test, columns=['protocol_type' ,'service', 'flag'])\n",
    "nslkdd_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Columns: 123 entries, duration to flag_SH\n",
      "dtypes: float64(15), int64(23), object(1), uint8(84)\n",
      "memory usage: 47.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125973.00000</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>125973.00000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>287.14465</td>\n",
       "      <td>4.556674e+04</td>\n",
       "      <td>1.977911e+04</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.204409</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.395736</td>\n",
       "      <td>0.279250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08917</td>\n",
       "      <td>0.012399</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.019218</td>\n",
       "      <td>0.276655</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.594929</td>\n",
       "      <td>0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2604.51531</td>\n",
       "      <td>5.870331e+06</td>\n",
       "      <td>4.021269e+06</td>\n",
       "      <td>0.014086</td>\n",
       "      <td>0.253530</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>2.149968</td>\n",
       "      <td>0.045239</td>\n",
       "      <td>0.489010</td>\n",
       "      <td>23.942042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28499</td>\n",
       "      <td>0.110661</td>\n",
       "      <td>0.028583</td>\n",
       "      <td>0.137292</td>\n",
       "      <td>0.447346</td>\n",
       "      <td>0.053750</td>\n",
       "      <td>0.031736</td>\n",
       "      <td>0.019719</td>\n",
       "      <td>0.490908</td>\n",
       "      <td>0.046332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.760000e+02</td>\n",
       "      <td>5.160000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42908.00000</td>\n",
       "      <td>1.379964e+09</td>\n",
       "      <td>1.309937e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes           land  \\\n",
       "count  125973.00000  1.259730e+05  1.259730e+05  125973.000000   \n",
       "mean      287.14465  4.556674e+04  1.977911e+04       0.000198   \n",
       "std      2604.51531  5.870331e+06  4.021269e+06       0.014086   \n",
       "min         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "25%         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "50%         0.00000  4.400000e+01  0.000000e+00       0.000000   \n",
       "75%         0.00000  2.760000e+02  5.160000e+02       0.000000   \n",
       "max     42908.00000  1.379964e+09  1.309937e+09       1.000000   \n",
       "\n",
       "       wrong_fragment         urgent            hot  num_failed_logins  \\\n",
       "count   125973.000000  125973.000000  125973.000000      125973.000000   \n",
       "mean         0.022687       0.000111       0.204409           0.001222   \n",
       "std          0.253530       0.014366       2.149968           0.045239   \n",
       "min          0.000000       0.000000       0.000000           0.000000   \n",
       "25%          0.000000       0.000000       0.000000           0.000000   \n",
       "50%          0.000000       0.000000       0.000000           0.000000   \n",
       "75%          0.000000       0.000000       0.000000           0.000000   \n",
       "max          3.000000       3.000000      77.000000           5.000000   \n",
       "\n",
       "           logged_in  num_compromised  ...      flag_REJ      flag_RSTO  \\\n",
       "count  125973.000000    125973.000000  ...  125973.00000  125973.000000   \n",
       "mean        0.395736         0.279250  ...       0.08917       0.012399   \n",
       "std         0.489010        23.942042  ...       0.28499       0.110661   \n",
       "min         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "25%         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "50%         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "75%         1.000000         0.000000  ...       0.00000       0.000000   \n",
       "max         1.000000      7479.000000  ...       1.00000       1.000000   \n",
       "\n",
       "         flag_RSTOS0      flag_RSTR        flag_S0        flag_S1  \\\n",
       "count  125973.000000  125973.000000  125973.000000  125973.000000   \n",
       "mean        0.000818       0.019218       0.276655       0.002897   \n",
       "std         0.028583       0.137292       0.447346       0.053750   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       1.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             flag_S2        flag_S3        flag_SF        flag_SH  \n",
       "count  125973.000000  125973.000000  125973.000000  125973.000000  \n",
       "mean        0.001008       0.000389       0.594929       0.002151  \n",
       "std         0.031736       0.019719       0.490908       0.046332  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       1.000000       0.000000  \n",
       "75%         0.000000       0.000000       1.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 122 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train.info()\n",
    "nslkdd_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_dataset_sampler_df(df, train_frac=0.2, val_frac=0.1, test_frac=0.7):\n",
    "    col = df.columns[-1]\n",
    "    print(col)\n",
    "    cols = df.columns[:-1]\n",
    "    print(cols)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    n = vc.iloc[-1]\n",
    "    print(n)\n",
    "    m = vc.iloc[0]\n",
    "    print(m)\n",
    "    print(int(m-n))\n",
    "    initial_cut = df.loc[df[col] == vc.index[0]].sample(n=int(m-n), replace=False)\n",
    "    print(initial_cut.index)\n",
    "    df = df.drop(index=initial_cut.index)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    print(int(n*train_frac))\n",
    "    train_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*train_frac), replace=False))\n",
    "    train_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=train_df.index)\n",
    "\n",
    "    validation_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*val_frac), replace=False))\n",
    "    validation_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=validation_df.index)\n",
    "\n",
    "    test_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*test_frac), replace=False))\n",
    "    test_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=test_df.index)\n",
    "\n",
    "    return train_df[cols], train_df[col], validation_df[cols], validation_df[col], test_df[cols], test_df[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nslkdd_split_df(train_df, test_df):\n",
    "    train_col = train_df.columns[-1]\n",
    "    print(train_col)\n",
    "    train_cols = train_df.columns[:-1]\n",
    "    print(train_cols)\n",
    "    test_col = test_df.columns[-1]\n",
    "    print(test_col)\n",
    "    test_cols = test_df.columns[:-1]\n",
    "    print(test_cols)\n",
    "\n",
    "    return train_df[train_cols], train_df[train_col], test_df[test_cols], test_df[test_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def malicious_benign(df):\n",
    "    print(df['class'].value_counts())\n",
    "    df['class'] = df['class'].astype('object')\n",
    "    atk_idx = df.loc[df['class'] != \"normal\"].index\n",
    "    df.loc[atk_idx, 'class'] = 1.0\n",
    "    df.loc[df.index.difference(atk_idx), 'class'] = 0.0\n",
    "    df['class'] = df['class'].astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: class, dtype: int64\n",
      "\n",
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "rootkit              13\n",
      "xterm                13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "worm                  2\n",
      "loadmodule            2\n",
      "perl                  2\n",
      "sqlattack             2\n",
      "udpstorm              2\n",
      "phf                   2\n",
      "imap                  1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "malicious_benign(nslkdd_train)\n",
    "print()\n",
    "malicious_benign(nslkdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['service_aol', 'service_harvest', 'service_http_2784',\n",
      "       'service_http_8001', 'service_red_i', 'service_urh_i'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Columns: 117 entries, duration to flag_SH\n",
      "dtypes: float32(1), float64(15), int64(23), uint8(78)\n",
      "memory usage: 46.4 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\AppData\\Local\\Temp\\ipykernel_26976\\366472954.py:1: FutureWarning: Index.__xor__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__xor__.  Use index.symmetric_difference(other) instead.\n",
      "  extra_removables = nslkdd_test.columns ^ nslkdd_train.columns\n"
     ]
    }
   ],
   "source": [
    "extra_removables = nslkdd_test.columns ^ nslkdd_train.columns\n",
    "print(extra_removables)\n",
    "try:\n",
    "    nslkdd_train = nslkdd_train.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    nslkdd_test.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "nslkdd_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag_SH\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR',\n",
      "       'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF'],\n",
      "      dtype='object', length=116)\n",
      "flag_SH\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR',\n",
      "       'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF'],\n",
      "      dtype='object', length=116)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test  = nslkdd_split_df(nslkdd_train, nslkdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()\n",
    "\n",
    "# custom keys -> replace by index\n",
    "\n",
    "x_train = x_train.set_index([pd.Index(range (0, len(x_train)))])\n",
    "y_train = y_train.set_index([pd.Index(range (0, len(y_train)))])\n",
    "x_test = x_test.set_index([pd.Index(range (0, len(x_test)))])\n",
    "y_test = y_test.set_index([pd.Index(range (0, len(y_test)))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN + DuelingNet Agent (w/o Double-DQN & PER)\n",
    "\n",
    "Here is a summary of DQNAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "| ---              | ---                                                  |\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|compute_dqn_loss  | return dqn loss.                                     |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|target_hard_update| hard update from the local model to the target model.|\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|plot              | plot the training progresses.                        |\n",
    "\n",
    "\n",
    "Aside from the dueling network architecture, the authors suggest to use Double-DQN and Prioritized Experience Replay as extra components for better performance. However, we don't implement them to simplify the tutorial. There is only one diffrence between DQNAgent here and the one from *01.dqn.ipynb* and that is the usage of clip_grad_norm_ to prevent gradient exploding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (ReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        epsilon (float): parameter for epsilon greedy policy\n",
    "        epsilon_decay (float): step size to decrease epsilon\n",
    "        max_epsilon (float): max value of epsilon\n",
    "        min_epsilon (float): min value of epsilon\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including\n",
    "                           state, action, reward, next_state, done\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        epsilon_decay: float,\n",
    "        max_epsilon: float = 1.0,\n",
    "        min_epsilon: float = 0.1,\n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            epsilon_decay (float): step size to decrease epsilon\n",
    "            lr (float): learning rate\n",
    "            max_epsilon (float): max value of epsilon\n",
    "            min_epsilon (float): min value of epsilon\n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.n\n",
    "        \n",
    "        self.env = env\n",
    "        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon = max_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.max_epsilon = max_epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.target_update = target_update\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # epsilon greedy policy\n",
    "        if self.epsilon > np.random.random():\n",
    "            selected_action = self.env.action_space.sample()\n",
    "        else:\n",
    "            selected_action = self.dqn(\n",
    "                torch.FloatTensor(state).to(self.device)\n",
    "            ).argmax()\n",
    "            selected_action = selected_action.detach().cpu().numpy()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        \n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, done, _ = self.env.step(action)\n",
    "\n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            self.memory.store(*self.transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        samples = self.memory.sample_batch()\n",
    "\n",
    "        loss = self._compute_dqn_loss(samples)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # DuelingNet: we clip the gradients to have their norm less than or equal to 10.\n",
    "        clip_grad_norm_(self.dqn.parameters(), 10.0)\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        update_cnt = 0\n",
    "        epsilons = []\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state = self.env.reset()\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # linearly decrease epsilon\n",
    "                self.epsilon = max(\n",
    "                    self.min_epsilon, self.epsilon - (\n",
    "                        self.max_epsilon - self.min_epsilon\n",
    "                    ) * self.epsilon_decay\n",
    "                )\n",
    "                epsilons.append(self.epsilon)\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses, epsilons)\n",
    "                \n",
    "        self.env.close()\n",
    "                \n",
    "    def test(self) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        TP, FP, TN, FN = 0,0,0,0\n",
    "        # for recording a video\n",
    "        naive_env = self.env\n",
    "        self.env = IdsEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)\n",
    "\n",
    "        action = self.env.reset()\n",
    "        done = False\n",
    "        count = 0\n",
    "        try:\n",
    "            while True:\n",
    "                     \n",
    "                done = False\n",
    "                while not done:\n",
    "                    count += 1\n",
    "                    action = self.select_action(action)\n",
    "                    next_action, rew, done, info = self.env.step(action)\n",
    "                    action = next_action\n",
    "                    label = info['label']\n",
    "                    if label == 0 and rew > 0:\n",
    "                        TP += 1\n",
    "                    if label == 0 and rew == 0:\n",
    "                        FP += 1\n",
    "                    if label == 1 and rew > 0:\n",
    "                        TN += 1\n",
    "                    if label == 1 and rew == 0:\n",
    "                        FN += 1\n",
    "        except StopIteration:\n",
    "            accuracy = (float(TP + TN) / (TP + FP + FN + TN)) \n",
    "            precision = (float(TP) / (TP + FP))\n",
    "            try:\n",
    "                recall = (float(TP) / (TP + FN)) # = TPR = Sensitivity\n",
    "            except:\n",
    "                recall = 0\n",
    "            try:\n",
    "                FPR = (float(FP) / (TN + FP)) # 1 - specificity\n",
    "            except:\n",
    "                FPR = 0\n",
    "            try:\n",
    "                f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "            except:\n",
    "                f1_score = 0\n",
    "            print()\n",
    "            print('validation done...')\n",
    "            print('Accuracy: {0}%'.format(accuracy * 100))\n",
    "            print('Precision: {0}%'.format(precision * 100))\n",
    "            print('Recall/TPR/Sensitivity: {0}%'.format(recall * 100))\n",
    "            print('FPR: {0}%'.format(FPR * 100))\n",
    "            print('F1 score: {0}'.format(f1_score))\n",
    "            print('count: {0}'.format(count))\n",
    "        self.env.close()\n",
    "        \n",
    "        # reset\n",
    "        self.env = naive_env\n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:\n",
    "        \"\"\"Return dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"].reshape(-1, 1)).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "\n",
    "        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal\n",
    "        #       = r                       otherwise\n",
    "        curr_q_value = self.dqn(state).gather(1, action)\n",
    "        next_q_value = self.dqn_target(next_state).max(\n",
    "            dim=1, keepdim=True\n",
    "        )[0].detach()\n",
    "        mask = 1 - done\n",
    "        target = (reward + self.gamma * next_q_value * mask).to(self.device)\n",
    "\n",
    "        # calculate dqn loss\n",
    "        loss = F.smooth_l1_loss(curr_q_value, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores: List[float], \n",
    "        losses: List[float], \n",
    "        epsilons: List[float],\n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
    "        plt.plot(scores)\n",
    "        plt.subplot(132)\n",
    "        plt.title('loss')\n",
    "        plt.plot(losses)\n",
    "        plt.subplot(133)\n",
    "        plt.title('epsilons')\n",
    "        plt.plot(epsilons)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "You can see the [code](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py) and [configurations](https://github.com/openai/gym/blob/master/gym/envs/__init__.py#L53) of CartPole-v0 from OpenAI's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdsEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "        # Actions we can take, classify as malicious or non-malicious (later also the correct attack)\n",
    "        # change to 19 if detectiong all different attacks\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "         # All the features we have, len(important_features) - 1 features and 1 label. Label should not be included\n",
    "        self.observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(len(nslkdd_train.columns) - 1,))\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "    \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "        current_label = self.expected_action\n",
    "        obs = self._next_obs()\n",
    "        \n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {'label': current_label}\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y.iloc[next_obs_idx,:])\n",
    "            obs = self.x.iloc[next_obs_idx,:]\n",
    "\n",
    "        else:\n",
    "            obs = self.x.iloc[self.dataset_idx]\n",
    "            self.expected_action = int(self.y.iloc[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "        return obs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "env = IdsEnv(images_per_episode=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\anaconda3\\envs\\MP\\lib\\site-packages\\gym\\core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[777]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 777\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "seed_torch(seed)\n",
    "env.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames = int(1.0e5)\n",
    "memory_size = 100000\n",
    "batch_size = 128\n",
    "target_update = 10000\n",
    "epsilon_decay = 1 / 10000\n",
    "\n",
    "# train\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update, epsilon_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.train(num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Run the trained agent (1 episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation done...\n",
      "Accuracy: 94.89397568982344%\n",
      "Precision: 94.88628777426676%\n",
      "Recall/TPR/Sensitivity: 99.99062001688397%\n",
      "FPR: 94.18032786885246%\n",
      "F1 score: 0.9737160603777031\n",
      "count: 22543\n"
     ]
    }
   ],
   "source": [
    "agent.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
