{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt install python-opengl\n",
    "    !apt install ffmpeg\n",
    "    !apt install xvfb\n",
    "    !pip install PyVirtualDisplay==3.0\n",
    "    !pip install gym==0.21.0\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    # Start virtual display\n",
    "    dis = Display(visible=0, size=(400, 400))\n",
    "    dis.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Double DQN\n",
    "\n",
    "[van Hasselt et al., \"Deep Reinforcement Learning with Double Q-learning.\" arXiv preprint arXiv:1509.06461, 2015.](https://arxiv.org/pdf/1509.06461.pdf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Let's take a close look at the difference between DQN and Double-DQN. The max operator in standard Q-learning and DQN uses the same values both to select and to evaluate an action. This makes it more likely to select overestimated values, resulting in overoptimistic value estimates.\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t + \\alpha \\big(Y_t^Q - Q(S_t, A_t; \\theta_t)\\big) \\cdot \\nabla_{\\theta_t} Q(S_t, A_t; \\theta_t),\\\\\n",
    "\\text{where } \\alpha \\text{ is a scalar step size and the target } Y_t^Q \\text{is defined as }\\\\\n",
    "Y_t^Q = R_{t+1} + \\gamma \\max_a Q(S_{t+1}, a; \\theta_t).\n",
    "$$\n",
    "\n",
    "In Double Q-learning ([van Hasselt 2010](https://papers.nips.cc/paper/3964-double-q-learning.pdf)), two value functions are learned by assigning experiences randomly to update one of the two value functions, resulting in two sets of weights, $\\theta$ and $\\theta'$. For each update, one set of weights is used to determine the greedy policy and the other to determine its value. For a clear comparison, we can untangle the selection and evaluation in Q-learning and rewrite DQN's target as\n",
    "\n",
    "$$\n",
    "Y_t^Q = R_{t+1} + \\gamma Q(S_{t+1}, \\arg\\max_a Q(S_{t+1}, a; \\theta_t); \\theta_t).\n",
    "$$\n",
    "\n",
    "The Double Q-learning error can then be written as\n",
    "\n",
    "$$\n",
    "Y_t^{DoubleQ} = R_{t+1} + \\gamma Q(S_{t+1}, \\arg\\max_a Q(S_{t+1}, a; \\theta_t); \\theta_t').\n",
    "$$\n",
    "\n",
    "The idea of Double Q-learning is to reduce overestimations by decomposing the max operation in the target into action selection and action evaluation. Although not fully decoupled, the target network in the DQN architecture provides a natural candidate for the second value function, without having to introduce additional networks. In conclusion, the weights of the second network $\\theta_t'$ are replaced with the weights of the target network for the evaluation of the current greedy policy. This makes just a small change in calculating the target value of DQN loss.\n",
    "\n",
    "##### DQN:\n",
    "\n",
    "```\n",
    "target = reward + gamma * dqn_target(next_state).max(dim=1, keepdim=True)[0]\n",
    "```\n",
    "\n",
    "##### DoubleDQN:\n",
    "\n",
    "```\n",
    "selected_action = dqn(next_state).argmax(dim=1, keepdim=True)\n",
    "target = reward + gamma * dqn_target(next_state).gather(1, selected_action)\n",
    "```\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import gym\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Please see *01.dqn.ipynb* for detailed description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "\n",
    "    def store(\n",
    "        self,\n",
    "        obs: np.ndarray,\n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ):\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "        return dict(obs=self.obs_buf[idxs],\n",
    "                    next_obs=self.next_obs_buf[idxs],\n",
    "                    acts=self.acts_buf[idxs],\n",
    "                    rews=self.rews_buf[idxs],\n",
    "                    done=self.done_buf[idxs])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network\n",
    "\n",
    "We are going to use a simple network architecture with three fully connected layers and two non-linearity functions (ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(128, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Using the preprocessed datasets by Laurens D'Hooge (https://gitlab.ilabt.imec.be/lpdhooge/clean-ids-collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0         0        491          0     0               0       0    0   \n",
       "1         0        146          0     0               0       0    0   \n",
       "2         0          0          0     0               0       0    0   \n",
       "3         0        232       8153     0               0       0    0   \n",
       "4         0        199        420     0               0       0    0   \n",
       "\n",
       "   num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_RSTO  \\\n",
       "0                  0          0                0  ...         0          0   \n",
       "1                  0          0                0  ...         0          0   \n",
       "2                  0          0                0  ...         0          0   \n",
       "3                  0          1                0  ...         0          0   \n",
       "4                  0          1                0  ...         0          0   \n",
       "\n",
       "   flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
       "0            0          0        0        0        0        0        1   \n",
       "1            0          0        0        0        0        0        1   \n",
       "2            0          0        1        0        0        0        0   \n",
       "3            0          0        0        0        0        0        1   \n",
       "4            0          0        0        0        0        0        1   \n",
       "\n",
       "   flag_SH  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train = pd.read_feather(\"./datasets/nsl-kdd/KDDTrain.feather\")\n",
    "nslkdd_test = pd.read_feather(\"./datasets/nsl-kdd/KDDTest.feather\")\n",
    "# data = pd.concat([nslkdd_test], ignore_index=True)\n",
    "# print(len(data.columns))\n",
    "\n",
    "# nslkdd_train.protocol_type = pd.Categorical(nslkdd_train.protocol_type).codes\n",
    "# nslkdd_train.service = pd.Categorical(nslkdd_train.service).codes\n",
    "# nslkdd_train.flag = pd.Categorical(nslkdd_train.flag).codes\n",
    "\n",
    "\n",
    "# nslkdd_test.protocol_type = pd.Categorical(nslkdd_test.protocol_type).codes\n",
    "# nslkdd_test.service = pd.Categorical(nslkdd_test.service).codes\n",
    "# nslkdd_test.flag = pd.Categorical(nslkdd_test.flag).codes\n",
    "\n",
    "\n",
    "nslkdd_train = pd.get_dummies(nslkdd_train,columns=['protocol_type' ,'service', 'flag'])\n",
    "nslkdd_test = pd.get_dummies(nslkdd_test, columns=['protocol_type' ,'service', 'flag'])\n",
    "nslkdd_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Columns: 123 entries, duration to flag_SH\n",
      "dtypes: float64(15), int64(23), object(1), uint8(84)\n",
      "memory usage: 47.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125973.00000</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>125973.00000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>287.14465</td>\n",
       "      <td>4.556674e+04</td>\n",
       "      <td>1.977911e+04</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.204409</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.395736</td>\n",
       "      <td>0.279250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08917</td>\n",
       "      <td>0.012399</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.019218</td>\n",
       "      <td>0.276655</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.594929</td>\n",
       "      <td>0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2604.51531</td>\n",
       "      <td>5.870331e+06</td>\n",
       "      <td>4.021269e+06</td>\n",
       "      <td>0.014086</td>\n",
       "      <td>0.253530</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>2.149968</td>\n",
       "      <td>0.045239</td>\n",
       "      <td>0.489010</td>\n",
       "      <td>23.942042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28499</td>\n",
       "      <td>0.110661</td>\n",
       "      <td>0.028583</td>\n",
       "      <td>0.137292</td>\n",
       "      <td>0.447346</td>\n",
       "      <td>0.053750</td>\n",
       "      <td>0.031736</td>\n",
       "      <td>0.019719</td>\n",
       "      <td>0.490908</td>\n",
       "      <td>0.046332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.760000e+02</td>\n",
       "      <td>5.160000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42908.00000</td>\n",
       "      <td>1.379964e+09</td>\n",
       "      <td>1.309937e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes           land  \\\n",
       "count  125973.00000  1.259730e+05  1.259730e+05  125973.000000   \n",
       "mean      287.14465  4.556674e+04  1.977911e+04       0.000198   \n",
       "std      2604.51531  5.870331e+06  4.021269e+06       0.014086   \n",
       "min         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "25%         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "50%         0.00000  4.400000e+01  0.000000e+00       0.000000   \n",
       "75%         0.00000  2.760000e+02  5.160000e+02       0.000000   \n",
       "max     42908.00000  1.379964e+09  1.309937e+09       1.000000   \n",
       "\n",
       "       wrong_fragment         urgent            hot  num_failed_logins  \\\n",
       "count   125973.000000  125973.000000  125973.000000      125973.000000   \n",
       "mean         0.022687       0.000111       0.204409           0.001222   \n",
       "std          0.253530       0.014366       2.149968           0.045239   \n",
       "min          0.000000       0.000000       0.000000           0.000000   \n",
       "25%          0.000000       0.000000       0.000000           0.000000   \n",
       "50%          0.000000       0.000000       0.000000           0.000000   \n",
       "75%          0.000000       0.000000       0.000000           0.000000   \n",
       "max          3.000000       3.000000      77.000000           5.000000   \n",
       "\n",
       "           logged_in  num_compromised  ...      flag_REJ      flag_RSTO  \\\n",
       "count  125973.000000    125973.000000  ...  125973.00000  125973.000000   \n",
       "mean        0.395736         0.279250  ...       0.08917       0.012399   \n",
       "std         0.489010        23.942042  ...       0.28499       0.110661   \n",
       "min         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "25%         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "50%         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "75%         1.000000         0.000000  ...       0.00000       0.000000   \n",
       "max         1.000000      7479.000000  ...       1.00000       1.000000   \n",
       "\n",
       "         flag_RSTOS0      flag_RSTR        flag_S0        flag_S1  \\\n",
       "count  125973.000000  125973.000000  125973.000000  125973.000000   \n",
       "mean        0.000818       0.019218       0.276655       0.002897   \n",
       "std         0.028583       0.137292       0.447346       0.053750   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       1.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             flag_S2        flag_S3        flag_SF        flag_SH  \n",
       "count  125973.000000  125973.000000  125973.000000  125973.000000  \n",
       "mean        0.001008       0.000389       0.594929       0.002151  \n",
       "std         0.031736       0.019719       0.490908       0.046332  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       1.000000       0.000000  \n",
       "75%         0.000000       0.000000       1.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 122 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train.info()\n",
    "nslkdd_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_dataset_sampler_df(df, train_frac=0.2, val_frac=0.1, test_frac=0.7):\n",
    "    col = df.columns[-1]\n",
    "    print(col)\n",
    "    cols = df.columns[:-1]\n",
    "    print(cols)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    n = vc.iloc[-1]\n",
    "    print(n)\n",
    "    m = vc.iloc[0]\n",
    "    print(m)\n",
    "    print(int(m-n))\n",
    "    initial_cut = df.loc[df[col] == vc.index[0]].sample(n=int(m-n), replace=False)\n",
    "    print(initial_cut.index)\n",
    "    df = df.drop(index=initial_cut.index)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    print(int(n*train_frac))\n",
    "    train_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*train_frac), replace=False))\n",
    "    train_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=train_df.index)\n",
    "\n",
    "    validation_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*val_frac), replace=False))\n",
    "    validation_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=validation_df.index)\n",
    "\n",
    "    test_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*test_frac), replace=False))\n",
    "    test_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=test_df.index)\n",
    "\n",
    "    return train_df[cols], train_df[col], validation_df[cols], validation_df[col], test_df[cols], test_df[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nslkdd_split_df(train_df, test_df):\n",
    "    train_col = train_df.columns[-1]\n",
    "    print(train_col)\n",
    "    train_cols = train_df.columns[:-1]\n",
    "    print(train_cols)\n",
    "    test_col = test_df.columns[-1]\n",
    "    print(test_col)\n",
    "    test_cols = test_df.columns[:-1]\n",
    "    print(test_cols)\n",
    "\n",
    "    return train_df[train_cols], train_df[train_col], test_df[test_cols], test_df[test_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def malicious_benign(df):\n",
    "    print(df['class'].value_counts())\n",
    "    df['class'] = df['class'].astype('object')\n",
    "    atk_idx = df.loc[df['class'] != \"normal\"].index\n",
    "    df.loc[atk_idx, 'class'] = 1.0\n",
    "    df.loc[df.index.difference(atk_idx), 'class'] = 0.0\n",
    "    df['class'] = df['class'].astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: class, dtype: int64\n",
      "\n",
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "rootkit              13\n",
      "xterm                13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "worm                  2\n",
      "loadmodule            2\n",
      "perl                  2\n",
      "sqlattack             2\n",
      "udpstorm              2\n",
      "phf                   2\n",
      "imap                  1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "malicious_benign(nslkdd_train)\n",
    "print()\n",
    "malicious_benign(nslkdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['service_aol', 'service_harvest', 'service_http_2784',\n",
      "       'service_http_8001', 'service_red_i', 'service_urh_i'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Columns: 117 entries, duration to flag_SH\n",
      "dtypes: float32(1), float64(15), int64(23), uint8(78)\n",
      "memory usage: 46.4 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\AppData\\Local\\Temp\\ipykernel_12384\\366472954.py:1: FutureWarning: Index.__xor__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__xor__.  Use index.symmetric_difference(other) instead.\n",
      "  extra_removables = nslkdd_test.columns ^ nslkdd_train.columns\n"
     ]
    }
   ],
   "source": [
    "extra_removables = nslkdd_test.columns ^ nslkdd_train.columns\n",
    "print(extra_removables)\n",
    "try:\n",
    "    nslkdd_train = nslkdd_train.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    nslkdd_test.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "nslkdd_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag_SH\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR',\n",
      "       'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF'],\n",
      "      dtype='object', length=116)\n",
      "flag_SH\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR',\n",
      "       'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF'],\n",
      "      dtype='object', length=116)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test  = nslkdd_split_df(nslkdd_train, nslkdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()\n",
    "\n",
    "# custom keys -> replace by index\n",
    "\n",
    "x_train = x_train.set_index([pd.Index(range (0, len(x_train)))])\n",
    "y_train = y_train.set_index([pd.Index(range (0, len(y_train)))])\n",
    "x_test = x_test.set_index([pd.Index(range (0, len(x_test)))])\n",
    "y_test = y_test.set_index([pd.Index(range (0, len(y_test)))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double DQN Agent\n",
    "\n",
    "Here is a summary of DQNAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "| ---              | ---                                                  |\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|compute_dqn_loss  | return dqn loss.                                     |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|target_hard_update| hard update from the local model to the target model.|\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|plot              | plot the training progresses.                        |\n",
    "\n",
    "We use `self.dqn` instead of `self.dqn_target` for action selection.\n",
    "\n",
    "```\n",
    "\n",
    "        next_q_value = self.dqn_target(next_state).gather(\n",
    "            1, self.dqn(next_state).argmax(dim=1, keepdim=True)  # Double DQN\n",
    "        ).detach()\n",
    "        mask = 1 - done\n",
    "        target = (reward + self.gamma * next_q_value * mask).to(self.device)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (ReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        epsilon (float): parameter for epsilon greedy policy\n",
    "        epsilon_decay (float): step size to decrease epsilon\n",
    "        max_epsilon (float): max value of epsilon\n",
    "        min_epsilon (float): min value of epsilon\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including \n",
    "                           state, action, reward, next_state, done\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        epsilon_decay: float,\n",
    "        max_epsilon: float = 1.0,\n",
    "        min_epsilon: float = 0.1,\n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            epsilon_decay (float): step size to decrease epsilon\n",
    "            lr (float): learning rate\n",
    "            max_epsilon (float): max value of epsilon\n",
    "            min_epsilon (float): min value of epsilon\n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.n\n",
    "        \n",
    "        self.env = env\n",
    "        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon = max_epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.max_epsilon = max_epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.target_update = target_update\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # epsilon greedy policy\n",
    "        if self.epsilon > np.random.random():\n",
    "            selected_action = self.env.action_space.sample()\n",
    "        else:\n",
    "            selected_action = self.dqn(\n",
    "                torch.FloatTensor(state).to(self.device)\n",
    "            ).argmax()\n",
    "            selected_action = selected_action.detach().cpu().numpy()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        \n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, done, _ = self.env.step(action)\n",
    "\n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            self.memory.store(*self.transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        samples = self.memory.sample_batch()\n",
    "\n",
    "        loss = self._compute_dqn_loss(samples)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        update_cnt = 0\n",
    "        epsilons = []\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state = self.env.reset()\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # linearly decrease epsilon\n",
    "                self.epsilon = max(\n",
    "                    self.min_epsilon, self.epsilon - (\n",
    "                        self.max_epsilon - self.min_epsilon\n",
    "                    ) * self.epsilon_decay\n",
    "                )\n",
    "                epsilons.append(self.epsilon)\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses, epsilons)\n",
    "                \n",
    "        self.env.close()\n",
    "                \n",
    "    def test(self) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        TP, FP, TN, FN = 0,0,0,0\n",
    "        # for recording a video\n",
    "        naive_env = self.env\n",
    "        self.env = IdsEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)\n",
    "\n",
    "        action = self.env.reset()\n",
    "        done = False\n",
    "        count = 0\n",
    "        try:\n",
    "            while True:\n",
    "                     \n",
    "                done = False\n",
    "                while not done:\n",
    "                    count += 1\n",
    "                    action = self.select_action(action)\n",
    "                    next_action, rew, done, info = self.env.step(action)\n",
    "                    action = next_action\n",
    "                    label = info['label']\n",
    "                    if label == 0 and rew > 0:\n",
    "                        TP += 1\n",
    "                    if label == 0 and rew == 0:\n",
    "                        FP += 1\n",
    "                    if label == 1 and rew > 0:\n",
    "                        TN += 1\n",
    "                    if label == 1 and rew == 0:\n",
    "                        FN += 1\n",
    "        except StopIteration:\n",
    "            accuracy = (float(TP + TN) / (TP + FP + FN + TN)) \n",
    "            precision = (float(TP) / (TP + FP))\n",
    "            try:\n",
    "                recall = (float(TP) / (TP + FN)) # = TPR = Sensitivity\n",
    "            except:\n",
    "                recall = 0\n",
    "            try:\n",
    "                FPR = (float(FP) / (TN + FP)) # 1 - specificity\n",
    "            except:\n",
    "                FPR = 0\n",
    "            try:\n",
    "                f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "            except:\n",
    "                f1_score = 0\n",
    "            print()\n",
    "            print('validation done...')\n",
    "            print('Accuracy: {0}%'.format(accuracy * 100))\n",
    "            print('Precision: {0}%'.format(precision * 100))\n",
    "            print('Recall/TPR/Sensitivity: {0}%'.format(recall * 100))\n",
    "            print('FPR: {0}%'.format(FPR * 100))\n",
    "            print('F1 score: {0}'.format(f1_score))\n",
    "            print('count: {0}'.format(count))\n",
    "        self.env.close()\n",
    "        \n",
    "        # reset\n",
    "        self.env = naive_env\n",
    "\n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:\n",
    "        \"\"\"Return dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"].reshape(-1, 1)).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "        \n",
    "        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal\n",
    "        #       = r                       otherwise\n",
    "        curr_q_value = self.dqn(state).gather(1, action)\n",
    "        next_q_value = self.dqn_target(next_state).gather(  # Double DQN\n",
    "            1, self.dqn(next_state).argmax(dim=1, keepdim=True)\n",
    "        ).detach()\n",
    "        mask = 1 - done\n",
    "        target = (reward + self.gamma * next_q_value * mask).to(self.device)\n",
    "\n",
    "        # calculate dqn loss\n",
    "        loss = F.smooth_l1_loss(curr_q_value, target)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores: List[float], \n",
    "        losses: List[float], \n",
    "        epsilons: List[float],\n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
    "        plt.plot(scores)\n",
    "        plt.subplot(132)\n",
    "        plt.title('loss')\n",
    "        plt.plot(losses)\n",
    "        plt.subplot(133)\n",
    "        plt.title('epsilons')\n",
    "        plt.plot(epsilons)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "You can see the [code](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py) and [configurations](https://github.com/openai/gym/blob/master/gym/envs/__init__.py#L53) of CartPole-v0 from OpenAI's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdsEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "        # Actions we can take, classify as malicious or non-malicious (later also the correct attack)\n",
    "        # change to 19 if detectiong all different attacks\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "         # All the features we have, len(important_features) - 1 features and 1 label. Label should not be included\n",
    "        self.observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(len(nslkdd_train.columns) - 1,))\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "    \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "        current_label = self.expected_action\n",
    "        obs = self._next_obs()\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {'label': current_label}\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y.iloc[next_obs_idx,:])\n",
    "            obs = self.x.iloc[next_obs_idx,:]\n",
    "\n",
    "        else:\n",
    "            obs = self.x.iloc[self.dataset_idx]\n",
    "            self.expected_action = int(self.y.iloc[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "        return obs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "env = IdsEnv(images_per_episode=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\anaconda3\\envs\\MP\\lib\\site-packages\\gym\\core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[777]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 777\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "seed_torch(seed)\n",
    "env.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames = int(1.0e5)\n",
    "memory_size = 100000\n",
    "batch_size = 128\n",
    "target_update = 10000\n",
    "epsilon_decay = 1 / 10000\n",
    "\n",
    "# train\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update, epsilon_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.train(num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation done...\n",
      "Accuracy: 95.06254990684056%\n",
      "Precision: 95.05095909920335%\n",
      "Recall/TPR/Sensitivity: 99.99531791366233%\n",
      "FPR: 93.91891891891892%\n",
      "F1 score: 0.9746046957355055\n",
      "count: 22543\n"
     ]
    }
   ],
   "source": [
    "agent.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
