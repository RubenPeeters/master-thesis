{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt install python-opengl\n",
    "    !apt install ffmpeg\n",
    "    !apt install xvfb\n",
    "    !pip install PyVirtualDisplay==3.0\n",
    "    !pip install gym==0.21.0\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    # Start virtual display\n",
    "    dis = Display(visible=0, size=(400, 400))\n",
    "    dis.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Noisy Networks for Exploration\n",
    "\n",
    "[M. Fortunato et al., \"Noisy Networks for Exploration.\" arXiv preprint arXiv:1706.10295, 2017.](https://arxiv.org/pdf/1706.10295.pdf)\n",
    "\n",
    "\n",
    "NoisyNet is an exploration method that learns perturbations of the network weights to drive exploration. The key insight is that a single change to the weight vector can induce a consistent, and potentially very complex, state-dependent change in policy over multiple time steps.\n",
    "\n",
    "Firstly, let's take a look into a linear layer of a neural network with $p$ inputs and $q$ outputs, represented by\n",
    "\n",
    "$$\n",
    "y = wx + b,\n",
    "$$\n",
    "\n",
    "where $x \\in \\mathbb{R}^p$ is the layer input, $w \\in \\mathbb{R}^{q \\times p}$, and $b \\in \\mathbb{R}$ the bias.\n",
    "\n",
    "The corresponding noisy linear layer is defined as:\n",
    "\n",
    "$$\n",
    "y = (\\mu^w + \\sigma^w \\odot \\epsilon^w) x + \\mu^b + \\sigma^b \\odot \\epsilon^b,\n",
    "$$\n",
    "\n",
    "where $\\mu^w + \\sigma^w \\odot \\epsilon^w$ and $\\mu^b + \\sigma^b \\odot \\epsilon^b$ replace $w$ and $b$ in the first linear layer equation. The parameters $\\mu^w \\in \\mathbb{R}^{q \\times p}, \\mu^b \\in \\mathbb{R}^q, \\sigma^w \\in \\mathbb{R}^{q \\times p}$ and $\\sigma^b \\in \\mathbb{R}^q$ are learnable, whereas $\\epsilon^w \\in \\mathbb{R}^{q \\times p}$ and $\\epsilon^b \\in \\mathbb{R}^q$ are noise random variables which can be generated by one of the following two ways:\n",
    "\n",
    "1. **Independent Gaussian noise**: the noise applied to each weight and bias is independent, where each random noise entry is drawn from a unit Gaussian distribution. This means that for each noisy linear layer, there are $pq + q$ noise variables (for $p$ inputs to the layer and $q$ outputs).\n",
    "2. **Factorised Gaussian noise:** This is a more computationally efficient way. It produces 2 random Gaussian noise vectors ($p, q$) and makes $pq + q$ noise entries by outer product as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\epsilon_{i,j}^w &= f(\\epsilon_i) f(\\epsilon_j),\\\\\n",
    "\\epsilon_{j}^b &= f(\\epsilon_i),\\\\\n",
    "\\text{where } f(x) &= sgn(x) \\sqrt{|x|}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In all experiements of the paper, the authors used Factorised Gaussian noise, so we will go for it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Please see *01.dqn.ipynb* for detailed description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "\n",
    "    def store(\n",
    "        self,\n",
    "        obs: np.ndarray,\n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ):\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "        return dict(obs=self.obs_buf[idxs],\n",
    "                    next_obs=self.next_obs_buf[idxs],\n",
    "                    acts=self.acts_buf[idxs],\n",
    "                    rews=self.rews_buf[idxs],\n",
    "                    done=self.done_buf[idxs])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Layer\n",
    "\n",
    "**References:**\n",
    "- https://github.com/higgsfield/RL-Adventure/blob/master/5.noisy%20dqn.ipynb\n",
    "- https://github.com/Kaixhin/Rainbow/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    \"\"\"Noisy linear module for NoisyNet.\n",
    "    \n",
    "    Attributes:\n",
    "        in_features (int): input size of linear module\n",
    "        out_features (int): output size of linear module\n",
    "        std_init (float): initial std value\n",
    "        weight_mu (nn.Parameter): mean value weight parameter\n",
    "        weight_sigma (nn.Parameter): std value weight parameter\n",
    "        bias_mu (nn.Parameter): mean value bias parameter\n",
    "        bias_sigma (nn.Parameter): std value bias parameter\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, std_init: float = 0.5):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(\n",
    "            torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"weight_epsilon\", torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.Tensor(out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reset trainable network parameters (factorized gaussian noise).\"\"\"\n",
    "        mu_range = 1 / math.sqrt(self.in_features)\n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.in_features)\n",
    "        )\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.out_features)\n",
    "        )\n",
    "\n",
    "    def reset_noise(self):\n",
    "        \"\"\"Make new noise.\"\"\"\n",
    "        epsilon_in = self.scale_noise(self.in_features)\n",
    "        epsilon_out = self.scale_noise(self.out_features)\n",
    "\n",
    "        # outer product\n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(epsilon_out)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\n",
    "        \n",
    "        We don't use separate statements on train / eval mode.\n",
    "        It doesn't show remarkable difference of performance.\n",
    "        \"\"\"\n",
    "        return F.linear(\n",
    "            x,\n",
    "            self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
    "            self.bias_mu + self.bias_sigma * self.bias_epsilon,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale_noise(size: int) -> torch.Tensor:\n",
    "        \"\"\"Set scale to make noise (factorized gaussian noise).\"\"\"\n",
    "        x = torch.randn(size)\n",
    "\n",
    "        return x.sign().mul(x.abs().sqrt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Network\n",
    "\n",
    "We use NoisyLinear for the last two FC layers, and there is a method to reset noise at every step.\n",
    "These are the only differences from the example of *01.dqn.ipynb*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.feature = nn.Linear(in_dim, 128)\n",
    "        self.noisy_layer1 = NoisyLinear(128, 128)\n",
    "        self.noisy_layer2 = NoisyLinear(128, out_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        feature = F.relu(self.feature(x))\n",
    "        hidden = F.relu(self.noisy_layer1(feature))\n",
    "        out = self.noisy_layer2(hidden)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        \"\"\"Reset all noisy layers.\"\"\"\n",
    "        self.noisy_layer1.reset_noise()\n",
    "        self.noisy_layer2.reset_noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0         0        491          0     0               0       0    0   \n",
       "1         0        146          0     0               0       0    0   \n",
       "2         0          0          0     0               0       0    0   \n",
       "3         0        232       8153     0               0       0    0   \n",
       "4         0        199        420     0               0       0    0   \n",
       "\n",
       "   num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_RSTO  \\\n",
       "0                  0          0                0  ...         0          0   \n",
       "1                  0          0                0  ...         0          0   \n",
       "2                  0          0                0  ...         0          0   \n",
       "3                  0          1                0  ...         0          0   \n",
       "4                  0          1                0  ...         0          0   \n",
       "\n",
       "   flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
       "0            0          0        0        0        0        0        1   \n",
       "1            0          0        0        0        0        0        1   \n",
       "2            0          0        1        0        0        0        0   \n",
       "3            0          0        0        0        0        0        1   \n",
       "4            0          0        0        0        0        0        1   \n",
       "\n",
       "   flag_SH  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train = pd.read_feather(\"./datasets/nsl-kdd/KDDTrain.feather\")\n",
    "nslkdd_test = pd.read_feather(\"./datasets/nsl-kdd/KDDTest.feather\")\n",
    "# data = pd.concat([nslkdd_test], ignore_index=True)\n",
    "# print(len(data.columns))\n",
    "\n",
    "# nslkdd_train.protocol_type = pd.Categorical(nslkdd_train.protocol_type).codes\n",
    "# nslkdd_train.service = pd.Categorical(nslkdd_train.service).codes\n",
    "# nslkdd_train.flag = pd.Categorical(nslkdd_train.flag).codes\n",
    "\n",
    "\n",
    "# nslkdd_test.protocol_type = pd.Categorical(nslkdd_test.protocol_type).codes\n",
    "# nslkdd_test.service = pd.Categorical(nslkdd_test.service).codes\n",
    "# nslkdd_test.flag = pd.Categorical(nslkdd_test.flag).codes\n",
    "\n",
    "\n",
    "nslkdd_train = pd.get_dummies(nslkdd_train,columns=['protocol_type' ,'service', 'flag'])\n",
    "nslkdd_test = pd.get_dummies(nslkdd_test, columns=['protocol_type' ,'service', 'flag'])\n",
    "nslkdd_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Columns: 123 entries, duration to flag_SH\n",
      "dtypes: float64(15), int64(23), object(1), uint8(84)\n",
      "memory usage: 47.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125973.00000</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>125973.00000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>287.14465</td>\n",
       "      <td>4.556674e+04</td>\n",
       "      <td>1.977911e+04</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.204409</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.395736</td>\n",
       "      <td>0.279250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08917</td>\n",
       "      <td>0.012399</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.019218</td>\n",
       "      <td>0.276655</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.594929</td>\n",
       "      <td>0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2604.51531</td>\n",
       "      <td>5.870331e+06</td>\n",
       "      <td>4.021269e+06</td>\n",
       "      <td>0.014086</td>\n",
       "      <td>0.253530</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>2.149968</td>\n",
       "      <td>0.045239</td>\n",
       "      <td>0.489010</td>\n",
       "      <td>23.942042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28499</td>\n",
       "      <td>0.110661</td>\n",
       "      <td>0.028583</td>\n",
       "      <td>0.137292</td>\n",
       "      <td>0.447346</td>\n",
       "      <td>0.053750</td>\n",
       "      <td>0.031736</td>\n",
       "      <td>0.019719</td>\n",
       "      <td>0.490908</td>\n",
       "      <td>0.046332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.760000e+02</td>\n",
       "      <td>5.160000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42908.00000</td>\n",
       "      <td>1.379964e+09</td>\n",
       "      <td>1.309937e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes           land  \\\n",
       "count  125973.00000  1.259730e+05  1.259730e+05  125973.000000   \n",
       "mean      287.14465  4.556674e+04  1.977911e+04       0.000198   \n",
       "std      2604.51531  5.870331e+06  4.021269e+06       0.014086   \n",
       "min         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "25%         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "50%         0.00000  4.400000e+01  0.000000e+00       0.000000   \n",
       "75%         0.00000  2.760000e+02  5.160000e+02       0.000000   \n",
       "max     42908.00000  1.379964e+09  1.309937e+09       1.000000   \n",
       "\n",
       "       wrong_fragment         urgent            hot  num_failed_logins  \\\n",
       "count   125973.000000  125973.000000  125973.000000      125973.000000   \n",
       "mean         0.022687       0.000111       0.204409           0.001222   \n",
       "std          0.253530       0.014366       2.149968           0.045239   \n",
       "min          0.000000       0.000000       0.000000           0.000000   \n",
       "25%          0.000000       0.000000       0.000000           0.000000   \n",
       "50%          0.000000       0.000000       0.000000           0.000000   \n",
       "75%          0.000000       0.000000       0.000000           0.000000   \n",
       "max          3.000000       3.000000      77.000000           5.000000   \n",
       "\n",
       "           logged_in  num_compromised  ...      flag_REJ      flag_RSTO  \\\n",
       "count  125973.000000    125973.000000  ...  125973.00000  125973.000000   \n",
       "mean        0.395736         0.279250  ...       0.08917       0.012399   \n",
       "std         0.489010        23.942042  ...       0.28499       0.110661   \n",
       "min         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "25%         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "50%         0.000000         0.000000  ...       0.00000       0.000000   \n",
       "75%         1.000000         0.000000  ...       0.00000       0.000000   \n",
       "max         1.000000      7479.000000  ...       1.00000       1.000000   \n",
       "\n",
       "         flag_RSTOS0      flag_RSTR        flag_S0        flag_S1  \\\n",
       "count  125973.000000  125973.000000  125973.000000  125973.000000   \n",
       "mean        0.000818       0.019218       0.276655       0.002897   \n",
       "std         0.028583       0.137292       0.447346       0.053750   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       1.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             flag_S2        flag_S3        flag_SF        flag_SH  \n",
       "count  125973.000000  125973.000000  125973.000000  125973.000000  \n",
       "mean        0.001008       0.000389       0.594929       0.002151  \n",
       "std         0.031736       0.019719       0.490908       0.046332  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       1.000000       0.000000  \n",
       "75%         0.000000       0.000000       1.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 122 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train.info()\n",
    "nslkdd_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_dataset_sampler_df(df, train_frac=0.2, val_frac=0.1, test_frac=0.7):\n",
    "    col = df.columns[-1]\n",
    "    print(col)\n",
    "    cols = df.columns[:-1]\n",
    "    print(cols)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    n = vc.iloc[-1]\n",
    "    print(n)\n",
    "    m = vc.iloc[0]\n",
    "    print(m)\n",
    "    print(int(m-n))\n",
    "    initial_cut = df.loc[df[col] == vc.index[0]].sample(n=int(m-n), replace=False)\n",
    "    print(initial_cut.index)\n",
    "    df = df.drop(index=initial_cut.index)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    print(int(n*train_frac))\n",
    "    train_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*train_frac), replace=False))\n",
    "    train_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=train_df.index)\n",
    "\n",
    "    validation_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*val_frac), replace=False))\n",
    "    validation_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=validation_df.index)\n",
    "\n",
    "    test_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*test_frac), replace=False))\n",
    "    test_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=test_df.index)\n",
    "\n",
    "    return train_df[cols], train_df[col], validation_df[cols], validation_df[col], test_df[cols], test_df[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nslkdd_split_df(train_df, test_df):\n",
    "    train_col = train_df.columns[-1]\n",
    "    print(train_col)\n",
    "    train_cols = train_df.columns[:-1]\n",
    "    print(train_cols)\n",
    "    test_col = test_df.columns[-1]\n",
    "    print(test_col)\n",
    "    test_cols = test_df.columns[:-1]\n",
    "    print(test_cols)\n",
    "\n",
    "    return train_df[train_cols], train_df[train_col], test_df[test_cols], test_df[test_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def malicious_benign(df):\n",
    "    print(df['class'].value_counts())\n",
    "    df['class'] = df['class'].astype('object')\n",
    "    atk_idx = df.loc[df['class'] != \"normal\"].index\n",
    "    df.loc[atk_idx, 'class'] = 1.0\n",
    "    df.loc[df.index.difference(atk_idx), 'class'] = 0.0\n",
    "    df['class'] = df['class'].astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: class, dtype: int64\n",
      "\n",
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "rootkit              13\n",
      "xterm                13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "worm                  2\n",
      "loadmodule            2\n",
      "perl                  2\n",
      "sqlattack             2\n",
      "udpstorm              2\n",
      "phf                   2\n",
      "imap                  1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "malicious_benign(nslkdd_train)\n",
    "print()\n",
    "malicious_benign(nslkdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['service_aol', 'service_harvest', 'service_http_2784',\n",
      "       'service_http_8001', 'service_red_i', 'service_urh_i'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Columns: 117 entries, duration to flag_SH\n",
      "dtypes: float32(1), float64(15), int64(23), uint8(78)\n",
      "memory usage: 46.4 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\AppData\\Local\\Temp\\ipykernel_25656\\366472954.py:1: FutureWarning: Index.__xor__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__xor__.  Use index.symmetric_difference(other) instead.\n",
      "  extra_removables = nslkdd_test.columns ^ nslkdd_train.columns\n"
     ]
    }
   ],
   "source": [
    "extra_removables = nslkdd_test.columns ^ nslkdd_train.columns\n",
    "print(extra_removables)\n",
    "try:\n",
    "    nslkdd_train = nslkdd_train.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    nslkdd_test.drop(labels=extra_removables, axis='columns')\n",
    "except:\n",
    "    pass\n",
    "nslkdd_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag_SH\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR',\n",
      "       'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF'],\n",
      "      dtype='object', length=116)\n",
      "flag_SH\n",
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR',\n",
      "       'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF'],\n",
      "      dtype='object', length=116)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test  = nslkdd_split_df(nslkdd_train, nslkdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()\n",
    "\n",
    "# custom keys -> replace by index\n",
    "\n",
    "x_train = x_train.set_index([pd.Index(range (0, len(x_train)))])\n",
    "y_train = y_train.set_index([pd.Index(range (0, len(y_train)))])\n",
    "x_test = x_test.set_index([pd.Index(range (0, len(x_test)))])\n",
    "y_test = y_test.set_index([pd.Index(range (0, len(y_test)))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN + NoisyNet Agent (w/o DuelingNet)\n",
    "\n",
    "Here is a summary of DQNAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "| ---              | ---                                                  |\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|compute_dqn_loss  | return dqn loss.                                     |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|target_hard_update| hard update from the local model to the target model.|\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|plot              | plot the training progresses.                        |\n",
    "\n",
    "In the paper, NoisyNet is used as a component of the Dueling Network Architecture, which includes Double-DQN and Prioritized Experience Replay. However, we don't implement them to simplify the tutorial. One thing to note is that NoisyNet is an alternertive to $\\epsilon$-greedy method, so all $\\epsilon$ related lines are removed. Please check all comments with *NoisyNet*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (ReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including\n",
    "                           state, action, reward, next_state, done\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        # NoisyNet: All attributes related to epsilon are removed\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.n\n",
    "        \n",
    "        self.env = env\n",
    "        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.target_update = target_update\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target = Network(obs_dim, action_dim).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # NoisyNet: no epsilon greedy action selection\n",
    "        selected_action = self.dqn(\n",
    "            torch.FloatTensor(state).to(self.device)\n",
    "        ).argmax()\n",
    "        selected_action = selected_action.detach().cpu().numpy()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        \n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        next_state, reward, done, _ = self.env.step(action)\n",
    "\n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            self.memory.store(*self.transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        samples = self.memory.sample_batch()\n",
    "\n",
    "        loss = self._compute_dqn_loss(samples)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # NoisyNet: reset noise\n",
    "        self.dqn.reset_noise()\n",
    "        self.dqn_target.reset_noise()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        update_cnt = 0\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "            # NoisyNet: removed decrease of epsilon\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state = self.env.reset()\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses)\n",
    "                \n",
    "        self.env.close()\n",
    "                \n",
    "    def test(self) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        TP, FP, TN, FN = 0,0,0,0\n",
    "        # for recording a video\n",
    "        naive_env = self.env\n",
    "        self.env = IdsEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)\n",
    "\n",
    "        obs = self.env.reset()\n",
    "        done = False\n",
    "        count = 0\n",
    "        try:\n",
    "            while True:\n",
    "                     \n",
    "                state, done = self.env.reset(), False\n",
    "                while not done:\n",
    "                    action = self.select_action(state)\n",
    "                    next_action, rew, done, info = self.env.step(action)\n",
    "                    action = next_action\n",
    "                    label = info['label']\n",
    "                    if label == 0 and rew > 0:\n",
    "                        TP += 1\n",
    "                    if label == 0 and rew == 0:\n",
    "                        FP += 1\n",
    "                    if label == 1 and rew > 0:\n",
    "                        TN += 1\n",
    "                    if label == 1 and rew == 0:\n",
    "                        FN += 1\n",
    "        except StopIteration:\n",
    "            accuracy = (float(TP + TN) / (TP + FP + FN + TN)) \n",
    "            precision = (float(TP) / (TP + FP))\n",
    "            recall = (float(TP) / (TP + FN)) # = TPR = Sensitivity\n",
    "            FPR = (float(FP) / (TN + FP)) # 1 - specificity\n",
    "            f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "            print()\n",
    "            print('validation done...')\n",
    "            print('Accuracy: {0}%'.format(accuracy * 100))\n",
    "            print('Precision: {0}%'.format(precision * 100))\n",
    "            print('Recall/TPR/Sensitivity: {0}%'.format(recall * 100))\n",
    "            print('FPR: {0}%'.format(FPR * 100))\n",
    "            print('F1 score: {0}'.format(f1_score))\n",
    "            print('count: {0}'.format(count))\n",
    "        self.env.close()\n",
    "        \n",
    "        # reset\n",
    "        self.env = naive_env\n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:\n",
    "        \"\"\"Return dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"].reshape(-1, 1)).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "        \n",
    "        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal\n",
    "        #       = r                       otherwise\n",
    "        curr_q_value = self.dqn(state).gather(1, action)\n",
    "        next_q_value = self.dqn_target(next_state).max(\n",
    "            dim=1, keepdim=True\n",
    "        )[0].detach()\n",
    "        mask = 1 - done\n",
    "        target = (reward + self.gamma * next_q_value * mask).to(self.device)\n",
    "\n",
    "        # calculate dqn loss\n",
    "        loss = F.smooth_l1_loss(curr_q_value, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores: List[float], \n",
    "        losses: List[float], \n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
    "        plt.plot(scores)\n",
    "        plt.subplot(132)\n",
    "        plt.title('loss')\n",
    "        plt.plot(losses)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "You can see the [code](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py) and [configurations](https://github.com/openai/gym/blob/master/gym/envs/__init__.py#L53) of CartPole-v0 from OpenAI's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdsEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "        # Actions we can take, classify as malicious or non-malicious (later also the correct attack)\n",
    "        # change to 19 if detectiong all different attacks\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "         # All the features we have, len(important_features) - 1 features and 1 label. Label should not be included\n",
    "        self.observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(len(nslkdd_train.columns) - 1,))\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "    \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "        current_label = self.expected_action\n",
    "        obs = self._next_obs()\n",
    "        \n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {'label': current_label}\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y.iloc[next_obs_idx,:])\n",
    "            obs = self.x.iloc[next_obs_idx,:]\n",
    "\n",
    "        else:\n",
    "            obs = self.x.iloc[self.dataset_idx]\n",
    "            self.expected_action = int(self.y.iloc[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "        return obs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "env = IdsEnv(images_per_episode=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rebus\\anaconda3\\envs\\MP\\lib\\site-packages\\gym\\core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[777]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 777\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "seed_torch(seed)\n",
    "env.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames = int(1.0e5)\n",
    "memory_size = 100000\n",
    "batch_size = 128\n",
    "target_update = 10000\n",
    "\n",
    "# train\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.train(num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Run the trained agent (1 episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation done...\n",
      "Accuracy: 100.0%\n",
      "Precision: 100.0%\n",
      "Recall/TPR/Sensitivity: 100.0%\n",
      "FPR: 0.0%\n",
      "F1 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "agent.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
