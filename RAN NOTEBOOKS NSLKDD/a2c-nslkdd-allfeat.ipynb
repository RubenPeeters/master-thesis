{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'baselines' already exists and is not an empty directory.\n",
      "/project/to-run-for-results/nsl=kdd/baselines\n",
      "Obtaining file:///project/to-run-for-results/nsl%3Dkdd/baselines\n",
      "Collecting gym<0.16.0,>=0.15.4\n",
      "  Downloading gym-0.15.7.tar.gz (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 14.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (1.4.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (4.46.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (0.15.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (1.4.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from baselines==0.1.6) (7.1.2)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.5 MB 66.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /opt/conda/lib/python3.7/site-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.18.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.15.0)\n",
      "Collecting pyglet<=1.5.0,>=1.4.0\n",
      "  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 42.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 45.1 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: gym, future\n",
      "  Building wheel for gym (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.15.7-py3-none-any.whl size=1648839 sha256=3d0ea4b75b8c5dbc6acac2b8f83b4b858f0ba32d86b7cccd4344aff3fedd14f9\n",
      "  Stored in directory: /home/rppeeter/.cache/pip/wheels/be/72/05/d3dfcfc2a31bbf886112b6373881bdf2e9e00d2c943f3b4f91\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=cfe7756d6ded18d768de55b44040531326f28987f4a698b3e1e99a4bae9fe7e9\n",
      "  Stored in directory: /home/rppeeter/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "Successfully built gym future\n",
      "\u001b[31mERROR: gym 0.15.7 has requirement cloudpickle~=1.2.0, but you'll have cloudpickle 1.4.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: future, pyglet, gym, opencv-python, baselines\n",
      "  Running setup.py develop for baselines\n",
      "Successfully installed baselines future-0.18.2 gym-0.15.7 opencv-python-4.5.5.64 pyglet-1.5.0\n",
      "Collecting stable-baselines\n",
      "  Downloading stable_baselines-2.10.2-py3-none-any.whl (240 kB)\n",
      "\u001b[K     |████████████████████████████████| 240 kB 15.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gym[atari,classic_control]>=0.11 in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (0.15.7)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (1.4.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (1.0.4)\n",
      "Requirement already satisfied: cloudpickle>=0.5.5 in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (1.4.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (1.18.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (3.2.1)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (4.5.5.64)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from stable-baselines) (0.15.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines) (1.15.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines) (1.5.0)\n",
      "Requirement already satisfied: Pillow; extra == \"atari\" in /opt/conda/lib/python3.7/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines) (7.1.2)\n",
      "Collecting atari-py~=0.2.0; extra == \"atari\"\n",
      "  Downloading atari_py-0.2.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 33.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas->stable-baselines) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->stable-baselines) (2020.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines) (1.2.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines) (0.18.2)\n",
      "Installing collected packages: stable-baselines, atari-py\n",
      "Successfully installed atari-py-0.2.9 stable-baselines-2.10.2\n",
      "Collecting tensorflow==1.14.0\n",
      "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 109.3 MB 89 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.18.5)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 4.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
      "\u001b[K     |████████████████████████████████| 488 kB 46.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.29.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (3.11.4)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (0.9.0)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 39.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14.0) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (47.1.1.post20200529)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.6.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.0)\n",
      "Installing collected packages: keras-applications, tensorflow-estimator, tensorboard, astor, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.2.0\n",
      "    Uninstalling tensorflow-estimator-2.2.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.2.2\n",
      "    Uninstalling tensorboard-2.2.2:\n",
      "      Successfully uninstalled tensorboard-2.2.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.2.0\n",
      "    Uninstalling tensorflow-2.2.0:\n",
      "      Successfully uninstalled tensorflow-2.2.0\n",
      "Successfully installed astor-0.8.1 keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
      "Collecting tensorflow-gpu==1.14.0\n",
      "  Downloading tensorflow_gpu-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (377.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 377.1 MB 11 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.29.0)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<1.15.0,>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (3.11.4)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (47.1.1.post20200529)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.6.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.1.0)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-1.14.0\n",
      "Requirement already satisfied: gym in /opt/conda/lib/python3.7/site-packages (0.15.7)\n",
      "Collecting cloudpickle~=1.2.0\n",
      "  Downloading cloudpickle-1.2.2-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gym) (1.15.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /opt/conda/lib/python3.7/site-packages (from gym) (1.18.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from gym) (1.4.1)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.18.2)\n",
      "\u001b[31mERROR: distributed 2.18.0 has requirement cloudpickle>=1.3.0, but you'll have cloudpickle 1.2.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: cloudpickle\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 1.4.1\n",
      "    Uninstalling cloudpickle-1.4.1:\n",
      "      Successfully uninstalled cloudpickle-1.4.1\n",
      "Successfully installed cloudpickle-1.2.2\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-7.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.7 MB 14.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from pyarrow) (1.18.5)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-7.0.0\n",
      "Found existing installation: tensorboard-plugin-wit 1.6.0.post3\n",
      "Uninstalling tensorboard-plugin-wit-1.6.0.post3:\n",
      "  Successfully uninstalled tensorboard-plugin-wit-1.6.0.post3\n",
      "/project/to-run-for-results/nsl=kdd\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/openai/baselines.git\n",
    "%cd baselines\n",
    "!pip install -e .\n",
    "!pip install stable-baselines\n",
    "!pip install --upgrade tensorflow==1.14.0\n",
    "!pip install --upgrade tensorflow-gpu==1.14.0\n",
    "!pip install gym\n",
    "!pip install pyarrow\n",
    "!pip uninstall --yes tensorboard-plugin-wit\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2719213667706452704,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 16153623178727706818\n",
       " physical_device_desc: \"device: XLA_CPU device\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gym\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from datetime import datetime\n",
    "\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "\n",
    "from stable_baselines import A2C\n",
    "from stable_baselines import bench\n",
    "from stable_baselines import logger\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  protocol_type  service  flag  src_bytes  dst_bytes  land  \\\n",
       "0         0              1       20     9        491          0     0   \n",
       "1         0              2       44     9        146          0     0   \n",
       "2         0              1       49     5          0          0     0   \n",
       "3         0              1       24     9        232       8153     0   \n",
       "4         0              1       24     9        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                  25   \n",
       "1               0       0    0  ...                   1   \n",
       "2               0       0    0  ...                  26   \n",
       "3               0       0    0  ...                 255   \n",
       "4               0       0    0  ...                 255   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.17                    0.03   \n",
       "1                    0.00                    0.60   \n",
       "2                    0.10                    0.05   \n",
       "3                    1.00                    0.00   \n",
       "4                    1.00                    0.00   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.17                         0.00   \n",
       "1                         0.88                         0.00   \n",
       "2                         0.00                         0.00   \n",
       "3                         0.03                         0.04   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                      0.00                  0.05   \n",
       "1                  0.00                      0.00                  0.00   \n",
       "2                  1.00                      1.00                  0.00   \n",
       "3                  0.03                      0.01                  0.00   \n",
       "4                  0.00                      0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_rerror_rate    class  \n",
       "0                      0.00   normal  \n",
       "1                      0.00   normal  \n",
       "2                      0.00  neptune  \n",
       "3                      0.01   normal  \n",
       "4                      0.00   normal  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train = pd.read_feather(\"/project/datasets/clean-ids-collection/nsl-kdd/clean/KDDTrain.feather\")\n",
    "nslkdd_test = pd.read_feather(\"/project/datasets/clean-ids-collection/nsl-kdd/clean/KDDTest.feather\")\n",
    "# data = pd.concat([nslkdd_test], ignore_index=True)\n",
    "# print(len(data.columns))\n",
    "\n",
    "nslkdd_train.protocol_type = pd.Categorical(nslkdd_train.protocol_type).codes\n",
    "nslkdd_train.service = pd.Categorical(nslkdd_train.service).codes\n",
    "nslkdd_train.flag = pd.Categorical(nslkdd_train.flag).codes\n",
    "\n",
    "\n",
    "nslkdd_test.protocol_type = pd.Categorical(nslkdd_test.protocol_type).codes\n",
    "nslkdd_test.service = pd.Categorical(nslkdd_test.service).codes\n",
    "nslkdd_test.flag = pd.Categorical(nslkdd_test.flag).codes\n",
    "\n",
    "\n",
    "# print(pd.get_dummies(nslkdd_train,columns=['protocol_type' ,'service', 'flag']))\n",
    "# nslkdd_test = pd.get_dummies(nslkdd_test)\n",
    "nslkdd_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   duration                     125973 non-null  int64  \n",
      " 1   protocol_type                125973 non-null  int8   \n",
      " 2   service                      125973 non-null  int8   \n",
      " 3   flag                         125973 non-null  int8   \n",
      " 4   src_bytes                    125973 non-null  int64  \n",
      " 5   dst_bytes                    125973 non-null  int64  \n",
      " 6   land                         125973 non-null  int64  \n",
      " 7   wrong_fragment               125973 non-null  int64  \n",
      " 8   urgent                       125973 non-null  int64  \n",
      " 9   hot                          125973 non-null  int64  \n",
      " 10  num_failed_logins            125973 non-null  int64  \n",
      " 11  logged_in                    125973 non-null  int64  \n",
      " 12  num_compromised              125973 non-null  int64  \n",
      " 13  root_shell                   125973 non-null  int64  \n",
      " 14  su_attempted                 125973 non-null  int64  \n",
      " 15  num_root                     125973 non-null  int64  \n",
      " 16  num_file_creations           125973 non-null  int64  \n",
      " 17  num_shells                   125973 non-null  int64  \n",
      " 18  num_access_files             125973 non-null  int64  \n",
      " 19  num_outbound_cmds            125973 non-null  int64  \n",
      " 20  is_host_login                125973 non-null  int64  \n",
      " 21  is_guest_login               125973 non-null  int64  \n",
      " 22  count                        125973 non-null  int64  \n",
      " 23  srv_count                    125973 non-null  int64  \n",
      " 24  serror_rate                  125973 non-null  float64\n",
      " 25  srv_serror_rate              125973 non-null  float64\n",
      " 26  rerror_rate                  125973 non-null  float64\n",
      " 27  srv_rerror_rate              125973 non-null  float64\n",
      " 28  same_srv_rate                125973 non-null  float64\n",
      " 29  diff_srv_rate                125973 non-null  float64\n",
      " 30  srv_diff_host_rate           125973 non-null  float64\n",
      " 31  dst_host_count               125973 non-null  int64  \n",
      " 32  dst_host_srv_count           125973 non-null  int64  \n",
      " 33  dst_host_same_srv_rate       125973 non-null  float64\n",
      " 34  dst_host_diff_srv_rate       125973 non-null  float64\n",
      " 35  dst_host_same_src_port_rate  125973 non-null  float64\n",
      " 36  dst_host_srv_diff_host_rate  125973 non-null  float64\n",
      " 37  dst_host_serror_rate         125973 non-null  float64\n",
      " 38  dst_host_srv_serror_rate     125973 non-null  float64\n",
      " 39  dst_host_rerror_rate         125973 non-null  float64\n",
      " 40  dst_host_srv_rerror_rate     125973 non-null  float64\n",
      " 41  class                        125973 non-null  object \n",
      "dtypes: float64(15), int64(23), int8(3), object(1)\n",
      "memory usage: 37.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125973.00000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>287.14465</td>\n",
       "      <td>1.053202</td>\n",
       "      <td>31.226469</td>\n",
       "      <td>6.979996</td>\n",
       "      <td>4.556674e+04</td>\n",
       "      <td>1.977911e+04</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.204409</td>\n",
       "      <td>...</td>\n",
       "      <td>182.148945</td>\n",
       "      <td>115.653005</td>\n",
       "      <td>0.521242</td>\n",
       "      <td>0.082951</td>\n",
       "      <td>0.148379</td>\n",
       "      <td>0.032542</td>\n",
       "      <td>0.284452</td>\n",
       "      <td>0.278485</td>\n",
       "      <td>0.118832</td>\n",
       "      <td>0.120240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2604.51531</td>\n",
       "      <td>0.426620</td>\n",
       "      <td>16.346470</td>\n",
       "      <td>2.689365</td>\n",
       "      <td>5.870331e+06</td>\n",
       "      <td>4.021269e+06</td>\n",
       "      <td>0.014086</td>\n",
       "      <td>0.253530</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>2.149968</td>\n",
       "      <td>...</td>\n",
       "      <td>99.206213</td>\n",
       "      <td>110.702741</td>\n",
       "      <td>0.448949</td>\n",
       "      <td>0.188922</td>\n",
       "      <td>0.308997</td>\n",
       "      <td>0.112564</td>\n",
       "      <td>0.444784</td>\n",
       "      <td>0.445669</td>\n",
       "      <td>0.306557</td>\n",
       "      <td>0.319459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.760000e+02</td>\n",
       "      <td>5.160000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42908.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.379964e+09</td>\n",
       "      <td>1.309937e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration  protocol_type        service           flag  \\\n",
       "count  125973.00000  125973.000000  125973.000000  125973.000000   \n",
       "mean      287.14465       1.053202      31.226469       6.979996   \n",
       "std      2604.51531       0.426620      16.346470       2.689365   \n",
       "min         0.00000       0.000000       0.000000       0.000000   \n",
       "25%         0.00000       1.000000      20.000000       5.000000   \n",
       "50%         0.00000       1.000000      24.000000       9.000000   \n",
       "75%         0.00000       1.000000      49.000000       9.000000   \n",
       "max     42908.00000       2.000000      69.000000      10.000000   \n",
       "\n",
       "          src_bytes     dst_bytes           land  wrong_fragment  \\\n",
       "count  1.259730e+05  1.259730e+05  125973.000000   125973.000000   \n",
       "mean   4.556674e+04  1.977911e+04       0.000198        0.022687   \n",
       "std    5.870331e+06  4.021269e+06       0.014086        0.253530   \n",
       "min    0.000000e+00  0.000000e+00       0.000000        0.000000   \n",
       "25%    0.000000e+00  0.000000e+00       0.000000        0.000000   \n",
       "50%    4.400000e+01  0.000000e+00       0.000000        0.000000   \n",
       "75%    2.760000e+02  5.160000e+02       0.000000        0.000000   \n",
       "max    1.379964e+09  1.309937e+09       1.000000        3.000000   \n",
       "\n",
       "              urgent            hot  ...  dst_host_count  dst_host_srv_count  \\\n",
       "count  125973.000000  125973.000000  ...   125973.000000       125973.000000   \n",
       "mean        0.000111       0.204409  ...      182.148945          115.653005   \n",
       "std         0.014366       2.149968  ...       99.206213          110.702741   \n",
       "min         0.000000       0.000000  ...        0.000000            0.000000   \n",
       "25%         0.000000       0.000000  ...       82.000000           10.000000   \n",
       "50%         0.000000       0.000000  ...      255.000000           63.000000   \n",
       "75%         0.000000       0.000000  ...      255.000000          255.000000   \n",
       "max         3.000000      77.000000  ...      255.000000          255.000000   \n",
       "\n",
       "       dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "count           125973.000000           125973.000000   \n",
       "mean                 0.521242                0.082951   \n",
       "std                  0.448949                0.188922   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.050000                0.000000   \n",
       "50%                  0.510000                0.020000   \n",
       "75%                  1.000000                0.070000   \n",
       "max                  1.000000                1.000000   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "count                125973.000000                125973.000000   \n",
       "mean                      0.148379                     0.032542   \n",
       "std                       0.308997                     0.112564   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       0.000000                     0.000000   \n",
       "75%                       0.060000                     0.020000   \n",
       "max                       1.000000                     1.000000   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "count         125973.000000             125973.000000         125973.000000   \n",
       "mean               0.284452                  0.278485              0.118832   \n",
       "std                0.444784                  0.445669              0.306557   \n",
       "min                0.000000                  0.000000              0.000000   \n",
       "25%                0.000000                  0.000000              0.000000   \n",
       "50%                0.000000                  0.000000              0.000000   \n",
       "75%                1.000000                  1.000000              0.000000   \n",
       "max                1.000000                  1.000000              1.000000   \n",
       "\n",
       "       dst_host_srv_rerror_rate  \n",
       "count             125973.000000  \n",
       "mean                   0.120240  \n",
       "std                    0.319459  \n",
       "min                    0.000000  \n",
       "25%                    0.000000  \n",
       "50%                    0.000000  \n",
       "75%                    0.000000  \n",
       "max                    1.000000  \n",
       "\n",
       "[8 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nslkdd_train.info()\n",
    "nslkdd_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing done by Laurens D'Hooge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n",
    "- Build an agent to classify network flow automatically\n",
    "- Feed a packet that gets classified\n",
    "- Want the classification to be equal to the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_dataset_sampler_df(df, train_frac=0.2, val_frac=0.1, test_frac=0.7):\n",
    "    col = df.columns[-1]\n",
    "    print(col)\n",
    "    cols = df.columns[:-1]\n",
    "    print(cols)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    n = vc.iloc[-1]\n",
    "    print(n)\n",
    "    m = vc.iloc[0]\n",
    "    print(m)\n",
    "    print(int(m-n))\n",
    "    initial_cut = df.loc[df[col] == vc.index[0]].sample(n=int(m-n), replace=False)\n",
    "    print(initial_cut.index)\n",
    "    df = df.drop(index=initial_cut.index)\n",
    "    vc = df[col].value_counts()\n",
    "    print(vc)\n",
    "    print(int(n*train_frac))\n",
    "    train_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*train_frac), replace=False))\n",
    "    train_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=train_df.index)\n",
    "\n",
    "    validation_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*val_frac), replace=False))\n",
    "    validation_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=validation_df.index)\n",
    "\n",
    "    test_df = df.groupby(col).apply(lambda x: x.sample(n=int(n*test_frac), replace=False))\n",
    "    test_df.reset_index(level=0, inplace=True, drop=True)\n",
    "    df = df.drop(index=test_df.index)\n",
    "\n",
    "    return train_df[cols], train_df[col], validation_df[cols], validation_df[col], test_df[cols], test_df[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nslkdd_split_df(train_df, test_df):\n",
    "    train_col = train_df.columns[-1]\n",
    "    print(train_col)\n",
    "    train_cols = train_df.columns[:-1]\n",
    "    print(train_cols)\n",
    "    test_col = test_df.columns[-1]\n",
    "    print(test_col)\n",
    "    test_cols = test_df.columns[:-1]\n",
    "    print(test_cols)\n",
    "\n",
    "    return train_df[train_cols], train_df[train_col], test_df[test_cols], test_df[test_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(nslkdd_train['class'].value_counts())\n",
    "nslkdd_train['class'] = nslkdd_train['class'].astype('object')\n",
    "atk_idx = nslkdd_train.loc[nslkdd_train['class'] != \"normal\"].index\n",
    "nslkdd_train.loc[atk_idx, 'class'] = 1.0\n",
    "nslkdd_train.loc[nslkdd_train.index.difference(atk_idx), 'class'] = 0.0\n",
    "nslkdd_train['class'] = nslkdd_train['class'].astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "rootkit              13\n",
      "xterm                13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "loadmodule            2\n",
      "udpstorm              2\n",
      "perl                  2\n",
      "worm                  2\n",
      "sqlattack             2\n",
      "phf                   2\n",
      "imap                  1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(nslkdd_test['class'].value_counts())\n",
    "nslkdd_test['class'] = nslkdd_test['class'].astype('object')\n",
    "atk_idx = nslkdd_test.loc[nslkdd_test['class'] != \"normal\"].index\n",
    "nslkdd_test.loc[atk_idx, 'class'] = 1.0\n",
    "nslkdd_test.loc[nslkdd_test.index.difference(atk_idx), 'class'] = 0.0\n",
    "nslkdd_test['class'] = nslkdd_test['class'].astype(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
      "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
      "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
      "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
      "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
      "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
      "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
      "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
      "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
      "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
      "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
      "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
      "       'dst_host_srv_rerror_rate'],\n",
      "      dtype='object')\n",
      "class\n",
      "Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
      "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
      "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
      "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
      "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
      "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
      "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
      "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
      "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
      "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
      "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
      "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
      "       'dst_host_srv_rerror_rate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test  = nslkdd_split_df(nslkdd_train, nslkdd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()\n",
    "\n",
    "# custom keys -> replace by index\n",
    "\n",
    "x_train = x_train.set_index([pd.Index(range (0, len(x_train)))])\n",
    "y_train = y_train.set_index([pd.Index(range (0, len(y_train)))])\n",
    "x_test = x_test.set_index([pd.Index(range (0, len(x_test)))])\n",
    "y_test = y_test.set_index([pd.Index(range (0, len(y_test)))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdsEnv(gym.Env):\n",
    "    def __init__(self, images_per_episode=1, dataset=(x_train, y_train), random=True):\n",
    "        # Actions we can take, classify as malicious or non-malicious (later also the correct attack)\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "         # All the features we have, len(important_features) - 1 features and 1 label. Label should not be included\n",
    "        self.observation_space = gym.spaces.Box(low=float('-inf'), high=float('inf'), shape=(len(nslkdd_train.columns) - 1,))\n",
    "        self.images_per_episode = images_per_episode\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.random = random\n",
    "        self.dataset_idx = 0\n",
    "    \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        reward = int(action == self.expected_action)\n",
    "        current_label = self.expected_action\n",
    "        obs = self._next_obs()\n",
    "\n",
    "        self.step_count += 1\n",
    "        if self.step_count >= self.images_per_episode:\n",
    "            done = True\n",
    "\n",
    "        return obs, reward, done, {'label': current_label}\n",
    "\n",
    "    def _next_obs(self):\n",
    "        if self.random:\n",
    "            next_obs_idx = random.randint(0, len(self.x) - 1)\n",
    "            self.expected_action = int(self.y.iloc[next_obs_idx,:])\n",
    "            obs = self.x.iloc[next_obs_idx,:]\n",
    "\n",
    "        else:\n",
    "            obs = self.x.iloc[self.dataset_idx]\n",
    "            self.expected_action = int(self.y.iloc[self.dataset_idx])\n",
    "\n",
    "            self.dataset_idx += 1\n",
    "            if self.dataset_idx >= len(self.x):\n",
    "                raise StopIteration()\n",
    "        return obs\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "\n",
    "        obs = self._next_obs()\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train classifier using dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fab317cab50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fab317cab50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fab317cab50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fab317cab50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fab31655f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fab31655f10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fab31655f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fab31655f10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:160: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:184: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:196: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.4      |\n",
      "| explained_variance | -0.675   |\n",
      "| fps                | 13       |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.589    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.94     |\n",
      "| explained_variance | 0.531    |\n",
      "| fps                | 338      |\n",
      "| nupdates           | 10000    |\n",
      "| policy_entropy     | 0.0537   |\n",
      "| total_timesteps    | 50000    |\n",
      "| value_loss         | 0.0972   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.94     |\n",
      "| explained_variance | -0.222   |\n",
      "| fps                | 339      |\n",
      "| nupdates           | 20000    |\n",
      "| policy_entropy     | 0.0725   |\n",
      "| total_timesteps    | 100000   |\n",
      "| value_loss         | 0.221    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.96     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 339      |\n",
      "| nupdates           | 30000    |\n",
      "| policy_entropy     | 0.0224   |\n",
      "| total_timesteps    | 150000   |\n",
      "| value_loss         | 0.00356  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.97     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 40000    |\n",
      "| policy_entropy     | 0.00882  |\n",
      "| total_timesteps    | 200000   |\n",
      "| value_loss         | 0.0128   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.95     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 339      |\n",
      "| nupdates           | 50000    |\n",
      "| policy_entropy     | 0.0254   |\n",
      "| total_timesteps    | 250000   |\n",
      "| value_loss         | 0.000116 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.93     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 60000    |\n",
      "| policy_entropy     | 0.000315 |\n",
      "| total_timesteps    | 300000   |\n",
      "| value_loss         | 3.03e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.95     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 70000    |\n",
      "| policy_entropy     | 0.0271   |\n",
      "| total_timesteps    | 350000   |\n",
      "| value_loss         | 0.00215  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.96     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 80000    |\n",
      "| policy_entropy     | 0.00286  |\n",
      "| total_timesteps    | 400000   |\n",
      "| value_loss         | 0.000209 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.94     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 90000    |\n",
      "| policy_entropy     | 5.48e-07 |\n",
      "| total_timesteps    | 450000   |\n",
      "| value_loss         | 0.00282  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.94     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 100000   |\n",
      "| policy_entropy     | 0.0266   |\n",
      "| total_timesteps    | 500000   |\n",
      "| value_loss         | 0.000436 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.97     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 110000   |\n",
      "| policy_entropy     | 0.0124   |\n",
      "| total_timesteps    | 550000   |\n",
      "| value_loss         | 0.00284  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.95     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 120000   |\n",
      "| policy_entropy     | 0.000284 |\n",
      "| total_timesteps    | 600000   |\n",
      "| value_loss         | 6.14e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.96     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 130000   |\n",
      "| policy_entropy     | 0.147    |\n",
      "| total_timesteps    | 650000   |\n",
      "| value_loss         | 0.0214   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.95     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 140000   |\n",
      "| policy_entropy     | 0.0099   |\n",
      "| total_timesteps    | 700000   |\n",
      "| value_loss         | 0.00318  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.99     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 150000   |\n",
      "| policy_entropy     | 0.0018   |\n",
      "| total_timesteps    | 750000   |\n",
      "| value_loss         | 0.00714  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.93     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 160000   |\n",
      "| policy_entropy     | 0.00386  |\n",
      "| total_timesteps    | 800000   |\n",
      "| value_loss         | 0.00416  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.99     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 170000   |\n",
      "| policy_entropy     | 0.000401 |\n",
      "| total_timesteps    | 850000   |\n",
      "| value_loss         | 0.00045  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 1        |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 180000   |\n",
      "| policy_entropy     | 0.00037  |\n",
      "| total_timesteps    | 900000   |\n",
      "| value_loss         | 0.000132 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.98     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 190000   |\n",
      "| policy_entropy     | 0.0161   |\n",
      "| total_timesteps    | 950000   |\n",
      "| value_loss         | 0.00251  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 1        |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 200000   |\n",
      "| policy_entropy     | 0.0812   |\n",
      "| total_timesteps    | 1000000  |\n",
      "| value_loss         | 0.00208  |\n",
      "---------------------------------\n",
      "\n",
      "A2C 1 Training Time: 2932.9691169261932\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fab04775fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fab04775fd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fab04775fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fab04775fd0>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9d8d96bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9d8d96bd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9d8d96bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9d8d96bd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.6      |\n",
      "| explained_variance | -1.11    |\n",
      "| fps                | 17       |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.43     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.96     |\n",
      "| explained_variance | -0.0976  |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 10000    |\n",
      "| policy_entropy     | 0.0858   |\n",
      "| total_timesteps    | 50000    |\n",
      "| value_loss         | 0.213    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.93     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 20000    |\n",
      "| policy_entropy     | 0.000148 |\n",
      "| total_timesteps    | 100000   |\n",
      "| value_loss         | 0.00117  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.94     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 30000    |\n",
      "| policy_entropy     | 0.0248   |\n",
      "| total_timesteps    | 150000   |\n",
      "| value_loss         | 0.00186  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.93     |\n",
      "| explained_variance | -0.0315  |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 40000    |\n",
      "| policy_entropy     | 0.156    |\n",
      "| total_timesteps    | 200000   |\n",
      "| value_loss         | 0.393    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.96     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 50000    |\n",
      "| policy_entropy     | 0.016    |\n",
      "| total_timesteps    | 250000   |\n",
      "| value_loss         | 0.000748 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.93     |\n",
      "| explained_variance | 0.361    |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 60000    |\n",
      "| policy_entropy     | 0.05     |\n",
      "| total_timesteps    | 300000   |\n",
      "| value_loss         | 0.12     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.97     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 70000    |\n",
      "| policy_entropy     | 0.0194   |\n",
      "| total_timesteps    | 350000   |\n",
      "| value_loss         | 0.0576   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.99     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 80000    |\n",
      "| policy_entropy     | 0.0304   |\n",
      "| total_timesteps    | 400000   |\n",
      "| value_loss         | 0.00315  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.98     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 90000    |\n",
      "| policy_entropy     | 0.00331  |\n",
      "| total_timesteps    | 450000   |\n",
      "| value_loss         | 0.00166  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.95     |\n",
      "| explained_variance | -0.118   |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 100000   |\n",
      "| policy_entropy     | 0.301    |\n",
      "| total_timesteps    | 500000   |\n",
      "| value_loss         | 0.199    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.94     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 110000   |\n",
      "| policy_entropy     | 0.0231   |\n",
      "| total_timesteps    | 550000   |\n",
      "| value_loss         | 0.000586 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.93     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 120000   |\n",
      "| policy_entropy     | 0.00745  |\n",
      "| total_timesteps    | 600000   |\n",
      "| value_loss         | 0.00273  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.94     |\n",
      "| explained_variance | 0.0936   |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 130000   |\n",
      "| policy_entropy     | 0.0371   |\n",
      "| total_timesteps    | 650000   |\n",
      "| value_loss         | 0.175    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.95     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 140000   |\n",
      "| policy_entropy     | 0.0139   |\n",
      "| total_timesteps    | 700000   |\n",
      "| value_loss         | 0.000144 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 1        |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 150000   |\n",
      "| policy_entropy     | 0.0582   |\n",
      "| total_timesteps    | 750000   |\n",
      "| value_loss         | 0.00127  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.98     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 160000   |\n",
      "| policy_entropy     | 0.00124  |\n",
      "| total_timesteps    | 800000   |\n",
      "| value_loss         | 0.000618 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.98     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 170000   |\n",
      "| policy_entropy     | 0.00688  |\n",
      "| total_timesteps    | 850000   |\n",
      "| value_loss         | 0.00181  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.95     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 180000   |\n",
      "| policy_entropy     | 0.000708 |\n",
      "| total_timesteps    | 900000   |\n",
      "| value_loss         | 0.0034   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.96     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 190000   |\n",
      "| policy_entropy     | 0.0017   |\n",
      "| total_timesteps    | 950000   |\n",
      "| value_loss         | 0.000134 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.96     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 341      |\n",
      "| nupdates           | 200000   |\n",
      "| policy_entropy     | 0.00429  |\n",
      "| total_timesteps    | 1000000  |\n",
      "| value_loss         | 0.00111  |\n",
      "---------------------------------\n",
      "\n",
      "A2C 2 Training Time: 2933.731439590454\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9d88b3250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9d88b3250>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9d88b3250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9d88b3250>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9c9767dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9c9767dd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9c9767dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9c9767dd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.4      |\n",
      "| explained_variance | -0.15    |\n",
      "| fps                | 16       |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.28     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.94     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 339      |\n",
      "| nupdates           | 10000    |\n",
      "| policy_entropy     | 0.108    |\n",
      "| total_timesteps    | 50000    |\n",
      "| value_loss         | 0.000838 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.97     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 339      |\n",
      "| nupdates           | 20000    |\n",
      "| policy_entropy     | 0.124    |\n",
      "| total_timesteps    | 100000   |\n",
      "| value_loss         | 0.000379 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.98     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 30000    |\n",
      "| policy_entropy     | 0.025    |\n",
      "| total_timesteps    | 150000   |\n",
      "| value_loss         | 0.000729 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.97     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 40000    |\n",
      "| policy_entropy     | 0.00443  |\n",
      "| total_timesteps    | 200000   |\n",
      "| value_loss         | 2.52e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.98     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 50000    |\n",
      "| policy_entropy     | 0.00241  |\n",
      "| total_timesteps    | 250000   |\n",
      "| value_loss         | 0.00367  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.98     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 60000    |\n",
      "| policy_entropy     | 0.00165  |\n",
      "| total_timesteps    | 300000   |\n",
      "| value_loss         | 0.00611  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.96     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 70000    |\n",
      "| policy_entropy     | 0.0153   |\n",
      "| total_timesteps    | 350000   |\n",
      "| value_loss         | 0.00316  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.97     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 80000    |\n",
      "| policy_entropy     | 0.00138  |\n",
      "| total_timesteps    | 400000   |\n",
      "| value_loss         | 0.0014   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.93     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 90000    |\n",
      "| policy_entropy     | 0.145    |\n",
      "| total_timesteps    | 450000   |\n",
      "| value_loss         | 0.0141   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.94     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 100000   |\n",
      "| policy_entropy     | 0.00406  |\n",
      "| total_timesteps    | 500000   |\n",
      "| value_loss         | 0.00368  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.95     |\n",
      "| explained_variance | 0.455    |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 110000   |\n",
      "| policy_entropy     | 0.016    |\n",
      "| total_timesteps    | 550000   |\n",
      "| value_loss         | 0.0899   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.98     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 120000   |\n",
      "| policy_entropy     | 0.0386   |\n",
      "| total_timesteps    | 600000   |\n",
      "| value_loss         | 0.000684 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.99     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 130000   |\n",
      "| policy_entropy     | 0.0018   |\n",
      "| total_timesteps    | 650000   |\n",
      "| value_loss         | 3.21e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.96     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 140000   |\n",
      "| policy_entropy     | 0.0112   |\n",
      "| total_timesteps    | 700000   |\n",
      "| value_loss         | 0.00067  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.93     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 150000   |\n",
      "| policy_entropy     | 0.00156  |\n",
      "| total_timesteps    | 750000   |\n",
      "| value_loss         | 0.00956  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.98     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 160000   |\n",
      "| policy_entropy     | 0.0015   |\n",
      "| total_timesteps    | 800000   |\n",
      "| value_loss         | 0.00288  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.95     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 170000   |\n",
      "| policy_entropy     | 0.0161   |\n",
      "| total_timesteps    | 850000   |\n",
      "| value_loss         | 2.33e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.97     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 180000   |\n",
      "| policy_entropy     | 0.125    |\n",
      "| total_timesteps    | 900000   |\n",
      "| value_loss         | 0.000417 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.99     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 190000   |\n",
      "| policy_entropy     | 0.000528 |\n",
      "| total_timesteps    | 950000   |\n",
      "| value_loss         | 0.000995 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.96     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 340      |\n",
      "| nupdates           | 200000   |\n",
      "| policy_entropy     | 0.0662   |\n",
      "| total_timesteps    | 1000000  |\n",
      "| value_loss         | 0.000104 |\n",
      "---------------------------------\n",
      "\n",
      "A2C 3 Training Time: 2940.948867082596\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9c92cb110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9c92cb110>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9c92cb110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9c92cb110>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9c2122e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9c2122e90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9c2122e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fa9c2122e90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0        |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 16       |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 0.423    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.96     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 10000    |\n",
      "| policy_entropy     | 0.167    |\n",
      "| total_timesteps    | 50000    |\n",
      "| value_loss         | 0.000537 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.96     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 20000    |\n",
      "| policy_entropy     | 0.0187   |\n",
      "| total_timesteps    | 100000   |\n",
      "| value_loss         | 7.56e-06 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.97     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 30000    |\n",
      "| policy_entropy     | 0.105    |\n",
      "| total_timesteps    | 150000   |\n",
      "| value_loss         | 0.0003   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.95     |\n",
      "| explained_variance | 0.473    |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 40000    |\n",
      "| policy_entropy     | 0.0298   |\n",
      "| total_timesteps    | 200000   |\n",
      "| value_loss         | 0.187    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.99     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 50000    |\n",
      "| policy_entropy     | 0.0222   |\n",
      "| total_timesteps    | 250000   |\n",
      "| value_loss         | 0.00275  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.93     |\n",
      "| explained_variance | 0.489    |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 60000    |\n",
      "| policy_entropy     | 0.0188   |\n",
      "| total_timesteps    | 300000   |\n",
      "| value_loss         | 0.0986   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.95     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 70000    |\n",
      "| policy_entropy     | 0.047    |\n",
      "| total_timesteps    | 350000   |\n",
      "| value_loss         | 0.000676 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.98     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 80000    |\n",
      "| policy_entropy     | 0.00127  |\n",
      "| total_timesteps    | 400000   |\n",
      "| value_loss         | 0.000239 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.98     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 90000    |\n",
      "| policy_entropy     | 0.0001   |\n",
      "| total_timesteps    | 450000   |\n",
      "| value_loss         | 0.000398 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.97     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 100000   |\n",
      "| policy_entropy     | 0.0392   |\n",
      "| total_timesteps    | 500000   |\n",
      "| value_loss         | 0.000231 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.98     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 110000   |\n",
      "| policy_entropy     | 0.0723   |\n",
      "| total_timesteps    | 550000   |\n",
      "| value_loss         | 0.000184 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.95     |\n",
      "| explained_variance | 0.959    |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 120000   |\n",
      "| policy_entropy     | 0.00368  |\n",
      "| total_timesteps    | 600000   |\n",
      "| value_loss         | 0.00718  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 1        |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 130000   |\n",
      "| policy_entropy     | 0.0513   |\n",
      "| total_timesteps    | 650000   |\n",
      "| value_loss         | 0.000221 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.95     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 140000   |\n",
      "| policy_entropy     | 0.00707  |\n",
      "| total_timesteps    | 700000   |\n",
      "| value_loss         | 0.00117  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.96     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 150000   |\n",
      "| policy_entropy     | 0.0147   |\n",
      "| total_timesteps    | 750000   |\n",
      "| value_loss         | 0.000696 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.96     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 160000   |\n",
      "| policy_entropy     | 0.00925  |\n",
      "| total_timesteps    | 800000   |\n",
      "| value_loss         | 0.00391  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.98     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 170000   |\n",
      "| policy_entropy     | 0.142    |\n",
      "| total_timesteps    | 850000   |\n",
      "| value_loss         | 0.000638 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.97     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 180000   |\n",
      "| policy_entropy     | 0.0137   |\n",
      "| total_timesteps    | 900000   |\n",
      "| value_loss         | 0.000925 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.9      |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 190000   |\n",
      "| policy_entropy     | 0.000394 |\n",
      "| total_timesteps    | 950000   |\n",
      "| value_loss         | 0.0196   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 1        |\n",
      "| ep_reward_mean     | 0.98     |\n",
      "| explained_variance | nan      |\n",
      "| fps                | 337      |\n",
      "| nupdates           | 200000   |\n",
      "| policy_entropy     | 0.00506  |\n",
      "| total_timesteps    | 1000000  |\n",
      "| value_loss         | 5.46e-05 |\n",
      "---------------------------------\n",
      "\n",
      "A2C 4 Training Time: 2961.4106860160828\n"
     ]
    }
   ],
   "source": [
    "def ids_ddqn():\n",
    "    env = IdsEnv(images_per_episode=1)\n",
    "    env = bench.Monitor(env, logger.get_dir())\n",
    "\n",
    "    model = A2C(\n",
    "        MlpPolicy, \n",
    "        env, \n",
    "        verbose=1,\n",
    "    )\n",
    "    model.learn(\n",
    "        total_timesteps=int(1.0e6),\n",
    "        log_interval=10000,\n",
    "        \n",
    "    )\n",
    "\n",
    "    env.close()\n",
    "    \n",
    "    return model\n",
    "\n",
    "start_time = time.time()\n",
    "ddqn_model_1 = ids_ddqn()\n",
    "print()\n",
    "print(\"A2C 1 Training Time:\", time.time() - start_time)\n",
    "start_time = time.time()\n",
    "ddqn_model_2 = ids_ddqn()\n",
    "print()\n",
    "print(\"A2C 2 Training Time:\", time.time() - start_time)\n",
    "start_time = time.time()\n",
    "ddqn_model_3 = ids_ddqn()\n",
    "print()\n",
    "print(\"A2C 3 Training Time:\", time.time() - start_time)\n",
    "start_time = time.time()\n",
    "ddqn_model_4 = ids_ddqn()\n",
    "print()\n",
    "print(\"A2C 4 Training Time:\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation done...\n",
      "Accuracy: 74.74048442906575%\n",
      "Precision: 91.27544661404238%\n",
      "Recall/TPR/Sensitivity: 64.41870693446708%\n",
      "FPR: 9.438202247191011%\n",
      "F1 score: 0.7553072625698324\n",
      "\n",
      "validation done...\n",
      "Accuracy: 76.42622659923698%\n",
      "Precision: 96.84254258412962%\n",
      "Recall/TPR/Sensitivity: 65.04813729593972%\n",
      "FPR: 3.7037037037037033%\n",
      "F1 score: 0.7782322009848928\n",
      "\n",
      "validation done...\n",
      "Accuracy: 75.68095111347706%\n",
      "Precision: 94.47444952222683%\n",
      "Recall/TPR/Sensitivity: 64.75865014950875%\n",
      "FPR: 6.261770244821093%\n",
      "F1 score: 0.7684379488045958\n",
      "\n",
      "validation done...\n",
      "Accuracy: 76.16005678289415%\n",
      "Precision: 92.16867469879519%\n",
      "Recall/TPR/Sensitivity: 65.76256113828369%\n",
      "FPR: 8.333333333333332%\n",
      "F1 score: 0.7675806591125336\n",
      "\n",
      "Total validation done...\n",
      "Accuracy: 75.75192973116849%\n",
      "Precision: 93.69027835479851%\n",
      "Recall/TPR/Sensitivity: 64.99701387954981%\n",
      "FPR: 6.934252382262285%\n",
      "F1 score: 0.7673895178679636\n",
      "\n",
      "Saving model 2\n"
     ]
    }
   ],
   "source": [
    "# 0 is benign (positive), 1 is malicious (negative) \n",
    "def ids_eval(model):\n",
    "    TP, FP, TN, FN = 0,0,0,0\n",
    "    env = IdsEnv(images_per_episode=1, dataset=(x_test, y_test), random=False)\n",
    "    obs, done = env.reset(), False\n",
    "    try:\n",
    "        while True:\n",
    "            obs, done = env.reset(), False\n",
    "            while not done:\n",
    "                obs, rew, done, info = env.step(model.predict(obs)[0])\n",
    "                label = info['label']\n",
    "                if label == 0 and rew > 0:\n",
    "                    TP += 1\n",
    "                if label == 0 and rew == 0:\n",
    "                    FP += 1\n",
    "                if label == 1 and rew > 0:\n",
    "                    TN += 1\n",
    "                if label == 1 and rew == 0:\n",
    "                    FN += 1\n",
    "\n",
    "    except StopIteration:\n",
    "        accuracy = (float(TP + TN) / (TP + FP + FN + TN)) \n",
    "        precision = (float(TP) / (TP + FP))\n",
    "        recall = (float(TP) / (TP + FN)) # = TPR = Sensitivity\n",
    "        FPR = (float(FP) / (TN + FP)) # 1 - specificity\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        print()\n",
    "        print('validation done...')\n",
    "        print('Accuracy: {0}%'.format(accuracy * 100))\n",
    "        print('Precision: {0}%'.format(precision * 100))\n",
    "        print('Recall/TPR/Sensitivity: {0}%'.format(recall * 100))\n",
    "        print('FPR: {0}%'.format(FPR * 100))\n",
    "        print('F1 score: {0}'.format(f1_score))\n",
    "    return [accuracy, precision, recall, FPR, f1_score]\n",
    "\n",
    "models = [ddqn_model_1, ddqn_model_2, ddqn_model_3, ddqn_model_4]\n",
    "\n",
    "results_1 = ids_eval(ddqn_model_1)\n",
    "results_2 = ids_eval(ddqn_model_2)\n",
    "results_3 = ids_eval(ddqn_model_3)\n",
    "results_4 = ids_eval(ddqn_model_4)\n",
    "total_results = [-1,-1,-1,-1,-1]\n",
    "accuracies = [results_1[0], results_2[0], results_3[0], results_4[0]]\n",
    "\n",
    "for i in range(len(results_1)):\n",
    "    total_results[i] = (results_1[i] + results_2[i] + results_3[i] + results_4[i] )/ 4\n",
    "\n",
    "print()    \n",
    "print('Total validation done...')\n",
    "print('Accuracy: {0}%'.format(total_results[0] * 100))\n",
    "print('Precision: {0}%'.format(total_results[1] * 100))\n",
    "print('Recall/TPR/Sensitivity: {0}%'.format(total_results[2] * 100))\n",
    "print('FPR: {0}%'.format(total_results[3] * 100))\n",
    "print('F1 score: {0}'.format(total_results[4]))\n",
    "\n",
    "highest = 0\n",
    "for i in range(4):\n",
    "    if accuracies[i] > accuracies[highest]:\n",
    "        highest = i\n",
    "\n",
    "print()\n",
    "print(\"Saving model {0}\".format(highest + 1))\n",
    "models[highest].save('a2c_cicddos2019_allfeat.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
